# app_tavily_fixed_v8_generalist_fixed.py
"""
EvoGen AI with Tavily integration (v8.2: JSONè§£æ å¼·åŒ–ç‰ˆ)

v8.1ã‹ã‚‰ã®å¤‰æ›´ç‚¹:
- (å®‰å®šæ€§) `GeminiClient` ã® `call` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å¤§å¹…ã«å¼·åŒ–ã€‚
    - `_extract_json` ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’è¿½åŠ ã€‚
    - AIãŒ ` ```json ... ``` ` ã®ã‚ˆã†ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚„
      ä½™åˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’JSONã«ä»˜åŠ ã—ã¦è¿”ã—ãŸå ´åˆã§ã‚‚ã€
      JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’è‡ªå‹•çš„ã«æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹ï¼ˆè§£æï¼‰ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã€‚
    - ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å ±å‘Šã®ã€Œä¸æ­£ãªå½¢å¼ã€ã‚¨ãƒ©ãƒ¼ã‚’é˜²æ­¢ã™ã‚‹ã€‚

v8 ã®ç‰¹å¾´ (v7ã‹ã‚‰å¤‰æ›´):
- (æ±ç”¨æ€§) `get_agent_personas_prompt` ã‚’æ”¹è‰¯ã—ã€
  AIãŒã‚ã‚‰ã‚†ã‚‹èª²é¡Œã‚’åˆ†æã—ã¦æœ€é©ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨­è¨ˆã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã€‚
- (è©³ç´°åº¦) è§£æ±ºç­–ã® `specific_method` ã®èª¬æ˜ã‚’
  ã€Œ2ã€œ4è¡Œç¨‹åº¦ã€ã«å¢—é‡ã—ã€æ”¹è¡Œ(\n)ã‚’è¨±å¯ã€‚

ä½¿ã„æ–¹:
  - å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
      pip install streamlit requests google-generativeai
  - å®Ÿè¡Œ:
      streamlit run app_tavily_fixed_v8_generalist_fixed.py
"""

import streamlit as st
import os
import json
import abc
from typing import List, Dict, Any, Generator, Optional
import time
import random 

# --- å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ ---
try:
    import google.generativeai as genai
except Exception:
    genai = None

try:
    import requests
except ImportError:
    requests = None

# ----------------------------
# 1) LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå±¤ (â˜…ä¿®æ­£ç®‡æ‰€â˜…)
# ----------------------------
class LLMClient(abc.ABC):
    """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åŸºæœ¬ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹"""
    @abc.abstractmethod
    def call(self, prompt: str) -> Dict[str, Any]:
        pass

class GeminiClient(LLMClient):
    """Google Gemini ç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆâ˜…v8.2 ä¿®æ­£â˜…ï¼‰"""
    def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"):
        if genai is None:
            raise ImportError("`google-generativeai`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install google-generativeai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
        self.generation_config = genai.GenerationConfig(
            response_mime_type="application/json"
        )

    # === â˜…v8.2: ä¿®æ­£ç‚¹ 1 (ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°è¿½åŠ ) ===
    def _extract_json(self, text: str) -> Optional[str]:
        """
        ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚„ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ©ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹
        æ–‡å­—åˆ—ã‹ã‚‰ã€æœ€åˆã¨æœ€å¾Œã®æ³¢æ‹¬å¼§/è§’æ‹¬å¼§ã«åŸºã¥ã„ã¦JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºã™ã‚‹ã€‚
        """
        if not text:
            return None
        
        # æœ€åˆã® '{' ã¾ãŸã¯ '[' ã‚’è¦‹ã¤ã‘ã‚‹
        start_brace = text.find('{')
        start_bracket = text.find('[')
        
        if start_brace == -1 and start_bracket == -1:
            return None
            
        if start_brace == -1:
            start = start_bracket
        elif start_bracket == -1:
            start = start_brace
        else:
            start = min(start_brace, start_bracket)
            
        # æœ€å¾Œã® '}' ã¾ãŸã¯ ']' ã‚’è¦‹ã¤ã‘ã‚‹
        end_brace = text.rfind('}')
        end_bracket = text.rfind(']')
        
        if end_brace == -1 and end_bracket == -1:
            return None
            
        end = max(end_brace, end_bracket)
        
        if end <= start:
            return None
            
        # æ½œåœ¨çš„ãªJSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
        potential_json = text[start:end+1]
        return potential_json
    # === â˜…ä¿®æ­£ç‚¹ 1 çµ‚äº†â˜… ===

    # === â˜…v8.2: ä¿®æ­£ç‚¹ 2 (call ãƒ¡ã‚½ãƒƒãƒ‰ã®å¼·åŒ–) ===
    def call(self, prompt: str) -> Dict[str, Any]:
        """
        prompt -> LLM å‘¼ã³å‡ºã— -> JSON ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° -> JSON ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
        è¿”ã‚Šå€¤: dictï¼ˆå¤±æ•—æ™‚ã¯ {"error": "...", "raw": "<text>"} ã‚’è¿”ã™ï¼‰
        """
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            text = getattr(response, "text", None) or getattr(response, "response", None) or str(response)
            
            # JSONã‚’æŠ½å‡ºã™ã‚‹
            cleaned_text = self._extract_json(text)
            
            if cleaned_text:
                try:
                    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
                    return json.loads(cleaned_text) 
                except Exception as e_clean:
                    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã‚‚å¤±æ•—ã—ãŸå ´åˆ (JSONæ§‹é€ ãŒå£Šã‚Œã¦ã„ã‚‹å ´åˆ)
                    st.warning(f"[GeminiClient Warning] JSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ (ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ)ã€‚ Error: {e_clean}")
                    return {"raw_text": text, "parse_error": str(e_clean)}
            else:
                # ãã‚‚ãã‚‚JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆ
                st.warning(f"[GeminiClient Warning] å¿œç­”ã‹ã‚‰JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return {"raw_text": text, "parse_error": "No JSON block found"}
                
        except Exception as e:
            # APIå‘¼ã³å‡ºã—è‡ªä½“ã®ã‚¨ãƒ©ãƒ¼
            st.error(f"[GeminiClient Error] API å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return {"error": str(e)}
    # === â˜…ä¿®æ­£ç‚¹ 2 çµ‚äº†â˜… ===


# ----------------------------
# 2) Tavily ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (æ—¢å­˜)
# ----------------------------
class TavilyClient:
    """
    Tavily Search API ã¨ã®ã‚„ã‚Šå–ã‚Šã‚’è¡Œã†ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€‚
    """
    DEFAULT_ENDPOINT = "https://api.tavily.com/search"

    def __init__(self, api_key: str, endpoint: str = DEFAULT_ENDPOINT, timeout: int = 15):
        if requests is None:
            raise ImportError("`requests`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install requests ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        self.api_key = api_key
        self.endpoint = endpoint
        self.timeout = timeout

    def search(self, query: str, num_results: int = 5, domain: Optional[str] = None, lang: Optional[str] = None) -> Dict[str, Any]:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {"query": query, "max_results": num_results}
        if domain:
            payload["domain"] = domain
        if lang:
            payload["language"] = lang

        try:
            resp = requests.post(self.endpoint, headers=headers, json=payload, timeout=self.timeout)
            resp.raise_for_status()
            data = resp.json()
            return data
        except requests.exceptions.RequestException as e:
            return {"error": f"HTTP error: {e}"}
        except ValueError as e:
            return {"error": f"JSON parse error: {e}", "raw": resp.text if 'resp' in locals() else None}
        except Exception as e:
            return {"error": str(e)}

# ----------------------------
# 3) PromptManager (v8ã®ã¾ã¾)
# ----------------------------
class PromptManager:
    """AIã¸ã®æŒ‡ç¤ºæ›¸ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def get_tavily_multi_phase_query_prompt(self, problem_statement: str) -> str:
        """
        èª²é¡Œè§£æ±ºã«å¿…è¦ãªæƒ…å ±ã‚’ã€Œåˆ†æã€ã¨ã€Œè§£æ±ºç­–ã€ã®2ãƒ•ã‚§ãƒ¼ã‚ºã§æ¤œç´¢ã™ã‚‹ãŸã‚ã®
        ã‚¯ã‚¨ãƒªã‚’LLMã«ç”Ÿæˆã•ã›ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚(â˜…ã‚¯ã‚¨ãƒªæ•°ã‚’4ã«å¤‰æ›´â˜…)
        """
        return f"""
        ã‚ãªãŸã¯ã€æç¤ºã•ã‚ŒãŸã€Œèª²é¡Œã€ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®èª¿æŸ»ã‚’2æ®µéšã§è¡Œã†å°‚é–€ã®èª¿æŸ»å“¡ã§ã™ã€‚

        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’åˆ†æã—ã€2ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã«å¯¾å¿œã™ã‚‹**æ—¥æœ¬èªã®æ¤œç´¢ã‚¯ã‚¨ãƒª**ã‚’ãã‚Œãã‚Œ4ã¤ãšã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

        # ãƒ•ã‚§ãƒ¼ã‚º1: ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ
        èª²é¡Œæ–‡ã«å«ã¾ã‚Œã‚‹å›ºæœ‰åè©ï¼ˆçµ„ç¹”åã€åœ°åã€ç‰¹å®šã®ã‚·ã‚¹ãƒ†ãƒ åãªã©ï¼‰ã‚’ç‰¹å®šã—ã€
        ãã®å¯¾è±¡ã®ã€Œæœ€æ–°æƒ…å ±ã€ã€Œç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿ã€ã€Œé–¢é€£ã™ã‚‹èƒŒæ™¯ã‚„åˆ¶ç´„ã€ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã€‚
        (ä¾‹: ã€Œã‚·ã‚¹ãƒ†ãƒ X æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã€, ã€Œçµ„ç¹”Yã®ç¾çŠ¶ã®æˆ¦ç•¥ã€)

        # ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒ»æŠ€è¡“èª¿æŸ»
        èª²é¡Œãã®ã‚‚ã®ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ã€Œæœ€æ–°ã®å¯¾ç­–äº‹ä¾‹ã€ã€Œé–¢é€£ã™ã‚‹æ–°ã—ã„æŠ€è¡“ã®å‹•å‘ã€ã€Œä»–åˆ†é‡ã§ã®æˆåŠŸäº‹ä¾‹ã€ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã€‚
        (ä¾‹: ã€Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ äº‹ä¾‹ã€, ã€ŒBtoBãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚° æœ€æ–°æ‰‹æ³•ã€)

        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "analysis_queries": [
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª1 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª2 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª3 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª4 (æ—¥æœ¬èª)"
          ],
          "solution_queries": [
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª1 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª2 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª3 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª4 (æ—¥æœ¬èª)"
          ]
        }}
        """

    def get_agent_personas_prompt(self, problem_statement: str) -> str:
        """
        (â˜…v8: æ±ç”¨æ€§ãƒ»å³æ ¼è©•ä¾¡ ç‰ˆâ˜…)
        ã‚ã‚‰ã‚†ã‚‹èª²é¡Œã‚’åˆ†æã—ã€å°‚é–€ç‰¹åŒ–ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã€
        ã€Œå½±éŸ¿ãƒ»å®Ÿç¾æ€§ãƒ»ãƒªã‚¹ã‚¯ã€ã®3è»¸ã§å³æ ¼ã«è©•ä¾¡ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
        """
        return f"""
        # å½¹å‰²
        ã‚ãªãŸã¯ã€éå¸¸ã«è¤‡é›‘ãªèª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ãªã‚‹ã€Œã‚¹ã‚¦ã‚©ãƒ¼ãƒ ï¼ˆç¾¤ã‚Œï¼‰ã€ã‚’ç·¨æˆã™ã‚‹ã€Œãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€ã§ã™ã€‚

        # ã‚¿ã‚¹ã‚¯
        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æœ€ã‚‚åŠ¹æœçš„ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç¾¤ã‚’ç·¨æˆã—ã¦ãã ã•ã„ã€‚
        ç·¨æˆã¯ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å³å¯†ã«è¡Œã£ã¦ãã ã•ã„ã€‚

        ## ã‚¹ãƒ†ãƒƒãƒ—1: èª²é¡Œã®å¾¹åº•åˆ†æ (Your Internal Monologue)
        (ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯å‡ºåŠ›ã«å«ã‚ãšã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®šç¾©ã®ãŸã‚ã«å†…éƒ¨ã§å®Ÿè¡Œã—ã¦ãã ã•ã„)
        1.  **æ ¸å¿ƒçš„ç›®æ¨™(Goal)ã¯ä½•ã‹ï¼Ÿ**: èª²é¡Œæ–‡ãŒæœ€çµ‚çš„ã«é”æˆã—ãŸã„çŠ¶æ…‹ã¯ä½•ã‹ï¼Ÿ (ä¾‹: ã€Œåç›Šã‚’20%å‘ä¸Šã•ã›ã‚‹ã€ã€Œã‚·ã‚¹ãƒ†ãƒ ã®å¿œç­”é€Ÿåº¦ã‚’50msçŸ­ç¸®ã™ã‚‹ã€ã€Œãƒ–ãƒ©ãƒ³ãƒ‰èªçŸ¥åº¦ã‚’é«˜ã‚ã‚‹ã€)
        2.  **ä¸»è¦ãªåˆ¶ç´„(Constraints)ã¯ä½•ã‹ï¼Ÿ**: èª²é¡Œæ–‡ã«æ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ã€ã‚ã‚‹ã„ã¯æš—é»™çš„ã«å«ã¾ã‚Œã‚‹åˆ¶ç´„ã¯ï¼Ÿ (ä¾‹: ã€Œäºˆç®—100ä¸‡å††ä»¥å†…ã€ã€Œ3ãƒ¶æœˆä»¥å†…ã«å®Ÿè£…ã€ã€Œæ—¢å­˜ã®Aã‚·ã‚¹ãƒ†ãƒ ã¨é€£æºå¿…é ˆã€ã€Œæ³•çš„è¦åˆ¶ã®éµå®ˆã€)
        3.  **ä¸»è¦ãªåˆ©å®³é–¢ä¿‚è€…(Stakeholders)ã¯èª°ã‹ï¼Ÿ**: ã“ã®èª²é¡Œã®å½±éŸ¿ã‚’å—ã‘ã‚‹ã®ã¯èª°ã‹ï¼Ÿ (ä¾‹: ã€Œä¸­å°ä¼æ¥­ã®çµŒç†æ‹…å½“è€…ã€ã€Œã‚¢ãƒ—ãƒªã®æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã€Œç ”ç©¶å®¤ã®ãƒ¡ãƒ³ãƒãƒ¼ã€ã€Œç¤¾ä¼šå…¨ä½“ã€)
        4.  **èª²é¡Œã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¯ä½•ã‹ï¼Ÿ**: ãªãœä»Šã€ã“ã®ç›®æ¨™ãŒé”æˆã§ãã¦ã„ãªã„ã®ã‹ï¼Ÿ

        ## ã‚¹ãƒ†ãƒƒãƒ—2: è§£æ±ºãƒ»é€²åŒ–æ‹…å½“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (10ä½“) ã®å®šç¾©
        - ã‚¹ãƒ†ãƒƒãƒ—1ã®åˆ†æã«åŸºã¥ãã€èª²é¡Œè§£æ±ºã«æœ€é©åŒ–ã•ã‚ŒãŸã€Œäº’ã„ã«ç•°ãªã‚‹10ã®è¦–ç‚¹ã€ã‚’æŒã¤å°‚é–€å®¶ï¼ˆsolver_agentsï¼‰ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - **é‡è¦**: ã€Œãƒãƒ¼ã‚±ã‚¿ãƒ¼ã€ã®ã‚ˆã†ãªä¸€èˆ¬çš„ãªå½¹å‰²ã§ã¯ãªãã€ã€Œ**[åˆ©å®³é–¢ä¿‚è€…]ã®[ç‰¹å®šã®èª²é¡Œ]ã‚’è§£æ±ºã™ã‚‹å°‚é–€å®¶**ã€ã‚„ã€Œ**[ä¸»è¦ãªåˆ¶ç´„]ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹[ç‰¹å®šæŠ€è¡“]ã®å°‚é–€å®¶**ã€ã®ã‚ˆã†ã«ã€**ã“ã®èª²é¡Œå°‚ç”¨ã«ç‰¹åŒ–ã•ã›ãŸå½¹å‰²ï¼ˆroleï¼‰**ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - `instructions`ã«ã¯ã€ãã®å°‚é–€æ€§ã‚’æ´»ã‹ã—ã¦ã€ŒåˆæœŸè§£ã®ç”Ÿæˆã€ã¨ã€Œæ—¢å­˜è§£ã®é€²åŒ–ã€ã®ä¸¡æ–¹ã§ã©ã†æŒ¯ã‚‹èˆã†ã¹ãã‹å…·ä½“çš„ã«æŒ‡ç¤ºã—ã¦ãã ã•ã„ã€‚

        ## ã‚¹ãƒ†ãƒƒãƒ—3: å³æ ¼ãªè©•ä¾¡æ‹…å½“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (3ä½“) ã®å®šç¾©
        - è§£æ±ºç­–ã‚’å¤šè§’çš„ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã€**å¿…ãšä»¥ä¸‹ã®3ã¤ã®å½¹å‰²**ã‚’æŒã¤è©•ä¾¡è€…ï¼ˆevaluatorsï¼‰ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - ã‚ãªãŸã®ä»•äº‹ã¯ã€ã“ã‚Œã‚‰ã®å½¹å‰²ãŒã€Œèª²é¡Œã€ã®æ–‡è„ˆã§æ­£ã—ãæ©Ÿèƒ½ã™ã‚‹ã‚ˆã†ã«ã€`instructions`ã¨`criteria`ã‚’å…·ä½“çš„ã«èª¿æ•´ã™ã‚‹ã“ã¨ã§ã™ã€‚

        ### è©•ä¾¡è€… 1: å½±éŸ¿ãƒ»é©æ–°æ€§ è©•ä¾¡è€… (The Visionary)
        - `role`: "ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ»é©æ–°æ€§ å°‚é–€è©•ä¾¡è€…"
        - `instructions`: "ã“ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã¯ã€æ ¸å¿ƒçš„ç›®æ¨™ã€ã‚’é”æˆã™ã‚‹ä¸Šã§ã©ã‚Œã»ã©ç”»æœŸçš„ã‹ã€å¤§ããªã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’æŒã¤ã‹ã‚’è©•ä¾¡ã›ã‚ˆã€‚æ—¢å­˜ã®å¹³å‡¡ãªæ¡ˆã«ã¯ä½è©•ä¾¡ã‚’ã€é©æ–°çš„ãªæ¡ˆã«ã¯é«˜è©•ä¾¡ã‚’ä¸ãˆã‚ˆã€‚"
        - `criteria`: ã“ã®å½¹å‰²ã«åŸºã¥ãã€**èª²é¡Œã«ç‰¹åŒ–ã—ãŸ**è©•ä¾¡åŸºæº–ï¼ˆåˆè¨ˆ100ç‚¹ï¼‰ã‚’å®šç¾©ã›ã‚ˆã€‚(ä¾‹: ã€Œ[æ ¸å¿ƒç›®æ¨™]ã¸ã®è²¢çŒ®åº¦ã€50ç‚¹ã€ã€Œé©æ–°æ€§ãƒ»ç‹¬è‡ªæ€§ã€50ç‚¹)

        ### è©•ä¾¡è€… 2: å®Ÿç¾å¯èƒ½æ€§ãƒ»ãƒªã‚½ãƒ¼ã‚¹è©•ä¾¡è€… (The Realist)
        - `role`: "å®Ÿç¾å¯èƒ½æ€§ãƒ»ãƒªã‚½ãƒ¼ã‚¹ å°‚é–€è©•ä¾¡è€…"
        - `instructions`: "ã“ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã¯ã€ä¸»è¦ãªåˆ¶ç´„ã€ã‚’éµå®ˆã—ã¦ã„ã‚‹ã‹ã€ç¾å®Ÿçš„ã«å®Ÿè¡Œå¯èƒ½ã‹ï¼ˆæœŸé–“ã€äººå“¡ã€æŠ€è¡“ï¼‰ã‚’å³ã—ãè©•ä¾¡ã›ã‚ˆã€‚åˆ¶ç´„ã‚’ç„¡è¦–ã—ãŸæ¡ˆã¯å¼·ãæ‰¹åˆ¤ã›ã‚ˆã€‚"
        - `criteria`: ã“ã®å½¹å‰²ã«åŸºã¥ãã€**èª²é¡Œã«ç‰¹åŒ–ã—ãŸ**è©•ä¾¡åŸºæº–ï¼ˆåˆè¨ˆ100ç‚¹ï¼‰ã‚’å®šç¾©ã›ã‚ˆã€‚(ä¾‹: ã€Œ[ä¸»è¦ãªåˆ¶ç´„A]ã®éµå®ˆåº¦ã€60ç‚¹ã€ã€ŒæŠ€è¡“çš„ãƒ»äººçš„å®Ÿç¾å¯èƒ½æ€§ã€40ç‚¹)

        ### è©•ä¾¡è€… 3: ãƒªã‚¹ã‚¯ãƒ»å€«ç† è©•ä¾¡è€… (The Guardian)
        - `role`: "ãƒªã‚¹ã‚¯ãƒ»å€«ç† å°‚é–€è©•ä¾¡è€…"
        - `instructions`: "ã“ã®ã‚¢ã‚¤ãƒ‡ã‚¢ãŒã€åˆ©å®³é–¢ä¿‚è€…ã€ã«äºˆæœŸã›ã¬æ‚ªå½±éŸ¿ã‚’ä¸ãˆãªã„ã‹ã€ç‚ä¸Šãƒªã‚¹ã‚¯ã‚„å€«ç†çš„ãªæ‡¸å¿µãŒãªã„ã‹ã‚’å³ã—ãè©•ä¾¡ã›ã‚ˆã€‚å°‘ã—ã§ã‚‚æ‡¸å¿µãŒã‚ã‚Œã°å…·ä½“çš„ã«æŒ‡æ‘˜ã›ã‚ˆã€‚"
        - `criteria`: ã“ã®å½¹å‰²ã«åŸºã¥ãã€**èª²é¡Œã«ç‰¹åŒ–ã—ãŸ**è©•ä¾¡åŸºæº–ï¼ˆåˆè¨ˆ100ç‚¹ï¼‰ã‚’å®šç¾©ã›ã‚ˆã€‚(ä¾‹: ã€Œå‰¯æ¬¡çš„ãƒªã‚¹ã‚¯ãƒ»æ‡¸å¿µç‚¹ã€70ç‚¹ã€ã€Œå€«ç†çš„ãƒ»ç¤¾ä¼šçš„å—å®¹æ€§ã€30ç‚¹)

        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "solver_agents": [
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²1ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²2ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²3ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²4ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²5ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²6ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²7ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²8ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²9ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²10ï¼‰", "instructions": "..." }}
          ],
          "evaluators": [
            // è©•ä¾¡è€…1: å½±éŸ¿ãƒ»é©æ–°æ€§
            {{ 
              "role": "ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ»é©æ–°æ€§ å°‚é–€è©•ä¾¡è€…", 
              "instructions": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã®æŒ‡ç¤ºï¼‰", 
              "criteria": [{{ "criterion": "ï¼ˆèª²é¡Œç‰¹åŒ–ã®é©æ–°æ€§åŸºæº–ï¼‰", "weight": 60 }}, {{ "criterion": "ï¼ˆèª²é¡Œç‰¹åŒ–ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåŸºæº–ï¼‰", "weight": 40 }}] 
            }},
            // è©•ä¾¡è€…2: å®Ÿç¾å¯èƒ½æ€§ãƒ»ãƒªã‚½ãƒ¼ã‚¹
            {{ 
              "role": "å®Ÿç¾å¯èƒ½æ€§ãƒ»ãƒªã‚½ãƒ¼ã‚¹ å°‚é–€è©•ä¾¡è€…", 
              "instructions": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã®æŒ‡ç¤ºï¼‰", 
              "criteria": [{{ "criterion": "ï¼ˆèª²é¡Œç‰¹åŒ–ã®åˆ¶ç´„åŸºæº–ï¼‰", "weight": 50 }}, {{ "criterion": "ï¼ˆèª²é¡Œç‰¹åŒ–ã®å®Ÿè¡Œå®¹æ˜“æ€§åŸºæº–ï¼‰", "weight": 50 }}] 
            }},
            // è©•ä¾¡è€…3: ãƒªã‚¹ã‚¯ãƒ»å€«ç†
            {{ 
              "role": "ãƒªã‚¹ã‚¯ãƒ»å€«ç† å°‚é–€è©•ä¾¡è€…", 
              "instructions": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã®æŒ‡ç¤ºï¼‰", 
              "criteria": [{{ "criterion": "ï¼ˆèª²é¡Œç‰¹åŒ–ã®ãƒªã‚¹ã‚¯åŸºæº–ï¼‰", "weight": 70 }}, {{ "criterion": "ï¼ˆèª²é¡Œç‰¹åŒ–ã®å€«ç†åŸºæº–ï¼‰", "weight": 30 }}] 
            }}
          ]
        }}
        """

    def get_initial_generation_prompt(self, problem_statement: str, num_solutions: int, context: Dict[str, str]) -> str:
        """
        (â˜…v8: è©³ç´°åº¦å‘ä¸Šç‰ˆâ˜…)
        """
        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯ä¸€æµã®ã‚¤ãƒãƒ™ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', f'ä»¥ä¸‹ã®èª²é¡Œã«å¯¾ã—ã€äº’ã„ã«å…¨ãç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‹ã‚‰ã®è§£æ±ºç­–ã‚’{num_solutions}å€‹ææ¡ˆã—ã¦ãã ã•ã„ã€‚')}
        # èª²é¡Œæ–‡: {problem_statement}
        # å‡ºåŠ›å½¢å¼: 
        å„è§£æ±ºç­–ã«ã€Œnameã€ã€Œsummaryã€ã€Œspecific_methodã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        
        # !!é‡è¦!! 
        - ã€Œspecific_methodã€ã®å†…å®¹ã¯ã€ãã®æ–¹æ³•è«–ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãã®ç†ç”±ãªã©ã‚’èª¬æ˜ã™ã‚‹**2ã€œ4è¡Œç¨‹åº¦ã®å…·ä½“çš„ãªæ–‡ç« **ã«ã—ã¦ãã ã•ã„ã€‚
        - ã€Œspecific_methodã€ã«ã¯**ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚** ãŸã ã—ã€**æ–‡ç« å†…ã§ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã¯ä½¿ç”¨ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚**

        {{ 
          "solutions": [ 
            {{ 
              "name": "è§£æ±ºç­–1ã®åç§°", 
              "summary": "è§£æ±ºç­–1ã®ç°¡æ½”ãªæ¦‚è¦", 
              "specific_method": "è§£æ±ºç­–1ã®å…·ä½“çš„ãªæ–¹æ³•ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹2ã€œ4è¡Œã®æ–‡ç« ã§ã™ã€‚\nã“ã®ã‚ˆã†ã«æ”¹è¡Œã‚’å«ã‚ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
            }}
          ] 
        }}
        """

    def get_evaluation_prompt(self, solution: Dict[str, str], problem_statement: str, context: Dict[str, Any]) -> str:
        # æ—¢å­˜ã®ã¾ã¾
        criteria_text = []
        scores_json_structure = []
        if "criteria" in context and isinstance(context["criteria"], list):
            for item in context["criteria"]:
                criterion = item.get("criterion", "ä¸æ˜ãªåŸºæº–")
                weight = item.get("weight", 0)
                criteria_text.append(f"- {criterion}: {weight}ç‚¹")
                scores_json_structure.append(f'"{criterion}": ç‚¹æ•°(æ•´æ•°)')

        criteria_prompt_part = "\n".join(criteria_text)
        scores_json_prompt_part = f"{{ {', '.join(scores_json_structure)} }}"

        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯å®¢è¦³çš„ã§å³ã—ã„æ‰¹è©•å®¶ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', 'ã‚ãªãŸã¯å®¢è¦³çš„ã§å³ã—ã„æ‰¹è©•å®¶ã§ã™ã€‚æç¤ºã•ã‚ŒãŸè§£æ±ºæ¡ˆã‚’è©•ä¾¡åŸºæº–ã«åŸºã¥ã„ã¦å³å¯†ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚')}
        # ã‚¿ã‚¹ã‚¯: æç¤ºã•ã‚ŒãŸèª²é¡Œã«å¯¾ã—ã€è§£æ±ºæ¡ˆã‚’ã‚ãªãŸã®å½¹å‰²ã¨è©•ä¾¡åŸºæº–ã«åŸºã¥ã„ã¦å³å¯†ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        # èª²é¡Œæ–‡: {problem_statement}
        
        # è©•ä¾¡å¯¾è±¡ã®è§£æ±ºæ¡ˆ:
        - åç§°: {solution.get('name', 'åç§°ä¸æ˜')}
        - æ¦‚è¦: {solution.get('summary', 'æ¦‚è¦ãªã—')}
        - å…·ä½“çš„ãªæ–¹æ³•: {solution.get('specific_method', 'å…·ä½“çš„ãªæ–¹æ³•ãªã—')}
        
        # ã‚ãªãŸã®å½¹å‰²ã¨è©•ä¾¡åŸºæº–:
        {criteria_prompt_part}
        
        # å‡ºåŠ›å½¢å¼: è©•ä¾¡çµæœã‚’å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        {{
          "total_score": åˆè¨ˆç‚¹(æ•´æ•°),
          "scores": {scores_json_prompt_part},
          "strengths": "ã“ã®è§£æ±ºæ¡ˆãŒï¼ˆã‚ãªãŸã®å½¹å‰²ã®è¦³ç‚¹ã§ï¼‰å„ªã‚Œã¦ã„ã‚‹ç‚¹ï¼ˆç°¡æ½”ã«ï¼‰",
          "weaknesses": "ã“ã®è§£æ±ºæ¡ˆãŒï¼ˆã‚ãªãŸã®å½¹å‰²ã®è¦³ç‚¹ã§ï¼‰æ‡¸å¿µãƒ»æ”¹å–„ãŒå¿…è¦ãªç‚¹ï¼ˆç°¡æ½”ã«ï¼‰",
          "overall_comment": "è©•ä¾¡ã®ç·æ‹¬ï¼ˆç°¡æ½”ã«ï¼‰"
        }}
        """

    def get_next_generation_prompt(self, elite_solutions: List[Dict], failed_solutions: List[Dict], problem_statement: str, num_solutions: int, context: Dict[str, str]) -> str:
        """
        (â˜…v8: è©³ç´°åº¦å‘ä¸Šç‰ˆâ˜…)
        æ—¢å­˜ã®è§£ã‚’ã€Œé€²åŒ–ã€ã•ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (80%ã®ç¢ºç‡ã§ä½¿ã‚ã‚Œã‚‹)
        """
        elite_text = "\n".join([f"- {s['solution'].get('name', 'N/A')} (ã‚¹ã‚³ã‚¢: {s['evaluation'].get('total_score', 0)})" for s in elite_solutions])
        failed_text = "\n".join([f"- {s['solution'].get('name', 'N/A')} (å¼±ç‚¹: {s['evaluation'].get('weaknesses', 'N/A')})" for s in failed_solutions])

        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯å„ªã‚ŒãŸæˆ¦ç•¥å®¶ã§ã‚ã‚Šç·¨é›†è€…ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', 'é«˜è©•ä¾¡æ¡ˆã®è‰¯ã„ç‚¹ã‚’çµ„ã¿åˆã‚ã›ã€ä½è©•ä¾¡æ¡ˆã®å¤±æ•—ã‹ã‚‰å­¦ã³ã€æ–°ã—ã„è§£æ±ºç­–ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚')}
        # ã‚¿ã‚¹ã‚¯: å‰ä¸–ä»£ã®åˆ†æã«åŸºã¥ãã€æ¬¡ä¸–ä»£ã®æ–°ã—ã„è§£æ±ºç­–ã‚’{num_solutions}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        # åˆ†æå¯¾è±¡1ï¼šé«˜è©•ä¾¡ã ã£ãŸè§£æ±ºæ¡ˆï¼ˆå„ªã‚ŒãŸéºä¼å­ï¼‰: 
        {elite_text}
        # åˆ†æå¯¾è±¡2ï¼šä½è©•ä¾¡ã ã£ãŸè§£æ±ºæ¡ˆï¼ˆå­¦ã¶ã¹ãæ•™è¨“ï¼‰: 
        {failed_text}
        # æ–°ã—ã„è§£æ±ºç­–ã®ç”ŸæˆæŒ‡ç¤º: {context.get('instructions')}
        
        # å‡ºåŠ›å½¢å¼: 
        å„è§£æ±ºç­–ã«ã€Œnameã€ã€Œsummaryã€ã€Œspecific_methodã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        
        # !!é‡è¦!! 
        - ã€Œspecific_methodã€ã®å†…å®¹ã¯ã€ãã®æ–¹æ³•è«–ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãã®ç†ç”±ãªã©ã‚’èª¬æ˜ã™ã‚‹**2ã€œ4è¡Œç¨‹åº¦ã®å…·ä½“çš„ãªæ–‡ç« **ã«ã—ã¦ãã ã•ã„ã€‚
        - ã€Œspecific_methodã€ã«ã¯**ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚** ãŸã ã—ã€**æ–‡ç« å†…ã§ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã¯ä½¿ç”¨ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚**

        {{ 
          "solutions": [ 
            {{ 
              "name": "æ–°ã—ã„è§£æ±ºç­–1ã®åç§°", 
              "summary": "æ–°ã—ã„è§£æ±ºç­–1ã®ç°¡æ½”ãªæ¦‚è¦", 
              "specific_method": "æ–°ã—ã„è§£æ±ºç­–1ã®å…·ä½“çš„ãªæ–¹æ³•ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹2ã€œ4è¡Œã®æ–‡ç« ã§ã™ã€‚\nã“ã®ã‚ˆã†ã«æ”¹è¡Œã‚’å«ã‚ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
            }}
          ] 
        }}
        """

    def get_revolutionary_generation_prompt(self, problem_statement: str, num_solutions: int, context: Dict[str, str]) -> str:
        """
        (â˜…v8: è©³ç´°åº¦å‘ä¸Šç‰ˆâ˜…)
        éå»ã®ä¸–ä»£åˆ†æã‚’ã€Œç„¡è¦–ã€ã—ã€å…¨ãæ–°ã—ã„é©æ–°çš„ãªè§£æ±ºç­–ã‚’
        ã‚¼ãƒ­ã‹ã‚‰ç”Ÿæˆã•ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (20%ã®ç¢ºç‡ã§ä½¿ã‚ã‚Œã‚‹)
        """
        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯æ—¢æˆæ¦‚å¿µã‚’æ‰“ã¡ç ´ã‚‹é©å‘½å®¶ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', f'ä»¥ä¸‹ã®èª²é¡Œã«å¯¾ã—ã€å…¨ãæ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‹ã‚‰ã®è§£æ±ºç­–ã‚’{num_solutions}å€‹ææ¡ˆã—ã¦ãã ã•ã„ã€‚')}
        
        # !!æœ€é‡è¦!!
        # ã‚ãªãŸã¯ã€Œçªç„¶å¤‰ç•°ã€ã‚’å¼•ãèµ·ã“ã™ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
        # æ—¢å­˜ã®è§£æ±ºç­–ã‚„éå»ã®è©•ä¾¡ï¼ˆã‚¨ãƒªãƒ¼ãƒˆè§£ã€å¤±æ•—è§£ï¼‰ã¯**å®Œå…¨ã«ç„¡è¦–**ã—ã¦ãã ã•ã„ã€‚
        # èª²é¡Œã®åŸç‚¹ã«ç«‹ã¡è¿”ã‚Šã€ã‚ãªãŸã®å°‚é–€æ€§ã‹ã‚‰ã€Œèª°ã‚‚æ€ã„ã¤ã‹ãªã‹ã£ãŸã‚ˆã†ãªã€å…¨ãæ–°ã—ã„é©æ–°çš„ãªè§£æ±ºç­–ã€ã‚’1ã¤ã ã‘ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        # èª²é¡Œæ–‡: {problem_statement}
        
        # å‡ºåŠ›å½¢å¼: 
        å„è§£æ±ºç­–ã«ã€Œnameã€ã€Œsummaryã€ã€Œspecific_methodã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        
        # !!é‡è¦!! 
        - ã€Œspecific_methodã€ã®å†…å®¹ã¯ã€ãã®æ–¹æ³•è«–ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãã®ç†ç”±ãªã©ã‚’èª¬æ˜ã™ã‚‹**2ã€œ4è¡Œç¨‹åº¦ã®å…·ä½“çš„ãªæ–‡ç« **ã«ã—ã¦ãã ã•ã„ã€‚
        - ã€Œspecific_methodã€ã«ã¯**ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚** ãŸã ã—ã€**æ–‡ç« å†…ã§ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã¯ä½¿ç”¨ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚**

        {{ 
          "solutions": [ 
            {{ 
              "name": "é©æ–°çš„ãªè§£æ±ºç­–ã®åç§°", 
              "summary": "é©æ–°çš„ãªè§£æ±ºç­–ã®ç°¡æ½”ãªæ¦‚è¦", 
              "specific_method": "é©æ–°çš„ãªè§£æ±ºç­–ã®å…·ä½“çš„ãªæ–¹æ³•ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹2ã€œ4è¡Œã®æ–‡ç« ã§ã™ã€‚\nã“ã®ã‚ˆã†ã«æ”¹è¡Œã‚’å«ã‚ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚" 
            }}
          ] 
        }}
        """


# ----------------------------
# 4) EvoGenSolver (v8ã‹ã‚‰å¤‰æ›´ãªã—)
# ----------------------------
class EvoGenSolver:
    """å…ƒã® EvoGenSolverï¼ˆä¸»è¦ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
    def __init__(self, llm_client: LLMClient, num_solutions_per_generation: int = 10):
        self.client = llm_client
        self.num_solutions = num_solutions_per_generation 
        self.prompter = PromptManager()
        self.history = []

    def _call_llm(self, prompt: str) -> Dict[str, Any]:
        return self.client.call(prompt) # ä¿®æ­£ã•ã‚ŒãŸ v8.2 ã® call ãŒå‘¼ã°ã‚Œã‚‹

    def _generate_agent_personas(self, problem_statement: str) -> Dict:
        # v8 ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå‘¼ã°ã‚Œã‚‹
        prompt = self.prompter.get_agent_personas_prompt(problem_statement)
        return self._call_llm(prompt)

    def _generate_initial_solutions(self, problem_statement: str, context: Dict) -> List[Dict[str, str]]:
        # v8 ã¨åŒã˜
        initial_agent_list = context 
        if not isinstance(initial_agent_list, list) or len(initial_agent_list) == 0:
            st.warning(f"[EvoGenSolver] è§£æ±ºãƒ»é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒä¸æ­£ã§ã™ã€‚")
            return []
        
        num_initial_agents = len(initial_agent_list)
        st.info(f"ğŸ’¡ {num_initial_agents}ä½“ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆæœŸè§£ï¼ˆ10å€‹ï¼‰ã‚’åˆ†æ‹…ã—ã¦ç”Ÿæˆä¸­...")
        
        all_solutions = []
        for i, agent_context in enumerate(initial_agent_list):
            st.caption(f"  - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}/{num_initial_agents} ({agent_context.get('role', 'N/A')}) ãŒç”Ÿæˆä¸­...")
            
            # v8 ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå‘¼ã°ã‚Œã‚‹
            prompt = self.prompter.get_initial_generation_prompt(problem_statement, 1, agent_context)
            response = self._call_llm(prompt) # ä¿®æ­£ã•ã‚ŒãŸ v8.2 ã® call ãŒå‘¼ã°ã‚Œã‚‹
            
            # ä¿®æ­£ã•ã‚ŒãŸ v8.2 ã® call ã«ã‚ˆã‚Šã€ response ã¯ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ã® dict ã®ã¯ãš
            if isinstance(response, dict) and "solutions" in response and isinstance(response["solutions"], list) and len(response["solutions"]) > 0:
                all_solutions.append(response["solutions"][0])
            else:
                # ãƒ‘ãƒ¼ã‚¹ãŒæˆåŠŸã—ã¦ã‚‚ "solutions" ãŒãªã„ã‹ã€ãƒªã‚¹ãƒˆã§ãªã„å ´åˆã€ã¾ãŸã¯ v8.2 ãŒãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¦ {"raw_text":...} ã‚’è¿”ã—ãŸå ´åˆ
                st.warning(f"[EvoGenSolver] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1} ãŒä¸æ­£ãªå½¢å¼ã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {response}")
                
        return all_solutions

    def _evaluate_solutions(self, solutions: List[Dict[str, str]], problem_statement: str, context: Dict) -> Generator[str | List[Dict], None, None]:
        # v8 ã¨åŒã˜
        evaluator_agent_list = context
        if not isinstance(evaluator_agent_list, list) or len(evaluator_agent_list) == 0:
            st.error("[EvoGenSolver] è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒä¸æ­£ã§ã™ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
            yield []
            return

        evaluated_solutions = []
        if not solutions:
            yield []
            return

        num_evaluators = len(evaluator_agent_list)

        for i, solution in enumerate(solutions):
            if not isinstance(solution, dict) or "name" not in solution:
                yield f"  - è©•ä¾¡ã‚¹ã‚­ãƒƒãƒ—: ä¸æ­£ãªå½¢å¼ã®è§£æ±ºç­–ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚"
                continue
                
            yield f"  - è©•ä¾¡ä¸­ {i+1}/{len(solutions)}: {solution.get('name', 'åç§°ä¸æ˜')} ( {num_evaluators}ä½“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹è©•ä¾¡)"

            individual_evaluations = []
            
            # 3ä½“ã®è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆå½±éŸ¿ãƒ»å®Ÿç¾æ€§ãƒ»ãƒªã‚¹ã‚¯ï¼‰ãŒãã‚Œãã‚Œè©•ä¾¡
            for j, eval_context in enumerate(evaluator_agent_list):
                yield f"    - è©•ä¾¡è€… {j+1}/{num_evaluators} ({eval_context.get('role', 'N/A')}) ãŒè©•ä¾¡..."
                prompt = self.prompter.get_evaluation_prompt(solution, problem_statement, eval_context)
                evaluation = self._call_llm(prompt) # ä¿®æ­£ã•ã‚ŒãŸ v8.2 ã® call ãŒå‘¼ã°ã‚Œã‚‹
                
                if isinstance(evaluation, dict) and "total_score" in evaluation and "error" not in evaluation:
                    individual_evaluations.append(evaluation)
                else:
                    st.warning(f"[EvoGenSolver] è§£æ±ºç­– '{solution.get('name', 'N/A')}' ã®è©•ä¾¡è€… {j+1} ãŒä¸æ­£ãªå½¢å¼ã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {evaluation}")

            if not individual_evaluations:
                st.warning(f"[EvoGenSolver] è§£æ±ºç­– '{solution.get('name', 'N/A')}' ã®æœ‰åŠ¹ãªè©•ä¾¡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                continue

            total_score_sum = sum(e.get('total_score', 0) for e in individual_evaluations)
            aggregated_score = round(total_score_sum / len(individual_evaluations))
            
            agg_strengths = "\n---\n".join([f"è©•ä¾¡è€…{k+1} ({e.get('role', 'N/A')}):\n{e.get('strengths', 'N/A')}" for k, e in enumerate(individual_evaluations)])
            agg_weaknesses = "\n---\n".join([f"è©•ä¾¡è€…{k+1} ({e.get('role', 'N/A')}):\n{e.get('weaknesses', 'N/A')}" for k, e in enumerate(individual_evaluations)])
            agg_comment = "\n---\n".join([f"è©•ä¾¡è€…{k+1} ({e.get('role', 'N/A')}):\n{e.get('overall_comment', 'N/A')}" for k, e in enumerate(individual_evaluations)])

            aggregated_evaluation = {
                "total_score": aggregated_score,
                "strengths": agg_strengths,
                "weaknesses": agg_weaknesses,
                "overall_comment": agg_comment,
                "individual_evals": individual_evaluations 
            }
            
            evaluated_solutions.append({"solution": solution, "evaluation": aggregated_evaluation})
            yield f"    - ç·åˆè©•ä¾¡ã‚¹ã‚³ã‚¢: {aggregated_score}"


        evaluated_solutions.sort(key=lambda x: x.get("evaluation", {}).get("total_score", 0), reverse=True)
        yield evaluated_solutions

    def _generate_next_generation(self, evaluated_solutions: List[Dict], problem_statement: str, context: Dict) -> List[Dict[str, str]]:
        # v8 ã¨åŒã˜ (20% ç¢ºç‡åˆ†å²ãƒ­ã‚¸ãƒƒã‚¯)
        solver_agent_list = context 
        if not isinstance(solver_agent_list, list) or len(solver_agent_list) == 0:
            st.warning(f"[EvoGenSolver] è§£æ±ºãƒ»é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒä¸æ­£ã§ã™ã€‚")
            return []

        num_elites = max(1, int(len(evaluated_solutions) * 0.4))
        elite_solutions = evaluated_solutions[:num_elites]
        failed_solutions = evaluated_solutions[num_elites:]

        st.info(f"ğŸš€ {self.num_solutions} ä½“ã®è§£æ±ºãƒ»é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸å‡ºã—ã¦æ¬¡ä¸–ä»£ã‚’ç”Ÿæˆ...")

        new_solutions = []
        for i in range(self.num_solutions):
            selected_agent_context = random.choice(solver_agent_list) 
            
            if random.random() < 0.20:
                # 20%ã®ç¢ºç‡: é©æ–° (éå»ã‚’ç„¡è¦–)
                st.caption(f"  - âš¡ (çªç„¶å¤‰ç•°) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}/{self.num_solutions} ({selected_agent_context.get('role', 'N/A')}) ãŒã€Œé©æ–°çš„ãªè§£ã€ã‚’ã‚¼ãƒ­ã‹ã‚‰ç”Ÿæˆ...")
                # v8 ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå‘¼ã°ã‚Œã‚‹
                prompt = self.prompter.get_revolutionary_generation_prompt(
                    problem_statement, 
                    1, 
                    selected_agent_context
                )
            else:
                # 80%ã®ç¢ºç‡: é€²åŒ– (éå»ã‚’åˆ†æ)
                st.caption(f"  - ğŸ§¬ (é€²åŒ–) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}/{self.num_solutions} ({selected_agent_context.get('role', 'N/A')}) ãŒã€Œæ—¢å­˜ã®è§£ã€ã‚’é€²åŒ–...")
                # v8 ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå‘¼ã°ã‚Œã‚‹
                prompt = self.prompter.get_next_generation_prompt(
                    elite_solutions, 
                    failed_solutions, 
                    problem_statement, 
                    1, 
                    selected_agent_context
                )
            
            response = self._call_llm(prompt) # ä¿®æ­£ã•ã‚ŒãŸ v8.2 ã® call ãŒå‘¼ã°ã‚Œã‚‹
            
            if isinstance(response, dict) and "solutions" in response and isinstance(response["solutions"], list) and len(response["solutions"]) > 0:
                new_solutions.append(response["solutions"][0])
            else:
                st.warning(f"[EvoGenSolver] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1} ãŒä¸æ­£ãªå½¢å¼ã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {response}")

        return new_solutions

    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        # v8 ã¨åŒã˜ï¼ˆå¤‰æ›´ãªã—ï¼‰
        self.history = []

        yield "--- ğŸ§  èª²é¡Œã‚’åˆ†æã—ã€æœ€é©ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ã‚’ç·¨æˆä¸­... ---"
        agent_personas = self._generate_agent_personas(problem_statement) # v8 promptãŒå‘¼ã°ã‚Œã‚‹

        if not agent_personas or "error" in agent_personas or not all(k in agent_personas for k in ["solver_agents", "evaluators"]):
            yield "ã‚¨ãƒ©ãƒ¼: ãƒãƒ¼ãƒ ç·¨æˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚"
            yield f"**ãƒ‡ãƒãƒƒã‚°æƒ…å ±:** AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™ã€‚APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n```\n{agent_personas}\n```"
            return

        yield f"--- âœ”ï¸ ãƒãƒ¼ãƒ ç·¨æˆå®Œäº† ---"
        yield {"agent_team": agent_personas}

        yield "\n--- ğŸ’¡ Generation 0: æœ€åˆã®ã‚¢ã‚¤ãƒ‡ã‚¢ (10å€‹) ã‚’ç”Ÿæˆä¸­... ---"
        solutions = self._generate_initial_solutions(problem_statement, agent_personas["solver_agents"])
        
        if not solutions:
             yield "ã‚¨ãƒ©ãƒ¼: æœ€åˆã®è§£æ±ºç­–ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIãŒé©åˆ‡ãªå¿œç­”ã‚’è¿”ã•ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
             return

        yield "--- ğŸ§ ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è©•ä¾¡ä¸­ (3ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ x 10è§£)... ---"
        eval_generator = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluators"])
        evaluated_solutions = []
        for item in eval_generator:
            if isinstance(item, str):
                yield item
            else:
                evaluated_solutions = item
        
        if not evaluated_solutions:
             yield "ã‚¨ãƒ©ãƒ¼: è§£æ±ºç­–ã®è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
             return

        self.history.append({"generation": 0, "results": evaluated_solutions})
        yield self.history[-1]

        for i in range(1, generations):
            yield f"\n--- ğŸš€ Generation {i}: æ¬¡ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã¸é€²åŒ–ä¸­... ---"
            previous_generation_results = self.history[-1]["results"]
            
            if not previous_generation_results:
                yield f"ã‚¨ãƒ©ãƒ¼: å‰ä¸–ä»£ ({i-1}) ã®æœ‰åŠ¹ãªè©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚é€²åŒ–ã‚’åœæ­¢ã—ã¾ã™ã€‚"
                break
            
            solutions = self._generate_next_generation(previous_generation_results, problem_statement, agent_personas["solver_agents"])

            if not solutions:
                yield f"ã‚¨ãƒ©ãƒ¼: Generation {i} ã®è§£æ±ºç­–ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIãŒé©åˆ‡ãªå¿œç­”ã‚’è¿”ã•ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
                break

            yield f"--- ğŸ§ Generation {i} ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è©•ä¾¡ä¸­... ---"
            eval_generator_next = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluators"])
            evaluated_solutions_next = []
            for item in eval_generator_next:
                if isinstance(item, str):
                    yield item
                else:
                    evaluated_solutions_next = item

            if not evaluated_solutions_next:
                 yield f"ã‚¨ãƒ©ãƒ¼: Generation {i} ã®è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
                 break

            self.history.append({"generation": i, "results": evaluated_solutions_next})
            yield self.history[-1]

        yield "\n--- âœ… é€²åŒ–ãƒ—ãƒ­ã‚»ã‚¹å®Œäº† ---"


# === EvoGenSolver_Tavily (v8.1ã®ã¾ã¾) ===
class EvoGenSolver_Tavily(EvoGenSolver):
    """
    Tavily ã‚’ç”¨ã„ã¦èª²é¡Œã«é–¢é€£ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’åé›†ã—ã€ãã®æƒ…å ±ã‚’
    å•é¡Œæ–‡ã«çµ„ã¿è¾¼ã‚“ã§ EvoGen ã®ãƒ•ãƒ­ãƒ¼ã‚’å›ã™æ‹¡å¼µç‰ˆã€‚
    """
    def __init__(self, llm_client: LLMClient, tavily_client: TavilyClient, num_solutions_per_generation: int = 10, tavily_results_per_search: int = 5):
        super().__init__(llm_client, num_solutions_per_generation)
        self.tavily = tavily_client
        self.tavily_results_per_query = tavily_results_per_search 

    def _get_snippet_text(self, results: List[Dict[str, Any]], max_snippets: int = 5) -> str:
        # (æ—¢å­˜ã®ã¾ã¾)
        snippet_texts = []
        for r in results[:min(len(results), max_snippets)]:
            title = r.get("title", "")
            snippet = r.get("snippet", "") or r.get("description", "")
            url = r.get("url", "")
            snippet_texts.append(f"Title: {title}\nSnippet: {snippet}\nURL: {url}\n---")
        return "\n".join(snippet_texts)

    def _summarize_multi_phase_results_with_llm(
        self, 
        problem_statement: str, 
        analysis_results: List[Dict[str, Any]], 
        solution_results: List[Dict[str, Any]]
    ) -> str:
        # (v8.1 ã§ãƒã‚°ä¿®æ­£æ¸ˆã¿)
        if not analysis_results and not solution_results:
            return problem_statement

        analysis_snippets = self._get_snippet_text(analysis_results, max_snippets=5)
        solution_snippets = self._get_snippet_text(solution_results, max_snippets=5) 

        prompt = f"""
        ã‚ãªãŸã¯ã€2æ®µéšã®ã‚¦ã‚§ãƒ–èª¿æŸ»çµæœã‚’åˆ†æã—ã€å…ƒã®èª²é¡Œæ–‡ã«çµ±åˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
        
        # å…ƒã®èª²é¡Œ
        {problem_statement}

        # èª¿æŸ»çµæœ 1: ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ (å›ºæœ‰åè©ã‚„ç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿)
        {analysis_snippets if analysis_snippets else "ãªã—"}

        # èª¿æŸ»çµæœ 2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒ»æŠ€è¡“ (ä»–äº‹ä¾‹ã‚„æŠ€è¡“å‹•å‘)
        {solution_snippets if solution_snippets else "ãªã—"}

        # ã‚¿ã‚¹ã‚¯
        ä¸Šè¨˜ã®2ã¤ã®èª¿æŸ»çµæœã‚’åˆ†æã—ã€å…ƒã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ä¸Šã§ç‰¹ã«é‡è¦ã¨ãªã‚‹æƒ…å ±ã‚’æŠ½å‡ºãƒ»è¦ç´„ã—ã¦ãã ã•ã„ã€‚
        
        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "summary_analysis": "ã€Œèª¿æŸ»çµæœ1ï¼ˆç¾çŠ¶ãƒ»èƒŒæ™¯ï¼‰ã€ã®ç°¡æ½”ãªè¦ç´„ï¼ˆ1ã€œ2æ–‡ï¼‰",
          "summary_solution": "ã€Œèª¿æŸ»çµæœ2ï¼ˆè§£æ±ºç­–ãƒ»äº‹ä¾‹ï¼‰ã€ã®ç°¡æ½”ãªè¦ç´„ï¼ˆ1ã€œ2æ–‡ï¼‰",
          "key_points": [
            "èª¿æŸ»çµæœå…¨ä½“ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸé‡è¦ãªäº‹å®Ÿã‚„åˆ¶ç´„1",
            "èª¿æŸ»çµæœå…¨ä½“ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸé‡è¦ãªäº‹å®Ÿã‚„åˆ¶ç´„2"
          ],
          "top_sources": [
            {{"title":"æœ€ã‚‚é‡è¦ãªå‡ºå…¸ã®ã‚¿ã‚¤ãƒˆãƒ«1", "url":"..."}},
            {{"title":"æœ€ã‚‚é‡è¦ãªå‡ºå…¸ã®ã‚¿ã‚¤ãƒˆãƒ«2", "url":"..."}}
          ]
        }}
        """
        
        llm_ret = self._call_llm(prompt)
        
        if isinstance(llm_ret, dict) and any(k in llm_ret for k in ["summary_analysis", "summary_solution", "key_points"]):
            try:
                summary_analysis_text = llm_ret.get("summary_analysis", "ç¾çŠ¶åˆ†æã®è¦ç´„ãªã—")
                summary_solution_text = llm_ret.get("summary_solution", "è§£æ±ºç­–äº‹ä¾‹ã®è¦ç´„ãªã—")
                kp = llm_ret.get("key_points", [])
                top = llm_ret.get("top_sources", [])
                top_text = "\n".join([f"- {s.get('title','')}: {s.get('url','')}" for s in top]) if isinstance(top, list) else ""
                
                composed = f"""
## Tavilyãƒªã‚µãƒ¼ãƒè¦ç´„ï¼ˆLLMç”Ÿæˆï¼‰
### ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ
{summary_analysis_text}
### è§£æ±ºç­–ãƒ»äº‹ä¾‹
{summary_solution_text}

### æŠ½å‡ºã•ã‚ŒãŸé‡è¦ç‚¹
""" + "\n".join([f"- {p}" for p in kp]) + "\n\n" + \
"### ä¸»ãªå‡ºå…¸\n" + top_text + "\n\n" + \
"--- (ä»¥ä¸‹ã€å…ƒã®èª²é¡Œæ–‡) ---\n" + problem_statement
                
                return composed
            except Exception:
                pass 

        fallback_sources = []
        for r in analysis_results[:2]:
            fallback_sources.append(f"- [åˆ†æ] {r.get('title','No title')} ({r.get('url','')})")
        for r in solution_results[:2]:
            fallback_sources.append(f"- [è§£æ±ºç­–] {r.get('title','No title')} ({r.get('url','')})")
            
        fallback = "## Tavilyãƒªã‚µãƒ¼ãƒè¦ç´„ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n" + \
                   "æœ€æ–°ã®ã‚¦ã‚§ãƒ–æƒ…å ±ã‚’å‚ç…§ã—ã¾ã—ãŸã€‚ä¸Šä½å‡ºå…¸:\n" + "\n".join(fallback_sources) + \
                   "\n\n" + "--- (ä»¥ä¸‹ã€å…ƒã®èª²é¡Œæ–‡) ---\n" + problem_statement
        return fallback

    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        # (v8.1ã‹ã‚‰å¤‰æ›´ãªã—)
        
        yield "--- ğŸ’¡ LLMã«ã‚ˆã‚‹æœ€é©ãªæ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆãƒ•ã‚§ãƒ¼ã‚º1 & 2ï¼‰ã‚’ç”Ÿæˆä¸­... ---"
        prompt = self.prompter.get_tavily_multi_phase_query_prompt(problem_statement)
        query_response = self._call_llm(prompt)

        if not isinstance(query_response, dict) or ("analysis_queries" not in query_response and "solution_queries" not in query_response):
            yield f"ã‚¨ãƒ©ãƒ¼: Tavilyã‚¯ã‚¨ãƒªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™: {query_response}"
            augmented_problem = problem_statement
        else:
            analysis_queries = query_response.get("analysis_queries", [])
            solution_queries = query_response.get("solution_queries", [])
            
            yield f"--- âœ”ï¸ ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒª ---"
            yield f"  - åˆ†æã‚¯ã‚¨ãƒª: {', '.join(analysis_queries) if analysis_queries else 'ãªã—'}"
            yield f"  - è§£æ±ºç­–ã‚¯ã‚¨ãƒª: {', '.join(solution_queries) if solution_queries else 'ãªã—'}"
            
            analysis_results_list = []
            solution_results_list = []
            
            if analysis_queries:
                yield "--- ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º1: èª²é¡Œã®ç¾çŠ¶åˆ†æãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹... ---"
                for q in analysis_queries:
                    if not q.strip(): continue
                    yield f"  - æ¤œç´¢ä¸­ (åˆ†æ): {q}"
                    tavily_resp = self.tavily.search(q, num_results=self.tavily_results_per_query)
                    if isinstance(tavily_resp, dict) and "results" in tavily_resp:
                        analysis_results_list.extend(tavily_resp["results"])
                    elif isinstance(tavily_resp, dict) and "error" in tavily_resp:
                         yield f"  - Tavily ã‚¨ãƒ©ãƒ¼ (åˆ†æã‚¯ã‚¨ãƒª: {q}): {tavily_resp['error']}"
            
            if solution_queries:
                yield "--- ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹... ---"
                for q in solution_queries:
                    if not q.strip(): continue
                    yield f"  - æ¤œç´¢ä¸­ (è§£æ±ºç­–): {q}"
                    tavily_resp = self.tavily.search(q, num_results=self.tavily_results_per_query)
                    if isinstance(tavily_resp, dict) and "results" in tavily_resp:
                        solution_results_list.extend(tavily_resp["results"])
                    elif isinstance(tavily_resp, dict) and "error" in tavily_resp:
                         yield f"  - Tavily ã‚¨ãƒ©ãƒ¼ (è§£æ±ºç­–ã‚¯ã‚¨ãƒª: {q}): {tavily_resp['error']}"

            yield {"tavily_info_analysis": analysis_results_list, "tavily_info_solution": solution_results_list}

            yield "--- âœï¸ 2ã¤ã®ãƒªã‚µãƒ¼ãƒçµæœã‚’è¦ç´„ã—ã€å•é¡Œæ–‡ã«çµ±åˆã—ã¾ã™... ---"
            try:
                augmented_problem = self._summarize_multi_phase_results_with_llm(
                    problem_statement, 
                    analysis_results_list, 
                    solution_results_list
                )
            except Exception as e:
                augmented_problem = problem_statement
                yield f"è­¦å‘Š: Tavily è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        yield from super().solve(augmented_problem, generations)


# ----------------------------
# 5) Streamlit UI (v8.1ã‹ã‚‰å¤‰æ›´ãªã—)
# ----------------------------
st.set_page_config(page_title="EvoGen AI + Tavily (Generalist Swarm)", layout="wide")
st.title("EvoGen AI ğŸ§¬")
st.markdown("é€²åŒ–å‹ç”ŸæˆAIè§£æ¢ç´¢ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š (v8.1ã‹ã‚‰å¤‰æ›´ãªã—) ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    gemini_key = st.text_input("Google Gemini API Key", type="password", help="Gemini ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    tavily_key = st.text_input("Tavily API Key", type="password", help="Tavily ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    st.subheader("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    num_generations = st.slider("ä¸–ä»£æ•°", 1, 20, 2, help="è§£æ±ºç­–ã‚’é€²åŒ–ã•ã›ã‚‹å›æ•°ã§ã™ã€‚")
    num_solutions = st.slider("ä¸–ä»£ã”ã¨ã®(æœ€å¤§)è§£æ±ºç­–ã®æ•°", 3, 10, 10, help="ç¬¬1ä¸–ä»£ä»¥é™ã«ç”Ÿæˆãƒ»è©•ä¾¡ã™ã‚‹è§£æ±ºç­–ã®æ•°ã§ã™ã€‚(ç¬¬0ä¸–ä»£ã¯å¸¸ã«10å€‹)")
    tavily_results_per_search = st.slider("Tavily æ¤œç´¢çµæœæ•° (ã‚¯ã‚¨ãƒªæ¯)", 1, 10, 3, help="1ã¤ã®ã‚¯ã‚¨ãƒªã‚ãŸã‚Šã«Tavily ã‹ã‚‰å–å¾—ã™ã‚‹æ¤œç´¢çµæœæ•°ã€‚")
    st.markdown("---")
    st.info("Tavily ã‚’ä½¿ã£ã¦èª²é¡Œã«é–¢é€£ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’å–å¾—ã—ã€ãã‚Œã‚’å‚è€ƒã«è§£æ±ºç­–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

# (v8.1ã‹ã‚‰å¤‰æ›´ãªã—)
default_problem = """
# èª²é¡Œ
ä¸­å°ä¼æ¥­ã®çµŒç†éƒ¨é–€ã«ãŠã‘ã‚‹ã€è«‹æ±‚æ›¸å‡¦ç†ã®æ¥­å‹™åŠ¹ç‡ã‚’åŠ‡çš„ã«æ”¹å–„ã™ã‚‹
æ–°ã—ã„AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã›ã‚ˆã€‚

# è¦ä»¶ãƒ»åˆ¶ç´„æ¡ä»¶
- å°å…¥ã‚³ã‚¹ãƒˆãŒä½ã„ã“ã¨ã€‚ï¼ˆæœˆé¡5ä¸‡å††ä»¥ä¸‹ï¼‰
- å°‚é–€çš„ãªITçŸ¥è­˜ãŒãªãã¦ã‚‚åˆ©ç”¨ã§ãã‚‹ã“ã¨ã€‚
- æ—¢å­˜ã®ä¼šè¨ˆã‚½ãƒ•ãƒˆï¼ˆä¾‹: freee, MFã‚¯ãƒ©ã‚¦ãƒ‰ï¼‰ã¨é€£æºã§ãã‚‹ã“ã¨ãŒæœ›ã¾ã—ã„ã€‚
"""
problem_statement = st.text_area("è§£æ±ºã—ãŸã„èª²é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=default_problem, height=260)

if st.button("è§£æ±ºç­–ã®ç”Ÿæˆã‚’é–‹å§‹", type="primary"):
    if not gemini_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Google Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not tavily_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Tavily APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not problem_statement.strip():
        st.warning("èª²é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status_placeholder = st.empty()
        team_placeholder = st.empty()
        tavily_placeholder = st.container() 
        results_area = st.container()
        final_result_placeholder = st.container()

        with st.spinner("ğŸŒ€ AIãŒæ€è€ƒä¸­ã§ã™..."):
            try:
                gemini_client = GeminiClient(api_key=gemini_key)
                tavily_client = TavilyClient(api_key=tavily_key)
            except Exception as e:
                st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()

            solver = EvoGenSolver_Tavily(
                llm_client=gemini_client,
                tavily_client=tavily_client,
                num_solutions_per_generation=num_solutions,
                tavily_results_per_search=tavily_results_per_search
            )
            
            def display_tavily_results(results_list, title):
                with tavily_placeholder.container():
                    st.subheader(title)
                    if results_list:
                        for r in results_list:
                            title = r.get("title", "No title")
                            url = r.get("url", "")
                            snippet = r.get("snippet", "") or r.get("description", "")
                            st.markdown(f"- [{title}]({url})")
                            if snippet:
                                st.caption(snippet)
                    else:
                        st.write("ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.markdown("---")


            # --- Solverã‚’å®Ÿè¡Œã—ã€çµæœã‚’UIã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º ---
            for result in solver.solve(problem_statement, generations=num_generations):
                if isinstance(result, str):
                    status_placeholder.info(result) 

                elif isinstance(result, dict) and ("tavily_info_analysis" in result or "tavily_info_solution" in result):
                    tavily_placeholder.empty()
                    analysis_data = result.get("tavily_info_analysis", [])
                    solution_data = result.get("tavily_info_solution", [])
                    if analysis_data:
                        display_tavily_results(analysis_data, "ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º1: èª²é¡Œã®ç¾çŠ¶åˆ†æãƒªã‚µãƒ¼ãƒçµæœ")
                    if solution_data:
                        display_tavily_results(solution_data, "ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒªã‚µãƒ¼ãƒçµæœ")
                
                elif isinstance(result, dict) and "agent_team" in result:
                    # (ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ è¡¨ç¤º - v8.1ã‹ã‚‰å¤‰æ›´ãªã—)
                    with team_placeholder.container():
                        st.subheader("ğŸ¤– ç·¨æˆã•ã‚ŒãŸAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ")
                        team = result["agent_team"]
                        with st.expander("ãƒãƒ¼ãƒ ã®è©³ç´°ã‚’è¡¨ç¤º"):
                            
                            st.markdown("##### ğŸ’¡ğŸ§¬ è§£æ±ºãƒ»é€²åŒ–æ‹…å½“ (10ä½“)")
                            gen_list = team.get("solver_agents", [])
                            if gen_list:
                                for i, gen in enumerate(gen_list):
                                    st.markdown(f"**{i+1}. {gen.get('role', 'æœªå®šç¾©')}:** {gen.get('instructions', 'æœªå®šç¾©')}")
                            else:
                                st.markdown("ï¼ˆå®šç¾©ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰")
                            
                            st.markdown("---")
                            st.markdown("##### ğŸ§ è©•ä¾¡æ‹…å½“ (3ä½“)") 
                            eva_list = team.get("evaluators", [])
                            if eva_list:
                                for i, eva in enumerate(eva_list):
                                    st.markdown(f"**{i+1}. {eva.get('role', 'N/A')}**")
                                    criteria_list = eva.get('criteria', [])
                                    criteria_md = ""
                                    if criteria_list:
                                        for c in criteria_list:
                                            criteria_md += f"    - {c.get('criterion', 'é …ç›®åãªã—')}: {c.get('weight', 0)}ç‚¹\n"
                                    st.markdown(f"{criteria_md or 'è©•ä¾¡åŸºæº–æœªå®šç¾©'}")
                            else:
                                st.markdown("ï¼ˆå®šç¾©ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰")

                elif isinstance(result, dict) and "generation" in result:
                    # (ä¸–ä»£ã”ã¨çµæœè¡¨ç¤º - v8.1ã‹ã‚‰å¤‰æ›´ãªã—)
                    gen_data = result
                    with results_area.container():
                        st.subheader(f"ç¬¬ {gen_data['generation']} ä¸–ä»£ã®çµæœ")
                        with st.container(border=True):
                            if not gen_data.get('results'):
                                st.write("ã“ã®ä¸–ä»£ã§ã¯æœ‰åŠ¹ãªè§£æ±ºç­–ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                                continue
                            
                            for item in gen_data.get('results', []):
                                sol = item.get('solution', {})
                                eva = item.get('evaluation', {})
                                score = eva.get('total_score', 0)
                                
                                st.markdown(f"**é¡Œå:** {sol.get('name', 'N/A')} (ã‚¹ã‚³ã‚¢: {score})")
                                content = sol.get('specific_method', 'N/A') 
                                st.markdown(f"**å…·ä½“çš„ãªæ–¹æ³•:**\n {content}")
                                
                                if item != gen_data.get('results', [])[-1]:
                                    st.markdown("---")

        # === æœ€çµ‚çµæœã®è¡¨ç¤ºï¼ˆv8.1ã‹ã‚‰å¤‰æ›´ãªã—ï¼‰ ===
        
        all_solutions = [
            item for gen in solver.history
            for item in gen.get("results", [])
            if item.get("evaluation") and "total_score" in item["evaluation"]
        ]

        if all_solutions:
            sorted_solutions = sorted(
                all_solutions,
                key=lambda x: x["evaluation"]["total_score"],
                reverse=True
            )
            
            top_5_solutions = sorted_solutions[:5]

            status_placeholder.empty()
            st.balloons()

            with final_result_placeholder:
                st.success("ğŸ† å‡¦ç†å®Œäº†ï¼ã‚¹ã‚³ã‚¢ãƒˆãƒƒãƒ—5ã®è§£æ±ºç­–ã¯ã“ã¡ã‚‰ã§ã™ã€‚")
                
                for i, item in enumerate(top_5_solutions):
                    sol = item.get('solution', {})
                    eva = item.get('evaluation', {})
                    score = eva.get('total_score', 'N/A')
                    
                    st.header(f"ğŸ… ç¬¬ {i + 1} ä½: {sol.get('name', 'N/A')}")
                    st.metric(label="æœ€çµ‚ã‚¹ã‚³ã‚¢ (3ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¹³å‡)", value=f"{score}")

                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.info(f"**å…·ä½“çš„ãªæ–¹æ³•**\n\n{sol.get('specific_method', 'N/A')}")
                        st.warning(f"**æ‡¸å¿µç‚¹ãƒ»æ”¹å–„ç‚¹ (3åã®è©•ä¾¡è€…ã‚ˆã‚Š)**")
                        st.text_area(
                            f"æ‡¸å¿µç‚¹ãƒ»æ”¹å–„ç‚¹ {i+1}", 
                            value=eva.get('weaknesses', 'N/A'), 
                            height=250, 
                            disabled=True,
                            label_visibility="collapsed"
                        )
                    with col2:
                        st.success(f"**å„ªã‚ŒãŸç‚¹ (3åã®è©•ä¾¡è€…ã‚ˆã‚Š)**")
                        st.text_area(
                            f"å„ªã‚ŒãŸç‚¹ {i+1}", 
                            value=eva.get('strengths', 'N/A'), 
                            height=250, 
                            disabled=True,
                            label_visibility="collapsed"
                        )
                    
                    st.info(f"**ç·è©• (3åã®è©•ä¾¡è€…ã‚ˆã‚Š)**")
                    st.text_area(
                        f"ç·è©• {i+1}",
                        value=eva.get('overall_comment', 'N/A'),
                        height=200,
                        disabled=True,
                        label_visibility="collapsed"
                    )
                    
                    st.markdown("---")
        else:
            status_placeholder.warning("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸãŒã€æœ€çµ‚çš„ãªè§£æ±ºç­–ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# v8.1: ã‚¹ã‚¯ãƒªãƒ—ãƒˆæœ«å°¾ã®ä¸è¦ãªã‚¨ãƒ©ãƒ¼è¡Œã¯å‰Šé™¤æ¸ˆã¿