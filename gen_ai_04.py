# app_tavily_fixed_v16_batch_queries.py
"""
EvoGen AI with Tavily integration (v16.0: ãƒãƒƒãƒã‚¯ã‚¨ãƒªæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«)

v15.0 (gen_ai_04.py) ã‹ã‚‰ã®å¤‰æ›´ç‚¹:
- (APIåŠ¹ç‡åŒ–) ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æœ›ã«åŸºã¥ãã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥èª¿æŸ»ã®ã€Œã‚¯ã‚¨ãƒªç”Ÿæˆã€ã‚’
  ãƒãƒƒãƒå‡¦ç†ï¼ˆ10ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†ã‚’LLM 1å›ã®å‘¼ã³å‡ºã—ï¼‰ã§è¡Œã†ã‚ˆã†ã«æœ€é©åŒ–ã€‚
- `PromptManager` (ä¿®æ­£):
  - (å‰Šé™¤) `get_agent_specific_queries_prompt`: v15.0ã§ 10å›å‘¼ã³å‡ºã•ã‚Œã¦ã„ãŸ
    å€‹åˆ¥ã‚¯ã‚¨ãƒªç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‰Šé™¤ã€‚
  - (æ–°è¨­) `get_all_agent_queries_prompt`: å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ(10ä½“)ã®ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€
    å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†ã®ã‚¯ã‚¨ãƒª(20å€‹)ã‚’ã€Œ1å›ã®LLMå‘¼ã³å‡ºã—ã€ã§ã¾ã¨ã‚ã¦ç”Ÿæˆã™ã‚‹
    ãƒãƒƒãƒå‡¦ç†ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ–°è¨­ã€‚
- `EvoGenSolver_Tavily` (ä¿®æ­£):
  - `_run_agent_specific_research` (ãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£):
    - v15.0: ãƒ«ãƒ¼ãƒ—å†…ã§ [LLMã‚¯ã‚¨ãƒªç”Ÿæˆ -> Tavilyæ¤œç´¢ -> LLMåˆ†æ] ã‚’å®Ÿè¡Œã—ã¦ã„ãŸã€‚
    - v16.0: 
      1. ãƒ«ãƒ¼ãƒ—ã®ã€Œå‰ã€ã« `get_all_agent_queries_prompt` ã‚’1å›ã ã‘å‘¼ã³å‡ºã—ã€
         å…¨ã‚¯ã‚¨ãƒªã‚’è¾æ›¸ã¨ã—ã¦å–å¾—ã€‚
      2. ãƒ«ãƒ¼ãƒ—å†…ã§ã¯ã€è¾æ›¸ã‹ã‚‰ã‚¯ã‚¨ãƒªã‚’å¼•ã„ã¦ [Tavilyæ¤œç´¢ -> LLMåˆ†æ] ã®ã¿å®Ÿè¡Œã€‚
    - ã“ã‚Œã«ã‚ˆã‚Šã€ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã®LLMå‘¼ã³å‡ºã—å›æ•°ã‚’ 20å› -> 11å› ã«å‰Šæ¸›ã€‚

v15.0 ã®ç‰¹å¾´ (gen_ai_04.py):
- (ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥èª¿æŸ») å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªèº«ã®å½¹å‰²å°‚ç”¨ã®èª¿æŸ»ã¨åˆ†æã‚’è¡Œã†ã€‚
- (æ·±å±¤åˆ†æ) Tavilyã§Webãƒšãƒ¼ã‚¸ã®ã€Œå…¨æ–‡ã€ã‚’å–å¾—ã—ã€LLMãŒã€Œæˆ¦ç•¥çš„æ´å¯Ÿã€ã‚’æŠ½å‡ºã€‚
- (æ±ç”¨æ€§) `{"proposal_main": "...", "proposal_details": "..."}` ã®2åˆ†å‰²JSONæ§‹é€ ã€‚
- (å‹•çš„UI) `output_labels` ã‚’AIãŒå‹•çš„ã«ç”Ÿæˆã—ã€UIã«åæ˜ ã™ã‚‹ã€‚
"""

import streamlit as st
import os
import json
import abc
from typing import List, Dict, Any, Generator, Optional
import time
import random 

# --- å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ ---
try:
    import google.generativeai as genai
except Exception:
    genai = None

try:
    import requests
except ImportError:
    requests = None

# ----------------------------
# 1) LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå±¤ (v14.0ã®ã¾ã¾å¤‰æ›´ãªã—)
# ----------------------------
class LLMClient(abc.ABC):
    """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åŸºæœ¬ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹"""
    @abc.abstractmethod
    def call(self, prompt: str) -> Dict[str, Any]:
        pass

class GeminiClient(LLMClient):
    """Google Gemini ç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆv9.0 JSONä¿®å¾©æ©Ÿèƒ½ä»˜ãï¼‰"""
    def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"): 
        if genai is None:
            raise ImportError("`google-generativeai`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install google-generativeai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
        self.generation_config = genai.GenerationConfig(
            response_mime_type="application/json"
        )

    def _extract_json(self, text: str) -> Optional[str]:
        """
        ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚„ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ©ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹
        æ–‡å­—åˆ—ã‹ã‚‰ã€æœ€åˆã¨æœ€å¾Œã®æ³¢æ‹¬å¼§/è§’æ‹¬å¼§ã«åŸºã¥ã„ã¦JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºã™ã‚‹ã€‚
        """
        if not text:
            return None
        
        start_brace = text.find('{')
        start_bracket = text.find('[')
        
        if start_brace == -1 and start_bracket == -1:
            return None
            
        if start_brace == -1:
            start = start_bracket
        elif start_bracket == -1:
            start = start_brace
        else:
            start = min(start_brace, start_bracket)
            
        end_brace = text.rfind('}')
        end_bracket = text.rfind(']')
        
        if end_brace == -1 and end_bracket == -1:
            return None
            
        end = max(end_brace, end_bracket)
        
        if end <= start:
            return None
            
        potential_json = text[start:end+1]
        return potential_json

    def _get_json_repair_prompt(self, malformed_text: str) -> str:
        """
        LLMãŒç”Ÿæˆã—ãŸä¸æ­£ãªå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿®å¾©ã•ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
        """
        return f"""
        # æŒ‡ç¤º
        ã‚ãªãŸã¯ä»¥å‰ã€JSONå½¢å¼ã§ã®å‡ºåŠ›ã‚’æ±‚ã‚ã‚‰ã‚Œã¾ã—ãŸãŒã€ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚
        ã—ã‹ã—ã€ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯JSONã¨ã—ã¦æ­£ã—ããƒ‘ãƒ¼ã‚¹ï¼ˆè§£æï¼‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚

        # ä¸æ­£ãªå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆ
        ```
        {malformed_text}
        ```

        # ã‚¿ã‚¹ã‚¯
        ä¸Šè¨˜ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’**å®Œå…¨ã«**åæ˜ ã—ã¤ã¤ã€**ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ (```json ... ```) ã‚„èª¬æ˜æ–‡ã‚’ä¸€åˆ‡å«ã¾ãªã„ã€
        å³å¯†ã«æ­£ã—ã„JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆ`{{ ... }}` ã¾ãŸã¯ `[ ... ]` ã§å§‹ã¾ã‚‹ï¼‰**
        ã¨ã—ã¦ä¿®æ­£ã—ã€ãã®JSONã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        """

    def call(self, prompt: str, is_retry: bool = False) -> Dict[str, Any]:
        """
        prompt -> LLM å‘¼ã³å‡ºã— -> JSON ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° -> JSON ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
        ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã€LLMã«ä¿®å¾©ã‚’ä¾é ¼ã™ã‚‹ãƒªãƒˆãƒ©ã‚¤ã‚’1å›è¡Œã†ã€‚
        """
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            text = getattr(response, "text", None) or getattr(response, "response", None) or str(response)
            
            cleaned_text = self._extract_json(text)
            
            if cleaned_text:
                try:
                    return json.loads(cleaned_text) 
                except Exception as e_clean:
                    st.warning(f"[GeminiClient Warning] JSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ (ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ)ã€‚ Error: {e_clean}")
                    
                    if is_retry:
                        st.error(f"[GeminiClient Error] JSONä¿®å¾©ãƒªãƒˆãƒ©ã‚¤ã«ã‚‚å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        return {"raw_text": text, "parse_error": f"Retry failed: {e_clean}"}
                    else:
                        st.info(f"[GeminiClient Info] JSONä¿®å¾©ã®ãŸã‚ã€LLMã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                        repair_prompt = self._get_json_repair_prompt(text)
                        return self.call(repair_prompt, is_retry=True)
            else:
                st.warning(f"[GeminiClient Warning] å¿œç­”ã‹ã‚‰JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                
                if is_retry:
                    st.error(f"[GeminiClient Error] JSONä¿®å¾©ãƒªãƒˆãƒ©ã‚¤å¾Œã‚‚ã€JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    return {"raw_text": text, "parse_error": "Retry failed: No JSON block found"}
                else:
                    st.info(f"[GeminiClient Info] JSONä¿®å¾©ã®ãŸã‚ã€LLMã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                    repair_prompt = self._get_json_repair_prompt(text)
                    return self.call(repair_prompt, is_retry=True)
                
        except Exception as e:
            st.error(f"[GeminiClient Error] API å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if is_retry:
                return {"error": f"API call failed during retry: {e}"}
            else:
                return {"error": str(e)}


# ----------------------------
# 2) Tavily ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (v14.0ã®ã¾ã¾å¤‰æ›´ãªã—)
# ----------------------------
class TavilyClient:
    """
    Tavily Search API ã¨ã®ã‚„ã‚Šå–ã‚Šã‚’è¡Œã†ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€‚
    (v14.0: å…¨æ–‡å–å¾—å¯¾å¿œ)
    """
    DEFAULT_ENDPOINT = "https://api.tavily.com/search"

    def __init__(self, api_key: str, endpoint: str = DEFAULT_ENDPOINT, timeout: int = 15):
        if requests is None:
            raise ImportError("`requests`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install requests ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        self.api_key = api_key
        self.endpoint = endpoint
        self.timeout = timeout

    def search(self, query: str, num_results: int = 5, domain: Optional[str] = None, lang: Optional[str] = None) -> Dict[str, Any]:
        """
        (v14.0) å…¨æ–‡å–å¾— (`include_raw_content: True`) ã‚’å¸¸ã«è¡Œã†
        """
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        payload = {
            "query": query, 
            "max_results": num_results,
            "include_raw_content": True, # Webãƒšãƒ¼ã‚¸ã®å…¨æ–‡(ç”Ÿãƒ†ã‚­ã‚¹ãƒˆ)ã‚’è¦æ±‚
            "search_depth": "advanced"    # ã‚ˆã‚Šè©³ç´°ãªæ¤œç´¢ã‚’å®Ÿè¡Œ
        }
        
        if domain:
            payload["domain"] = domain
        if lang:
            payload["language"] = lang

        try:
            resp = requests.post(self.endpoint, headers=headers, json=payload, timeout=self.timeout)
            resp.raise_for_status()
            data = resp.json()
            return data
        except requests.exceptions.RequestException as e:
            return {"error": f"HTTP error: {e}"}
        except ValueError as e:
            return {"error": f"JSON parse error: {e}", "raw": resp.text if 'resp' in locals() else None}
        except Exception as e:
            return {"error": str(e)}

# ----------------------------
# 3) PromptManager (â˜…v16.0: ä¿®æ­£ç®‡æ‰€â˜…)
# ----------------------------
class PromptManager:
    """AIã¸ã®æŒ‡ç¤ºæ›¸ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def get_tavily_multi_phase_query_prompt(self, problem_statement: str) -> str:
        """
        (v14.0ã®ã¾ã¾) èª²é¡Œæ–‡ã®ã€Œäº‹å‰è£œå¼·ã€ç”¨
        """
        return f"""
        ã‚ãªãŸã¯ã€æç¤ºã•ã‚ŒãŸã€Œèª²é¡Œã€ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®èª¿æŸ»ã‚’2æ®µéšã§è¡Œã†å°‚é–€ã®èª¿æŸ»å“¡ã§ã™ã€‚

        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’åˆ†æã—ã€2ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã«å¯¾å¿œã™ã‚‹**æ—¥æœ¬èªã®æ¤œç´¢ã‚¯ã‚¨ãƒª**ã‚’ãã‚Œãã‚Œ4ã¤ãšã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

        # ãƒ•ã‚§ãƒ¼ã‚º1: ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ
        èª²é¡Œæ–‡ã«å«ã¾ã‚Œã‚‹å›ºæœ‰åè©ï¼ˆçµ„ç¹”åã€åœ°åã€ç‰¹å®šã®ã‚·ã‚¹ãƒ†ãƒ åãªã©ï¼‰ã‚’ç‰¹å®šã—ã€
        ãã®å¯¾è±¡ã®ã€Œæœ€æ–°æƒ…å ±ã€ã€Œç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿ã€ã€Œé–¢é€£ã™ã‚‹èƒŒæ™¯ã‚„åˆ¶ç´„ã€ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã€‚

        # ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒ»æŠ€è¡“èª¿æŸ»
        èª²é¡Œãã®ã‚‚ã®ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ã€Œæœ€æ–°ã®å¯¾ç­–äº‹ä¾‹ã€ã€Œé–¢é€£ã™ã‚‹æ–°ã—ã„æŠ€è¡“ã®å‹•å‘ã€ã€Œä»–åˆ†é‡ã§ã®æˆåŠŸäº‹ä¾‹ã€ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã€‚

        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "analysis_queries": [
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª1 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª2 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª3 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª4 (æ—¥æœ¬èª)"
          ],
          "solution_queries": [
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª1 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª2 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª3 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª4 (æ—¥æœ¬èª)"
          ]
        }}
        """

    def get_agent_personas_prompt(self, problem_statement: str) -> str:
        """
        (v13.0ã®ã¾ã¾)
        """
        return f"""
        # å½¹å‰²
        ã‚ãªãŸã¯ã€éå¸¸ã«è¤‡é›‘ãªèª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ãªã‚‹ã€Œã‚¹ã‚¦ã‚©ãƒ¼ãƒ ï¼ˆç¾¤ã‚Œï¼‰ã€ã‚’ç·¨æˆã™ã‚‹ã€Œãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€ã§ã™ã€‚

        # ã‚¿ã‚¹ã‚¯
        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æœ€ã‚‚åŠ¹æœçš„ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç¾¤ã¨ã€æˆæœç‰©ã®è¡¨ç¤ºãƒ©ãƒ™ãƒ«ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        ç·¨æˆã¯ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å³å¯†ã«è¡Œã£ã¦ãã ã•ã„ã€‚

        ## ã‚¹ãƒ†ãƒƒãƒ—1: èª²é¡Œã®å¾¹åº•åˆ†æ (Your Internal Monologue)
        1.  **æ ¸å¿ƒçš„ç›®æ¨™(Goal)ã¯ä½•ã‹ï¼Ÿ**
        2.  **ã‚¿ã‚¹ã‚¯ã®æ€§è³ª**: ã“ã®èª²é¡Œã¯ã€Œè§£æ±ºç­–(Solution)ã€ã‹ã€Œå‰µä½œç‰©(Creative)ã€ã‹ï¼Ÿ
        3.  **ä¸»è¦ãªåˆ¶ç´„(Constraints)ã¯ä½•ã‹ï¼Ÿ**
        4.  **ä¸»è¦ãªåˆ©å®³é–¢ä¿‚è€…(Stakeholders)ã¯èª°ã‹ï¼Ÿ**

        ## ã‚¹ãƒ†ãƒƒãƒ—2: è§£æ±ºãƒ»é€²åŒ–æ‹…å½“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (10ä½“) ã®å®šç¾©
        - ã‚¹ãƒ†ãƒƒãƒ—1ã®åˆ†æã«åŸºã¥ãã€èª²é¡Œè§£æ±ºã«æœ€é©åŒ–ã•ã‚ŒãŸã€Œäº’ã„ã«ç•°ãªã‚‹10ã®è¦–ç‚¹ã€ã‚’æŒã¤å°‚é–€å®¶ï¼ˆsolver_agentsï¼‰ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - **é‡è¦**: ã€Œãƒãƒ¼ã‚±ã‚¿ãƒ¼ã€ã®ã‚ˆã†ãªä¸€èˆ¬çš„ãªå½¹å‰²ã§ã¯ãªãã€ã€Œ**[åˆ©å®³é–¢ä¿‚è€…]ã®[ç‰¹å®šã®èª²é¡Œ]ã‚’è§£æ±ºã™ã‚‹å°‚é–€å®¶**ã€ã‚„ã€Œ**[ä¸»è¦ãªåˆ¶ç´„]ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹[ç‰¹å®šæŠ€è¡“]ã®å°‚é–€å®¶**ã€ã®ã‚ˆã†ã«ã€**ã“ã®èª²é¡Œå°‚ç”¨ã«ç‰¹åŒ–ã•ã›ãŸå½¹å‰²ï¼ˆroleï¼‰**ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - `instructions`ã«ã¯ã€ãã®å°‚é–€æ€§ã‚’æ´»ã‹ã—ã¦ã€ŒåˆæœŸè§£ã®ç”Ÿæˆã€ã¨ã€Œæ—¢å­˜è§£ã®é€²åŒ–ã€ã®ä¸¡æ–¹ã§ã©ã†æŒ¯ã‚‹èˆã†ã¹ãã‹å…·ä½“çš„ã«æŒ‡ç¤ºã—ã¦ãã ã•ã„ã€‚

        ## ã‚¹ãƒ†ãƒƒãƒ—3: èª²é¡Œç‰¹åŒ–å‹ è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (3ä½“) ã®å®šç¾©
        - ã‚¹ãƒ†ãƒƒãƒ—1ã®åˆ†æã«åŸºã¥ãã€ç”Ÿæˆã•ã‚ŒãŸææ¡ˆã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«**æœ€ã‚‚é‡è¦ã¨ãªã‚‹3ã¤ã®ç•°ãªã‚‹è©•ä¾¡è¦³ç‚¹**ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
        - ãã®3ã¤ã®è¦³ç‚¹ã«åŸºã¥ãã€ãã‚Œãã‚Œå°‚é–€ã®è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆevaluatorsï¼‰ã‚’3ä½“å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - `role`: ã‚ãªãŸãŒè€ƒæ¡ˆã—ãŸã€èª²é¡Œã«ç‰¹åŒ–ã—ãŸè©•ä¾¡è€…ã®å½¹å‰²åã€‚
        - `evaluation_guideline`: (v11.0ã®ã¾ã¾) ãã®å½¹å‰²ãŒææ¡ˆã‚’å³å¯†ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ã€**å…·ä½“çš„ã‹ã¤è©³ç´°ãªè©•ä¾¡æŒ‡é‡ï¼ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼‰**ã€‚

        ## ã‚¹ãƒ†ãƒƒãƒ—4: å‹•çš„UIãƒ©ãƒ™ãƒ«ã®å®šç¾© (v13.0)
        - ã‚¹ãƒ†ãƒƒãƒ—1ã®ã€Œã‚¿ã‚¹ã‚¯ã®æ€§è³ªã€åˆ†æã«åŸºã¥ãã€æœ€çµ‚çš„ãªæˆæœç‰©ã‚’UIã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã®2ã¤ã®ãƒ©ãƒ™ãƒ« (`output_labels`) ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - **`main_label`**: æˆæœç‰©ã®ã€Œæ ¸ã€ã¨ãªã‚‹éƒ¨åˆ†ã®ãƒ©ãƒ™ãƒ«ã€‚(ä¾‹: "ææ¡ˆã®åç§°", "å‰µä½œã—ãŸä¿³å¥")
        - **`details_label`**: æˆæœç‰©ã®ã€Œè©³ç´°ã€ã¨ãªã‚‹éƒ¨åˆ†ã®ãƒ©ãƒ™ãƒ«ã€‚(ä¾‹: "æ¦‚è¦ã¨å…·ä½“çš„ãªæ–¹æ³•", "ä¿³å¥ã®æ„å›³ã¨èƒŒæ™¯")
        
        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "output_labels": {{
             "main_label": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—4ã§å®šç¾©ã—ãŸãƒ¡ã‚¤ãƒ³ãƒ©ãƒ™ãƒ«ï¼‰",
             "details_label": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—4ã§å®šç¾©ã—ãŸè©³ç´°ãƒ©ãƒ™ãƒ«ï¼‰"
          }},
          "solver_agents": [
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²1ï¼‰", "instructions": "..." }},
            // ... (10ä½“åˆ†)
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²10ï¼‰", "instructions": "..." }}
          ],
          "evaluators": [
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã§è€ƒæ¡ˆã—ãŸè©•ä¾¡å½¹å‰²1ï¼‰", "evaluation_guideline": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã§è€ƒæ¡ˆã—ãŸè©•ä¾¡å½¹å‰²2ï¼‰", "evaluation_guideline": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã§è€ƒæ¡ˆã—ãŸè©•ä¾¡å½¹å‰²3ï¼‰", "evaluation_guideline": "..." }}
          ]
        }}
        """

    # === â˜…v16.0: æ–°è¨­ (å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¯ã‚¨ãƒªã‚’ãƒãƒƒãƒç”Ÿæˆ) ===
    def get_all_agent_queries_prompt(self, problem_statement: str, solver_agents: List[Dict]) -> str:
        """
        (v16.0) 10ä½“ã™ã¹ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å½¹å‰²ã«åŸºã¥ãã€
        å¿…è¦ãªæ¤œç´¢ã‚¯ã‚¨ãƒª(åˆè¨ˆ20å€‹)ã‚’ã€Œ1å›ã®LLMå‘¼ã³å‡ºã—ã€ã§
        ã¾ã¨ã‚ã¦ç”Ÿæˆã•ã›ã‚‹ã€‚
        """
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã«æ•´å½¢
        agent_list_text = []
        for i, agent in enumerate(solver_agents):
            agent_list_text.append(f"### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}")
            agent_list_text.append(f"role: \"{agent.get('role', 'N/A')}\"")
            agent_list_text.append(f"instructions: {agent.get('instructions', 'N/A')}")
        
        agents_definition_block = "\n".join(agent_list_text)

        return f"""
        # å…¨ä½“ã®èª²é¡Œ
        {problem_statement}

        # ç·¨æˆã•ã‚ŒãŸå°‚é–€å®¶ãƒãƒ¼ãƒ  (10ä½“)
        {agents_definition_block}

        # ã‚¿ã‚¹ã‚¯
        ã‚ãªãŸã¯ã€ä¸Šè¨˜ã®å°‚é–€å®¶ãƒãƒ¼ãƒ ï¼ˆ10ä½“ï¼‰ã®èª¿æŸ»ã‚’è£œä½ã™ã‚‹ã€Œèª¿æŸ»ãƒãƒ¼ãƒ•ã€ã§ã™ã€‚
        å„å°‚é–€å®¶ãŒã€ãã®ç‹¬è‡ªã®ã€Œå½¹å‰²(role)ã€ã¨ã€ŒæŒ‡ç¤º(instructions)ã€ã«åŸºã¥ãã€
        ã€Œå…¨ä½“ã®èª²é¡Œã€ã«å¯¾ã™ã‚‹å„ªã‚ŒãŸææ¡ˆã‚’è¡Œã†ãŸã‚ã«å¿…è¦ã¨ãªã‚‹
        **æ—¥æœ¬èªã®æ¤œç´¢ã‚¯ã‚¨ãƒª**ã‚’ã€å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã”ã¨ã«**å³å¯†ã«2ã¤**ãšã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

        # !!æœ€é‡è¦!! å‡ºåŠ›å½¢å¼ (JSON)
        - 10ä½“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå…¨å“¡åˆ†ã®ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        - ã‚­ãƒ¼ã¯ã€ä¸Šè¨˜ã§æç¤ºã•ã‚ŒãŸ**ã€Œroleã€ã®æ–‡å­—åˆ—ã¨å®Œå…¨ã«ä¸€è‡´**ã•ã›ã¦ãã ã•ã„ã€‚
        - JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ `{{ ... }}` ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        
        {{
          "agent_queries": {{
            "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1ã® role æ–‡å­—åˆ—ï¼‰": [
              "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1ã®è¦–ç‚¹ã§ã®æ¤œç´¢ã‚¯ã‚¨ãƒª1ï¼‰",
              "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1ã®è¦–ç‚¹ã§ã®æ¤œç´¢ã‚¯ã‚¨ãƒª2ï¼‰"
            ],
            "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2ã® role æ–‡å­—åˆ—ï¼‰": [
              "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2ã®è¦–ç‚¹ã§ã®æ¤œç´¢ã‚¯ã‚¨ãƒª1ï¼‰",
              "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2ã®è¦–ç‚¹ã§ã®æ¤œç´¢ã‚¯ã‚¨ãƒª2ï¼‰"
            ],
            // ... 10ä½“å…¨å“¡åˆ† ...
            "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ10ã® role æ–‡å­—åˆ—ï¼‰": [
              "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ10ã®è¦–ç‚¹ã§ã®æ¤œç´¢ã‚¯ã‚¨ãƒª1ï¼‰",
              "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ10ã®è¦–ç‚¹ã§ã®æ¤œç´¢ã‚¯ã‚¨ãƒª2ï¼‰"
            ]
          }}
        }}
        """

    # === â˜…v15.0: (v16.0ã§ã‚‚å¤‰æ›´ãªã—) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥åˆ†æ ===
    def get_agent_specific_analysis_prompt(self, problem_statement: str, agent_role: str, agent_instructions: str, raw_content_text: str) -> str:
        """
        (v15.0) ç‰¹å®šã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€è‡ªèº«ã®å½¹å‰²è¦–ç‚¹ã§å…¨æ–‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æã—ã€
        ã€Œ10å€‹ã®ç®‡æ¡æ›¸ãã®æ´å¯Ÿã€ã‚’æŠ½å‡ºã™ã‚‹ã€‚
        """
        return f"""
        # å…¨ä½“ã®èª²é¡Œ
        {problem_statement}

        # ã‚ãªãŸã®å°‚é–€å®¶ã¨ã—ã¦ã®å½¹å‰²
        ã‚ãªãŸã¯ã€Œ{agent_role}ã€ã§ã™ã€‚
        
        # ã‚ãªãŸã¸ã®æŒ‡ç¤º
        {agent_instructions}

        # ã‚ãªãŸå°‚ç”¨ã®èª¿æŸ»è³‡æ–™ (Webãƒšãƒ¼ã‚¸å…¨æ–‡)
        {raw_content_text}
        
        # ã‚¿ã‚¹ã‚¯
        ã‚ãªãŸã¯ä»Šã€ã‚ãªãŸã®å½¹å‰²å°‚ç”¨ã®ã€Œèª¿æŸ»è³‡æ–™ã€ï¼ˆWebãƒšãƒ¼ã‚¸ã®å…¨æ–‡ï¼‰ã‚’èª­ã¿çµ‚ãˆã¾ã—ãŸã€‚
        ã‚ãªãŸã®ã€Œå½¹å‰²ã€ã¨ã€ŒæŒ‡ç¤ºã€ã«å³å¯†ã«å¾“ã„ã€ä¸Šè¨˜ã®ã€Œå…¨ä½“ã®èª²é¡Œã€ã«å¯¾ã™ã‚‹
        ç‹¬è‡ªã®ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€ã“ã®èª¿æŸ»è³‡æ–™ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹
        **æœ€ã‚‚é‡è¦ã§å…·ä½“çš„ãªæ´å¯Ÿï¼ˆã‚­ãƒ¼ã‚¤ãƒ³ã‚µã‚¤ãƒˆï¼‰**ã‚’ã€
        **ç°¡æ½”ãªç®‡æ¡æ›¸ãã§10å€‹ç¨‹åº¦**ã€æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "key_insights": [
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ1ï¼‰",
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ2ï¼‰",
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ3ï¼‰",
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ4ï¼‰",
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ5ï¼‰",
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ6ï¼‰",
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ7ï¼‰",
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ8ï¼‰",
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ9ï¼‰",
            "ï¼ˆ{agent_role}ã®è¦–ç‚¹ã§æŠ½å‡ºã—ãŸé‡è¦ãªæ´å¯Ÿ10ï¼‰"
          ]
        }}
        """

    # === â˜…v15.0: (v16.0ã§ã‚‚å¤‰æ›´ãªã—) å€‹åˆ¥èª¿æŸ»æƒ…å ±ã‚’å‚ç…§ ===
    def get_initial_generation_prompt(self, problem_statement: str, num_solutions: int, context: Dict[str, Any]) -> str:
        """
        (v15.0) `proposal_main` ã¨ `proposal_details` ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå°‚ç”¨ã® `agent_research_insights` ã‚’å‚ç…§ã™ã‚‹ã€‚
        """
        
        # v15.0: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥ã®èª¿æŸ»æƒ…å ±ã‚’å–å¾—
        insights = context.get('agent_research_insights', [])
        insights_text = "\n".join([f"- {item}" for item in insights]) if insights else "ï¼ˆè¿½åŠ ã®èª¿æŸ»æƒ…å ±ãªã—ï¼‰"

        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯ä¸€æµã®ã‚¤ãƒãƒ™ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', f'ä»¥ä¸‹ã®èª²é¡Œã«å¯¾ã—ã€äº’ã„ã«å…¨ãç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‹ã‚‰ã®ææ¡ˆã‚’{num_solutions}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚')}
        # èª²é¡Œæ–‡: {problem_statement}

        # â˜…ã‚ãªãŸå°‚ç”¨ã®èª¿æŸ»æƒ…å ± (v15.0)â˜…
        # ä»¥ä¸‹ã®å€‹åˆ¥ã®èª¿æŸ»çµæœã‚’**å¿…ãš**å‚è€ƒã«ã—ã¦ã€ç‹¬è‡ªã®ææ¡ˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        {insights_text}

        # !!æœ€é‡è¦!! (å‡ºåŠ›å½¢å¼)
        å„ææ¡ˆã«ã€Œproposal_mainã€ã€Œproposal_detailsã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

        # å‡ºåŠ›é …ç›®ã®å®šç¾© (v13.0)
        * **proposal_main**: ææ¡ˆã®ã€Œæ ¸ã€ã¨ãªã‚‹éƒ¨åˆ†ã€‚(ä¾‹: ã€Œææ¡ˆã®åç§°ã€ ã¾ãŸã¯ ã€Œå‰µä½œç‰©ãã®ã‚‚ã®ã€)
        * **proposal_details**: ææ¡ˆã®ã€Œè©³ç´°ã€ã¨ãªã‚‹éƒ¨åˆ†ã€‚(ä¾‹: ã€Œå…·ä½“çš„ãªå†…å®¹ã‚„æ–¹æ³•ã€å¾—ã‚‰ã‚Œã‚‹åŠ¹æœã€ ã¾ãŸã¯ ã€Œæ„å›³ã€èƒŒæ™¯ã€ç†ç”±ã€ç‹™ã„ã€) ã‚’2ã€œ4è¡Œã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        * **é‡è¦**: ã€Œproposal_detailsã€ã«ã¯ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚ãŸã ã—ã€**æ–‡ç« å†…ã§ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã¯ä½¿ç”¨ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚**

        # å‡ºåŠ›JSONã®ä¾‹
        {{ 
          "solutions": [ 
            {{ 
              "proposal_main": "ææ¡ˆ1ã®æ ¸ (åç§° ã¾ãŸã¯ å‰µä½œç‰©ãã®ã‚‚ã®)", 
              "proposal_details": "ææ¡ˆ1ã®è©³ç´° (å…·ä½“çš„ãªå†…å®¹ã€æ„å›³ã€èƒŒæ™¯ã€ç†ç”±ã€åŠ¹æœãªã©) ã‚’èª¬æ˜ã™ã‚‹2ã€œ4è¡Œã®æ–‡ç« ã§ã™ã€‚\nã“ã®ã‚ˆã†ã«æ”¹è¡Œã‚’å«ã‚ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
            }}
          ] 
        }}
        """

    def get_evaluation_prompt(self, solution: Dict[str, str], problem_statement: str, context: Dict[str, Any]) -> str:
        """
        (v13.0ã®ã¾ã¾)
        """
        
        evaluator_role = context.get('role', 'ã‚ãªãŸã¯å®¢è¦³çš„ã§å³ã—ã„æ‰¹è©•å®¶ã§ã™ã€‚')
        evaluation_guideline = context.get('evaluation_guideline', 'æç¤ºã•ã‚ŒãŸææ¡ˆã‚’ã€èª²é¡Œã®è¦ä»¶ã«åŸºã¥ãå³å¯†ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚')

        return f"""
        # ã‚ãªãŸã®å³æ ¼ãªå½¹å‰²
        ã‚ãªãŸã¯ã€Œ{evaluator_role}ã€ã§ã™ã€‚

        # ã‚ãªãŸã®æœ€é‡è¦è©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
        {evaluation_guideline}

        # è©•ä¾¡å¯¾è±¡ã®èª²é¡Œ
        {problem_statement}
        
        # è©•ä¾¡å¯¾è±¡ã®ææ¡ˆ (v13.0)
        - ææ¡ˆã®æ ¸ (åç§°/å‰µä½œç‰©): {solution.get('proposal_main', 'å†…å®¹ãªã—')}
        - ææ¡ˆã®è©³ç´° (æ–¹æ³•/ç†ç”±): {solution.get('proposal_details', 'è©³ç´°ãªã—')}
        
        # ã‚¿ã‚¹ã‚¯
        ã‚ãªãŸã®ã€Œå½¹å‰²ã€ã¨ã€Œæœ€é‡è¦è©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€ã«å³å¯†ã«å¾“ã„ã€ä¸Šè¨˜ã®ã€Œææ¡ˆã€ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«ç…§ã‚‰ã—ã¦ã€ã“ã®ææ¡ˆãŒèª²é¡Œã‚’ã©ã‚Œã ã‘åŠ¹æœçš„ã«è§£æ±º/é”æˆã§ãã‚‹ã‹ã€ã¾ãŸã¯åŠ£ã£ã¦ã„ã‚‹ã‹ã‚’å…·ä½“çš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "total_score": (0-100ã®æ•´æ•°),
          "strengths": "ï¼ˆ{evaluator_role}ã®è¦³ç‚¹ã§å„ªã‚Œã¦ã„ã‚‹ç‚¹ï¼‰",
          "weaknesses": "ï¼ˆ{evaluator_role}ã®è¦³ç‚¹ã§æ‡¸å¿µãƒ»æ”¹å–„ãŒå¿…è¦ãªç‚¹ï¼‰",
          "overall_comment": "ï¼ˆ{evaluator_role}ã®è¦³ç‚¹ã§ã®ç·æ‹¬ï¼‰"
        }}
        """

    # === â˜…v15.0: (v16.0ã§ã‚‚å¤‰æ›´ãªã—) å€‹åˆ¥èª¿æŸ»æƒ…å ±ã‚’å‚ç…§ ===
    def get_next_generation_prompt(self, elite_solutions: List[Dict], failed_solutions: List[Dict], problem_statement: str, num_solutions: int, context: Dict[str, Any]) -> str:
        """
        (v15.0) æ—¢å­˜ã®è§£ã‚’ã€Œé€²åŒ–ã€ã•ã›ã€æ–°ã—ã„2åˆ†å‰²JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã™ã‚‹ã€‚
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå°‚ç”¨ã® `agent_research_insights` ã‚’å‚ç…§ã™ã‚‹ã€‚
        """
        elite_text = "\n".join([f"- {s['solution'].get('proposal_main', 'N/A')} (ã‚¹ã‚³ã‚¢: {s['evaluation'].get('total_score', 0)})" for s in elite_solutions])
        failed_text = "\n".join([f"- {s['solution'].get('proposal_main', 'N/A')} (å¼±ç‚¹: {s['evaluation'].get('weaknesses', 'N/A')})" for s in failed_solutions])

        # v15.0: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥ã®èª¿æŸ»æƒ…å ±ã‚’å–å¾—
        insights = context.get('agent_research_insights', [])
        insights_text = "\n".join([f"- {item}" for item in insights]) if insights else "ï¼ˆè¿½åŠ ã®èª¿æŸ»æƒ…å ±ãªã—ï¼‰"

        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯å„ªã‚ŒãŸæˆ¦ç•¥å®¶ã§ã‚ã‚Šç·¨é›†è€…ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', 'é«˜è©•ä¾¡æ¡ˆã®è‰¯ã„ç‚¹ã‚’çµ„ã¿åˆã‚ã›ã€ä½è©•ä¾¡æ¡ˆã®å¤±æ•—ã‹ã‚‰å­¦ã³ã€æ–°ã—ã„ææ¡ˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚')}
        # ã‚¿ã‚¹ã‚¯: å‰ä¸–ä»£ã®åˆ†æã«åŸºã¥ãã€æ¬¡ä¸–ä»£ã®æ–°ã—ã„ææ¡ˆã‚’{num_solutions}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        # åˆ†æå¯¾è±¡1ï¼šé«˜è©•ä¾¡ã ã£ãŸææ¡ˆï¼ˆå„ªã‚ŒãŸéºä¼å­ï¼‰: 
        {elite_text}
        # åˆ†æå¯¾è±¡2ï¼šä½è©•ä¾¡ã ã£ãŸææ¡ˆï¼ˆå­¦ã¶ã¹ãæ•™è¨“ï¼‰: 
        {failed_text}

        # â˜…ã‚ãªãŸå°‚ç”¨ã®èª¿æŸ»æƒ…å ± (v15.0)â˜…
        # ä»¥ä¸‹ã®å€‹åˆ¥ã®èª¿æŸ»çµæœã‚‚**å¿…ãš**å‚è€ƒã«ã—ã¦ã€ææ¡ˆã‚’é€²åŒ–ã•ã›ã¦ãã ã•ã„ã€‚
        {insights_text}
        
        # æ–°ã—ã„ææ¡ˆã®ç”ŸæˆæŒ‡ç¤º: {context.get('instructions')}
        
        # !!æœ€é‡è¦!! (å‡ºåŠ›å½¢å¼)
        å„ææ¡ˆã«ã€Œproposal_mainã€ã€Œproposal_detailsã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

        # å‡ºåŠ›é …ç›®ã®å®šç¾© (v13.0)
        * **proposal_main**: ææ¡ˆã®ã€Œæ ¸ã€ã¨ãªã‚‹éƒ¨åˆ†ã€‚ (ä¾‹: ã€Œææ¡ˆã®åç§°ã€ ã¾ãŸã¯ ã€Œå‰µä½œç‰©ãã®ã‚‚ã®ã€)
        * **proposal_details**: ææ¡ˆã®ã€Œè©³ç´°ã€ã¨ãªã‚‹éƒ¨åˆ†ã€‚ (ä¾‹: ã€Œå…·ä½“çš„ãªå†…å®¹ã‚„æ–¹æ³•ã€å¾—ã‚‰ã‚Œã‚‹åŠ¹æœã€ ã¾ãŸã¯ ã€Œæ„å›³ã€èƒŒæ™¯ã€ç†ç”±ã€ç‹™ã„ã€) ã‚’2ã€œ4è¡Œã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        * **é‡è¦**: ã€Œproposal_detailsã€ã«ã¯ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚ãŸã ã—ã€**æ–‡ç« å†…ã§ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã¯ä½¿ç”¨ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚**

        # å‡ºåŠ›JSONã®ä¾‹
        {{ 
          "solutions": [ 
            {{ 
              "proposal_main": "æ–°ã—ã„ææ¡ˆ1ã®æ ¸ (åç§° ã¾ãŸã¯ å‰µä½œç‰©ãã®ã‚‚ã®)", 
              "proposal_details": "æ–°ã—ã„ææ¡ˆ1ã®è©³ç´° (å†…å®¹ã€æ„å›³ã€èƒŒæ™¯ã€ç†ç”±ã€åŠ¹æœãªã©) ã‚’èª¬æ˜ã™ã‚‹2ã€œ4è¡Œã®æ–‡ç« ã§ã™ã€‚"
            }}
          ] 
        }}
        """

    def get_revolutionary_generation_prompt(self, problem_statement: str, num_solutions: int, existing_roles: List[str]) -> str:
        """
        (v13.0ã®ã¾ã¾)
        çªç„¶å¤‰ç•°ç”¨ã€‚å€‹åˆ¥ã®èª¿æŸ»æƒ…å ±ã¯å‚ç…§ã—ãªã„ã€‚
        """
        
        existing_roles_list = "\n".join([f"- {role}" for role in existing_roles]) if existing_roles else "ãªã—"

        return f"""
        # å½¹å‰²: 
        ã‚ãªãŸã¯ã€Œå¸¸è­˜å¤–ã‚Œã®ã‚¤ãƒãƒ™ãƒ¼ã‚¿ãƒ¼ã€ã‚’ä»»å‘½ã™ã‚‹ãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚
        ã‚ãªãŸã¯ã€Œçªç„¶å¤‰ç•°ã€ã‚’å¼•ãèµ·ã“ã™ãŸã‚ã€æ—¢å­˜ã®ææ¡ˆã‚„éå»ã®è©•ä¾¡ï¼ˆã‚¨ãƒªãƒ¼ãƒˆè§£ã€å¤±æ•—è§£ï¼‰ã€
        ãŠã‚ˆã³**æ—¢å­˜ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèª¿æŸ»æƒ…å ±ã‚‚ã™ã¹ã¦ç„¡è¦–**ã—ã¾ã™ã€‚

        # ã‚¿ã‚¹ã‚¯:
        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã«å¯¾ã—ã€æ—¢å­˜ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã¯**å…¨ãç•°ãªã‚‹æ–°ã—ã„è¦³ç‚¹**ã‚’æŒã¤
        ã€Œé©æ–°çš„ãªå°‚é–€å®¶ã€ã‚’{num_solutions}äººï¼ˆã¾ãŸã¯{num_solutions}å€‹ï¼‰å®šç¾©ã—ã€
        ãã®å°‚é–€å®¶ã®è¦–ç‚¹ã‹ã‚‰ã€é©æ–°çš„ãªææ¡ˆã‚’{num_solutions}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

        # èª²é¡Œæ–‡: 
        {problem_statement}

        # æ—¢å­˜ã®å°‚é–€å®¶ãƒ­ãƒ¼ãƒ« (ã“ã‚Œã‚‰ã¨ã¯ç•°ãªã‚‹è¦–ç‚¹ã«ã™ã‚‹ã“ã¨):
        {existing_roles_list}

        # !!é‡è¦!! 
        - ã‚¹ãƒ†ãƒƒãƒ—1ï¼ˆå†…éƒ¨æ€è€ƒï¼‰: æ—¢å­˜ãƒ­ãƒ¼ãƒ«ãŒã‚«ãƒãƒ¼ã—ã¦ã„ãªã„ã€å…¨ãæ–°ã—ã„ã€Œå½¹å‰²ï¼ˆãƒ­ãƒ¼ãƒ«ï¼‰ã€ã‚’è€ƒæ¡ˆã™ã‚‹ã€‚
        - ã‚¹ãƒ†ãƒƒãƒ—2ï¼ˆå†…éƒ¨æ€è€ƒï¼‰: ãã®å½¹å‰²ã«åŸºã¥ãã€é©æ–°çš„ãªææ¡ˆï¼ˆproposal_main, proposal_detailsï¼‰ã‚’è€ƒæ¡ˆã™ã‚‹ã€‚
        - ã‚¹ãƒ†ãƒƒãƒ—3ï¼ˆå‡ºåŠ›ï¼‰: è€ƒæ¡ˆã—ãŸææ¡ˆã‚’ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã€‚

        # !!æœ€é‡è¦!! (å‡ºåŠ›å½¢å¼)
        å„ææ¡ˆã«ã€Œproposal_mainã€ã€Œproposal_detailsã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        ã€Œproposal_mainã€ã«ã¯ã€è€ƒæ¡ˆã—ãŸæ–°ã—ã„å°‚é–€å®¶ã®å½¹å‰²ã‚„ã€ãã®é©æ–°æ€§ãŒä¼ã‚ã‚‹ã‚ˆã†ãªåç§°/å‰µä½œç‰©ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

        # å‡ºåŠ›é …ç›®ã®å®šç¾© (v13.0)
        * **proposal_main**: ææ¡ˆã®ã€Œæ ¸ã€ã¨ãªã‚‹éƒ¨åˆ†ã€‚ (ä¾‹: ã€Œææ¡ˆã®åç§°ã€ ã¾ãŸã¯ ã€Œå‰µä½œç‰©ãã®ã‚‚ã®ã€)
        * **proposal_details**: ææ¡ˆã®ã€Œè©³ç´°ã€ã¨ãªã‚‹éƒ¨åˆ†ã€‚ (ä¾‹: ã€Œå…·ä½“çš„ãªå†…å®¹ã‚„æ–¹æ³•ã€å¾—ã‚‰ã‚Œã‚‹åŠ¹æœã€ ã¾ãŸã¯ ã€Œæ„å›³ã€èƒŒæ™¯ã€ç†ç”±ã€ç‹™ã„ã€) ã‚’2ã€œ4è¡Œã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        * **é‡è¦**: ã€Œproposal_detailsã€ã«ã¯ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚ãŸã ã—ã€**æ–‡ç« å†…ã§ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã¯ä½¿ç”¨ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚**

        # å‡ºåŠ›JSONã®ä¾‹
        {{ 
          "solutions": [ 
            {{ 
              "proposal_main": "ï¼ˆè€ƒæ¡ˆã—ãŸæ–°å°‚é–€å®¶ã®å½¹å‰²ã‚’åæ˜ ã—ãŸé©æ–°çš„ãªåç§° ã¾ãŸã¯ å‰µä½œç‰©ï¼‰", 
              "proposal_details": "ï¼ˆãã®ææ¡ˆã®è©³ç´° (å†…å®¹ã€æ„å›³ã€èƒŒæ™¯ã€ç†ç”±ã€åŠ¹æœãªã©) ã‚’èª¬æ˜ã™ã‚‹2ã€œ4è¡Œã®æ–‡ç« ã§ã™ã€‚ï¼‰" 
            }}
          ] 
        }}
        """


# ----------------------------
# 4) EvoGenSolver (v15.0ã®ã¾ã¾å¤‰æ›´ãªã—)
# ----------------------------
class EvoGenSolver:
    """å…ƒã® EvoGenSolverï¼ˆä¸»è¦ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
    def __init__(self, llm_client: LLMClient, num_solutions_per_generation: int = 10):
        self.client = llm_client
        self.num_solutions = num_solutions_per_generation 
        self.prompter = PromptManager()
        self.history = []

    def _call_llm(self, prompt: str) -> Dict[str, Any]:
        return self.client.call(prompt) 

    def _generate_agent_personas(self, problem_statement: str) -> Dict:
        # (v13.0)
        prompt = self.prompter.get_agent_personas_prompt(problem_statement)
        return self._call_llm(prompt)

    def _generate_initial_solutions(self, problem_statement: str, context: List[Dict]) -> List[Dict[str, str]]:
        """
        (v15.0) `context` ã¯ `solver_agents` ã®ãƒªã‚¹ãƒˆ
        """
        initial_agent_list = context 
        if not isinstance(initial_agent_list, list) or len(initial_agent_list) == 0:
            st.warning(f"[EvoGenSolver] è§£æ±ºãƒ»é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒä¸æ­£ã§ã™ã€‚")
            return []
        
        num_initial_agents = len(initial_agent_list)
        st.info(f"ğŸ’¡ {num_initial_agents}ä½“ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆæœŸææ¡ˆï¼ˆ10å€‹ï¼‰ã‚’åˆ†æ‹…ã—ã¦ç”Ÿæˆä¸­...")
        
        all_solutions = []
        for i, agent_context in enumerate(initial_agent_list):
            st.caption(f"  - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}/{num_initial_agents} ({agent_context.get('role', 'N/A')}) ãŒç”Ÿæˆä¸­...")
            
            # (v15.0) `get_initial_generation_prompt` ã« `agent_context` (èª¿æŸ»æƒ…å ±ã‚’å«ã‚€) ã‚’æ¸¡ã™
            prompt = self.prompter.get_initial_generation_prompt(
                problem_statement, 
                1, 
                agent_context # 'role', 'instructions', 'agent_research_insights' ãŒå«ã¾ã‚Œã‚‹
            )
            response = self._call_llm(prompt) 
            
            if isinstance(response, dict) and "solutions" in response and isinstance(response["solutions"], list) and len(response["solutions"]) > 0:
                all_solutions.append(response["solutions"][0])
            else:
                st.warning(f"[EvoGenSolver] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1} ãŒä¸æ­£ãªå½¢å¼ã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {response}")
                
        return all_solutions

    def _evaluate_solutions(self, solutions: List[Dict[str, str]], problem_statement: str, context: Dict) -> Generator[str | List[Dict], None, None]:
        # (v13.0ã®ã¾ã¾)
        evaluator_agent_list = context
        if not isinstance(evaluator_agent_list, list) or len(evaluator_agent_list) == 0:
            st.error("[EvoGenSolver] è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒä¸æ­£ã§ã™ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
            yield []
            return

        evaluated_solutions = []
        if not solutions:
            yield []
            return

        num_evaluators = len(evaluator_agent_list)

        for i, solution in enumerate(solutions):
            if not isinstance(solution, dict) or "proposal_main" not in solution:
                yield f"  - è©•ä¾¡ã‚¹ã‚­ãƒƒãƒ—: ä¸æ­£ãªå½¢å¼ã®ææ¡ˆãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚"
                continue
            
            yield f"  - è©•ä¾¡ä¸­ {i+1}/{len(solutions)}: {solution.get('proposal_main', 'åç§°ä¸æ˜')} ( {num_evaluators}ä½“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹è©•ä¾¡)"

            individual_evaluations = []
            
            for j, eval_context in enumerate(evaluator_agent_list):
                yield f"    - è©•ä¾¡è€… {j+1}/{num_evaluators} ({eval_context.get('role', 'N/A')}) ãŒè©•ä¾¡..."
                
                prompt = self.prompter.get_evaluation_prompt(solution, problem_statement, eval_context)
                evaluation = self._call_llm(prompt)
                
                if isinstance(evaluation, dict) and "total_score" in evaluation and "error" not in evaluation:
                    individual_evaluations.append(evaluation)
                else:
                    st.warning(f"[EvoGenSolver] ææ¡ˆ '{solution.get('proposal_main', 'N/A')}' ã®è©•ä¾¡è€… {j+1} ãŒä¸æ­£ãªå½¢å¼ã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {evaluation}")

            if not individual_evaluations:
                st.warning(f"[EvoGenSolver] ææ¡ˆ '{solution.get('proposal_main', 'N/A')}' ã®æœ‰åŠ¹ãªè©•ä¾¡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                continue

            total_score_sum = sum(e.get('total_score', 0) for e in individual_evaluations)
            aggregated_score = round(total_score_sum / len(individual_evaluations))
            
            agg_strengths = "\n---\n".join([f"è©•ä¾¡è€…{k+1} ({e.get('role', 'N/A')}):\n{e.get('strengths', 'N/A')}" for k, e in enumerate(individual_evaluations)])
            agg_weaknesses = "\n---\n".join([f"è©•ä¾¡è€…{k+1} ({e.get('role', 'N/A')}):\n{e.get('weaknesses', 'N/A')}" for k, e in enumerate(individual_evaluations)])
            agg_comment = "\n---\n".join([f"è©•ä¾¡è€…{k+1} ({e.get('role', 'N/A')}):\n{e.get('overall_comment', 'N/A')}" for k, e in enumerate(individual_evaluations)])

            aggregated_evaluation = {
                "total_score": aggregated_score,
                "strengths": agg_strengths,
                "weaknesses": agg_weaknesses,
                "overall_comment": agg_comment,
                "individual_evals": individual_evaluations 
            }
            
            evaluated_solutions.append({"solution": solution, "evaluation": aggregated_evaluation})
            yield f"    - ç·åˆè©•ä¾¡ã‚¹ã‚³ã‚¢: {aggregated_score}"


        evaluated_solutions.sort(key=lambda x: x.get("evaluation", {}).get("total_score", 0), reverse=True)
        yield evaluated_solutions

    def _generate_next_generation(self, evaluated_solutions: List[Dict], problem_statement: str, context: List[Dict]) -> List[Dict[str, str]]:
        """
        (v15.0) `context` ã¯ `solver_agents` ã®ãƒªã‚¹ãƒˆ
        """
        solver_agent_list = context 
        if not isinstance(solver_agent_list, list) or len(solver_agent_list) == 0:
            st.warning(f"[EvoGenSolver] è§£æ±ºãƒ»é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒä¸æ­£ã§ã™ã€‚")
            return []

        num_elites = max(1, int(len(evaluated_solutions) * 0.4))
        elite_solutions = evaluated_solutions[:num_elites]
        failed_solutions = evaluated_solutions[num_elites:]

        st.info(f"ğŸš€ {self.num_solutions} ä½“ã®è§£æ±ºãƒ»é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸å‡ºã—ã¦æ¬¡ä¸–ä»£ã‚’ç”Ÿæˆ...")

        new_solutions = []
        for i in range(self.num_solutions):
            
            if random.random() < 0.20:
                # 20%ã®ç¢ºç‡: é©æ–° (çªç„¶å¤‰ç•°)
                st.caption(f"  - âš¡ (çªç„¶å¤‰ç•°) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}/{self.num_solutions} ãŒã€Œæ–°è¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®šç¾©ã€ã¨ã€Œé©æ–°çš„ãªææ¡ˆã€ã‚’å®Ÿè¡Œ...")
                
                existing_roles = [a.get('role', 'N/A') for a in solver_agent_list]
                
                # (v13.0) èª¿æŸ»æƒ…å ±ã¯å‚ç…§ã—ãªã„
                prompt = self.prompter.get_revolutionary_generation_prompt(
                    problem_statement, 
                    1, 
                    existing_roles 
                )
            else:
                # 80%ã®ç¢ºç‡: é€²åŒ– (æ—¢å­˜ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å†åˆ©ç”¨)
                selected_agent_context = random.choice(solver_agent_list) 
                st.caption(f"  - ğŸ§¬ (é€²åŒ–) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}/{self.num_solutions} ({selected_agent_context.get('role', 'N/A')}) ãŒã€Œæ—¢å­˜ã®ææ¡ˆã€ã‚’é€²åŒ–...")
                
                # (v15.0) `get_next_generation_prompt` ã« `selected_agent_context` ã‚’æ¸¡ã™
                prompt = self.prompter.get_next_generation_prompt(
                    elite_solutions, 
                    failed_solutions, 
                    problem_statement, 
                    1, 
                    selected_agent_context # 'role', 'instructions', 'agent_research_insights' ãŒå«ã¾ã‚Œã‚‹
                )
            
            response = self._call_llm(prompt) 
            
            if isinstance(response, dict) and "solutions" in response and isinstance(response["solutions"], list) and len(response["solutions"]) > 0:
                new_solutions.append(response["solutions"][0])
            else:
                st.warning(f"[EvoGenSolver] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1} ãŒä¸æ­£ãªå½¢å¼ã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {response}")

        return new_solutions

    # === (v15.0) ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ ===

    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        """
        (v15.0) ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ç·¨æˆã®ã¿ã‚’è¡Œã†ã€‚
        """
        self.history = []

        yield "--- ğŸ§  èª²é¡Œã‚’åˆ†æã—ã€æœ€é©ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ã‚’ç·¨æˆä¸­... ---"
        agent_personas = self._generate_agent_personas(problem_statement) 

        if not agent_personas or "error" in agent_personas or not all(k in agent_personas for k in ["solver_agents", "evaluators", "output_labels"]):
            yield "ã‚¨ãƒ©ãƒ¼: ãƒãƒ¼ãƒ ç·¨æˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚"
            yield f"**ãƒ‡ãƒãƒƒã‚°æƒ…å ±:** AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™ã€‚APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n```\n{agent_personas}\n```"
            return

        yield f"--- âœ”ï¸ ãƒãƒ¼ãƒ ç·¨æˆå®Œäº† ---"
        yield {"agent_team": agent_personas} # `output_labels` ã‚‚ã“ã“ã«å«ã¾ã‚Œã‚‹
        
        # (v15.0) å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯ã‚’ `solve_internal` ã«ç§»è­²
        yield from self.solve_internal(problem_statement, agent_personas, generations)

    def solve_internal(self, problem_statement: str, agent_personas: Dict, generations: int) -> Generator[str | Dict, None, None]:
        """
        (v15.0) ã‚¹ãƒ†ãƒƒãƒ—2: ææ¡ˆã®ç”Ÿæˆãƒ»è©•ä¾¡ãƒ»é€²åŒ–ã®ã€Œå®Ÿè¡Œã€ã‚µã‚¤ã‚¯ãƒ«ã€‚
        """
        if self.history: 
             pass
        else:
             self.history = []
             
        yield "\n--- ğŸ’¡ Generation 0: æœ€åˆã®ææ¡ˆ (10å€‹) ã‚’ç”Ÿæˆä¸­... ---"
        solutions = self._generate_initial_solutions(problem_statement, agent_personas["solver_agents"])
        
        if not solutions:
             yield "ã‚¨ãƒ©ãƒ¼: æœ€åˆã®ææ¡ˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIãŒé©åˆ‡ãªå¿œç­”ã‚’è¿”ã•ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
             return

        yield "--- ğŸ§ ææ¡ˆã‚’è©•ä¾¡ä¸­ (3ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ x 10ææ¡ˆ)... ---"
        eval_generator = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluators"])
        evaluated_solutions = []
        for item in eval_generator:
            if isinstance(item, str):
                yield item
            else:
                evaluated_solutions = item
        
        if not evaluated_solutions:
             yield "ã‚¨ãƒ©ãƒ¼: ææ¡ˆã®è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
             return

        self.history.append({"generation": 0, "results": evaluated_solutions})
        yield self.history[-1]

        # G1ä»¥é™ã®é€²åŒ–ã‚µã‚¤ã‚¯ãƒ«
        for i in range(1, generations):
            yield f"\n--- ğŸš€ Generation {i}: æ¬¡ã®ææ¡ˆã¸é€²åŒ–ä¸­... ---"
            previous_generation_results = self.history[-1]["results"]
            
            if not previous_generation_results:
                yield f"ã‚¨ãƒ©ãƒ¼: å‰ä¸–ä»£ ({i-1}) ã®æœ‰åŠ¹ãªè©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚é€²åŒ–ã‚’åœæ­¢ã—ã¾ã™ã€‚"
                break
            
            solutions = self._generate_next_generation(previous_generation_results, problem_statement, agent_personas["solver_agents"]) 

            if not solutions:
                yield f"ã‚¨ãƒ©ãƒ¼: Generation {i} ã®ææ¡ˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIãŒé©åˆ‡ãªå¿œç­”ã‚’è¿”ã•ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
                break

            yield f"--- ğŸ§ Generation {i} ã®ææ¡ˆã‚’è©•ä¾¡ä¸­... ---"
            eval_generator_next = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluators"])
            evaluated_solutions_next = []
            for item in eval_generator_next:
                if isinstance(item, str):
                    yield item
                else:
                    evaluated_solutions_next = item

            if not evaluated_solutions_next:
                 yield f"ã‚¨ãƒ©ãƒ¼: Generation {i} ã®è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
                 break

            self.history.append({"generation": i, "results": evaluated_solutions_next})
            yield self.history[-1]

        yield "\n--- âœ… é€²åŒ–ãƒ—ãƒ­ã‚»ã‚¹å®Œäº† ---"


# ----------------------------
# 5) EvoGenSolver_Tavily (â˜…v16.0: ä¿®æ­£ç®‡æ‰€â˜…)
# ----------------------------
class EvoGenSolver_Tavily(EvoGenSolver):
    """
    (v16.0) 
    1. èª²é¡Œæ–‡ã®äº‹å‰è£œå¼· (v14)
    2. ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ç·¨æˆ (v13)
    3. â˜…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥èª¿æŸ» (v16: ãƒãƒƒãƒã‚¯ã‚¨ãƒª)â˜…
    4. å®Ÿè¡Œã‚µã‚¤ã‚¯ãƒ« (v15)
    """
    def __init__(self, llm_client: LLMClient, tavily_client: TavilyClient, num_solutions_per_generation: int = 10, tavily_results_per_search: int = 5):
        super().__init__(llm_client, num_solutions_per_generation)
        self.tavily = tavily_client
        # (v15.0)
        self.tavily_results_per_agent_query = max(1, tavily_results_per_search // 2) 
        # (v15.0)
        self.tavily_results_for_augmentation = tavily_results_per_search 

    def _format_raw_content_for_llm(self, results: List[Dict[str, Any]], context_tag: str, max_items: int = 3, truncate_chars: int = 4000) -> str:
        """
        (v14.0ã®ã¾ã¾)
        """
        content_blocks = []
        if not results:
            return f"({context_tag}: No content found.)\n"
        
        for i, r in enumerate(results[:max_items]): 
            url = r.get("url", "Unknown URL")
            title = r.get("title", "No Title")
            raw_content = r.get("raw_content")
            
            content_blocks.append(f"--- START {context_tag} SOURCE {i+1} ({title}) ---\n")
            content_blocks.append(f"URL: {url}\n")
            
            if raw_content:
                truncated_content = raw_content[:truncate_chars] 
                content_blocks.append(f"CONTENT (first {truncate_chars} chars):\n{truncated_content}\n")
            else:
                snippet = r.get("snippet", "") or r.get("description", "")
                content_blocks.append(f"CONTENT: (No raw content available, using snippet)\n{snippet}\n")
            
            content_blocks.append(f"--- END {context_tag} SOURCE {i+1} ---\n")
        
        return "\n".join(content_blocks)

    def _summarize_multi_phase_results_with_llm(
        self, 
        problem_statement: str, 
        analysis_results: List[Dict[str, Any]], 
        solution_results: List[Dict[str, Any]]
    ) -> str:
        """
        (v14.0ã®ã¾ã¾) èª²é¡Œæ–‡ã®ã€Œäº‹å‰è£œå¼·ã€ç”¨
        """
        
        if not analysis_results and not solution_results:
            return problem_statement

        analysis_content_text = self._format_raw_content_for_llm(
            analysis_results, 
            "ANALYSIS CONTENT", 
            max_items=3, 
            truncate_chars=4000
        )
        solution_content_text = self._format_raw_content_for_llm(
            solution_results, 
            "SOLUTION CONTENT", 
            max_items=3, 
            truncate_chars=4000
        )

        # v14.0ã®æ·±å±¤åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt = f"""
        # å½¹å‰²
        ã‚ãªãŸã¯ã€ç¬¬ä¸€ç·šã®ãƒªã‚µãƒ¼ãƒæˆ¦ç•¥å®¶ã§ã™ã€‚ã‚ãªãŸã®ä»•äº‹ã¯ã€å¤§é‡ã®èª¿æŸ»è³‡æ–™ï¼ˆWebãƒšãƒ¼ã‚¸ã®å…¨æ–‡ï¼‰ã‚’èª­ã¿è§£ãã€
        å˜ãªã‚‹è¦ç´„ã§ã¯ãªãã€ã€Œæˆ¦ç•¥çš„ãªæ´å¯Ÿã€ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ã§ã™ã€‚

        # å…ƒã®èª²é¡Œ
        {problem_statement}

        # èª¿æŸ»è³‡æ–™ 1: ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ (Webãƒšãƒ¼ã‚¸å…¨æ–‡)
        {analysis_content_text if analysis_content_text else "ãªã—"}

        # èª¿æŸ»è³‡æ–™ 2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒ»æŠ€è¡“ (Webãƒšãƒ¼ã‚¸å…¨æ–‡)
        {solution_content_text if solution_content_text else "ãªã—"}

        # ã‚¿ã‚¹ã‚¯
        ã‚ãªãŸã¯ä»Šã€ä¸Šè¨˜ã®ã€Œèª¿æŸ»è³‡æ–™1ã€ã¨ã€Œèª¿æŸ»è³‡æ–™2ã€ã®*å…¨æ–‡*ï¼ˆã¾ãŸã¯ãã®å†’é ­ï¼‰ã‚’èª­ã¿çµ‚ãˆã¾ã—ãŸã€‚
        ã“ã‚Œã‚‰ã®è©³ç´°ãªæƒ…å ±ã«åŸºã¥ãã€å…ƒã®èª²é¡Œã‚’ã‚ˆã‚Šæ·±ãã€ã‚ˆã‚Šå…·ä½“çš„ã«è£œå¼·ã™ã‚‹ãŸã‚ã®åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
        **ã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼ˆæŠœç²‹ï¼‰ã§ã¯ãªãã€æä¾›ã•ã‚ŒãŸå…¨æ–‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ·±ãåˆ†æã—ã¦ãã ã•ã„ã€‚**

        # å‡ºåŠ›å½¢å¼ (JSON)
        åˆ†æçµæœã‚’ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        {{
          "summary_analysis": "ã€Œèª¿æŸ»è³‡æ–™1ï¼ˆç¾çŠ¶ãƒ»èƒŒæ™¯ï¼‰ã€ã‚’æ·±ãåˆ†æã—ãŸ*æˆ¦ç•¥çš„æ´å¯Ÿ*ã€‚å˜ãªã‚‹è¦ç´„ã§ã¯ãªãã€èª²é¡Œã®èƒŒæ™¯ã«ã‚ã‚‹é‡è¦ãªæ–‡è„ˆã‚„åˆ¶ç´„ã‚’æŒ‡æ‘˜ã™ã‚‹ã€‚(1ã€œ3æ–‡)",
          "summary_solution": "ã€Œèª¿æŸ»è³‡æ–™2ï¼ˆè§£æ±ºç­–ãƒ»äº‹ä¾‹ï¼‰ã€ã‹ã‚‰æŠ½å‡ºã—ãŸ*é‡è¦ãªå‚¾å‘*ã€‚ä»–ç¤¾ã®äº‹ä¾‹ã‚„æ–°æŠ€è¡“ã‹ã‚‰å­¦ã¹ã‚‹ã€èª²é¡Œè§£æ±ºã®ãƒ’ãƒ³ãƒˆã‚’æŒ‡æ‘˜ã™ã‚‹ã€‚(1ã€œ3æ–‡)",
          "key_points": [
            "ã€Œèª¿æŸ»è³‡æ–™1ï¼ˆç¾çŠ¶ãƒ»èƒŒæ™¯ï¼‰ã€ã«ãŠã„ã¦ãã®ä»–ã€è€ƒæ…®ã™ã‚‹ã¹ãã¨æ€ã‚ã‚Œã‚‹è¤‡æ•°ã®è¦³ç‚¹ã«é–¢ã™ã‚‹ç°¡æ½”ãª1æ–‡ã‚’10å€‹ç¨‹åº¦ä½œæˆã™ã‚‹",
            "ã€Œèª¿æŸ»è³‡æ–™2ï¼ˆè§£æ±ºç­–ãƒ»äº‹ä¾‹ï¼‰ã€ã«ãŠã„ã¦ãã®ä»–ã€è€ƒæ…®ã™ã‚‹ã¹ãã¨æ€ã‚ã‚Œã‚‹æ•°ã®è¦³ç‚¹ã«é–¢ã™ã‚‹ç°¡æ½”ãª1æ–‡ã‚’10å€‹ç¨‹åº¦ä½œæˆã™ã‚‹",
          ]
        }}
        """
        
        llm_ret = self._call_llm(prompt) 
        
        if isinstance(llm_ret, dict) and any(k in llm_ret for k in ["summary_analysis", "summary_solution", "key_points"]):
            try:
                summary_analysis_text = llm_ret.get("summary_analysis", "ç¾çŠ¶åˆ†æã®è¦ç´„ãªã—")
                summary_solution_text = llm_ret.get("summary_solution", "è§£æ±ºç­–äº‹ä¾‹ã®è¦ç´„ãªã—")
                kp = llm_ret.get("key_points", [])
                
                # v14.0 (gen_ai_03.py) ã® `top_sources` ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹éƒ¨åˆ†ãŒæ¬ è½ã—ã¦ã„ãŸãŸã‚
                # v14.0 ã®ã‚³ãƒ¼ãƒ‰ã‚’å¾©å…ƒãƒ»ä¿®æ­£ (v15.0 ã§æ¬ è½ã—ã¦ã„ãŸ)
                top = llm_ret.get("top_sources", [])
                top_text = "\n".join([f"- {s.get('title','')}: {s.get('url','')}" for s in top]) if isinstance(top, list) else ""
                
                composed = f"""
## Tavilyãƒªã‚µãƒ¼ãƒè¦ç´„ï¼ˆLLMã«ã‚ˆã‚‹è©³ç´°åˆ†æï¼‰
### ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ (æˆ¦ç•¥çš„æ´å¯Ÿ)
{summary_analysis_text}
### è§£æ±ºç­–ãƒ»äº‹ä¾‹ (é‡è¦ãªå‚¾å‘)
{summary_solution_text}

### æŠ½å‡ºã•ã‚ŒãŸé‡è¦ç‚¹
""" + "\n".join([f"- {p}" for p in kp]) + "\n\n" + \
"### ä¸»ãªå‡ºå…¸\n" + top_text + "\n\n" + \
"--- (ä»¥ä¸‹ã€å…ƒã®èª²é¡Œæ–‡) ---\n" + problem_statement
                
                return composed
            except Exception:
                pass 

        # (v13.0äº’æ›) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯
        fallback_sources = []
        for r in analysis_results[:2]:
            fallback_sources.append(f"- [åˆ†æ] {r.get('title','No title')} ({r.get('url','')})")
        for r in solution_results[:2]:
            fallback_sources.append(f"- [è§£æ±ºç­–] {r.get('title','No title')} ({r.get('url','')})")
            
        fallback = "## Tavilyãƒªã‚µãƒ¼ãƒè¦ç´„ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n" + \
                   "æœ€æ–°ã®ã‚¦ã‚§ãƒ–æƒ…å ±ã‚’å‚ç…§ã—ã¾ã—ãŸã€‚ä¸Šä½å‡ºå…¸:\n" + "\n".join(fallback_sources) + \
                   "\n\n" + "--- (ä»¥ä¸‹ã€å…ƒã®èª²é¡Œæ–‡) ---\n" + problem_statement
        return fallback

    # === â˜…v16.0: ä¿®æ­£ (ãƒãƒƒãƒã‚¯ã‚¨ãƒªç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯) ===
    def _run_agent_specific_research(self, problem_statement: str, solver_agents: List[Dict]) -> Generator[str, None, List[Dict]]:
        """
        (v16.0) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥èª¿æŸ»ã‚’å®Ÿè¡Œã€‚
        1. (LLM x1) å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¯ã‚¨ãƒªã‚’ãƒãƒƒãƒç”Ÿæˆ
        2. (Loop x10) [Tavilyæ¤œç´¢ -> LLMåˆ†æ] ã‚’å®Ÿè¡Œ
        """
        if not solver_agents:
            yield "è­¦å‘Š: è§£æ±ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€å€‹åˆ¥èª¿æŸ»ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
            return []
            
        yield f"--- ğŸ¤– 10ä½“ã®è§£æ±ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å°‚ç”¨èª¿æŸ»ã‚¯ã‚¨ãƒªã‚’ãƒãƒƒãƒç”Ÿæˆä¸­... ---"
        
        # 1. (v16.0) å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¯ã‚¨ãƒªã‚’1å›ã®LLMå‘¼ã³å‡ºã—ã§ç”Ÿæˆ
        all_queries_prompt = self.prompter.get_all_agent_queries_prompt(problem_statement, solver_agents)
        all_queries_response = self._call_llm(all_queries_prompt)
        
        all_queries_dict = {}
        if isinstance(all_queries_response, dict) and "agent_queries" in all_queries_response:
            all_queries_dict = all_queries_response["agent_queries"]
        else:
            yield f"  - è­¦å‘Š: å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¯ã‚¨ãƒªä¸€æ‹¬ç”Ÿæˆã«å¤±æ•—ã€‚å€‹åˆ¥èª¿æŸ»ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚ (Debug: {all_queries_response})"
            return solver_agents # èª¿æŸ»æƒ…å ±ãªã—ã§å…ƒã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
            
        yield f"--- âœ”ï¸ ã‚¯ã‚¨ãƒªãƒãƒƒãƒç”Ÿæˆå®Œäº†ã€‚10ä½“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå€‹åˆ¥ã®æ·±å±¤ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹... ---"
        
        updated_agents = []
        num_agents = len(solver_agents)

        # 2. (v16.0) å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€Œæ¤œç´¢ã€ã¨ã€Œåˆ†æã€ã‚’å®Ÿè¡Œ
        for i, agent_context in enumerate(solver_agents):
            role = agent_context.get("role", "ä¸æ˜ãªå½¹å‰²")
            instructions = agent_context.get("instructions", "")
            
            # (v16.0) LLMã‚’å‘¼ã³å‡ºã™ä»£ã‚ã‚Šã«ã€è¾æ›¸ã‹ã‚‰ã‚¯ã‚¨ãƒªã‚’å–å¾—
            queries = all_queries_dict.get(role, [])
            
            if not queries:
                yield f"  - {i+1}/{num_agents}: ã€Œ{role}ã€ ã¯ã‚¯ã‚¨ãƒªã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚èª¿æŸ»ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚"
                updated_agents.append(agent_context) # èª¿æŸ»æƒ…å ±ãªã—ã§è¿½åŠ 
                continue

            # (v15.0ã®ã¾ã¾) ã‚¯ã‚¨ãƒªã§Tavilyæ¤œç´¢ï¼ˆå…¨æ–‡å–å¾—ï¼‰ã‚’å®Ÿè¡Œ
            yield f"  - {i+1}/{num_agents}: ã€Œ{role}ã€ ãŒèª¿æŸ»ã‚’å®Ÿè¡Œä¸­ (ã‚¯ã‚¨ãƒª: {', '.join(queries)})..."
            agent_search_results = []
            for q in queries:
                if not q.strip(): continue
                tavily_resp = self.tavily.search(q, num_results=self.tavily_results_per_agent_query)
                if isinstance(tavily_resp, dict) and "results" in tavily_resp:
                    agent_search_results.extend(tavily_resp["results"])
                elif isinstance(tavily_resp, dict) and "error" in tavily_resp:
                     yield f"  - Tavily ã‚¨ãƒ©ãƒ¼ (ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ã‚¨ãƒª: {q}): {tavily_resp['error']}"

            if not agent_search_results:
                yield f"  - è­¦å‘Š: ã€Œ{role}ã€ ã¯èª¿æŸ»çµæœã‚’å¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚èª¿æŸ»ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚"
                updated_agents.append(agent_context) # èª¿æŸ»æƒ…å ±ãªã—ã§è¿½åŠ 
                continue

            # (v15.0ã®ã¾ã¾) å…¨æ–‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ•´å½¢
            raw_content_text = self._format_raw_content_for_llm(
                agent_search_results,
                f"AGENT {i+1} RESEARCH",
                max_items=self.tavily_results_per_agent_query * 2, # ã‚¯ã‚¨ãƒª2å€‹åˆ†
                truncate_chars=3000 
            )

            # (v15.0ã®ã¾ã¾) å…¨æ–‡ã‚’LLMã§åˆ†æã—ã€ç®‡æ¡æ›¸ãã®æ´å¯Ÿã‚’æŠ½å‡º
            yield f"  - {i+1}/{num_agents}: ã€Œ{role}ã€ ãŒèª¿æŸ»çµæœï¼ˆå…¨æ–‡ï¼‰ã‚’åˆ†æã—ã€æ´å¯Ÿã‚’æŠ½å‡ºä¸­..."
            analysis_prompt = self.prompter.get_agent_specific_analysis_prompt(
                problem_statement,
                role,
                instructions,
                raw_content_text
            )
            analysis_response = self._call_llm(analysis_prompt)
            
            insights = []
            if isinstance(analysis_response, dict) and "key_insights" in analysis_response and isinstance(analysis_response["key_insights"], list):
                insights = analysis_response["key_insights"]
            else:
                yield f"  - è­¦å‘Š: ã€Œ{role}ã€ ã®åˆ†æã«å¤±æ•—ã€‚ (Debug: {analysis_response})"
            
            # (v15.0ã®ã¾ã¾) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¾æ›¸ã«èª¿æŸ»çµæœ (`agent_research_insights`) ã‚’æ³¨å…¥
            agent_context["agent_research_insights"] = insights
            updated_agents.append(agent_context)
            yield f"  - {i+1}/{num_agents}: ã€Œ{role}ã€ ãŒ {len(insights)} å€‹ã®å€‹åˆ¥æ´å¯Ÿã‚’ç²å¾—ã€‚"

        yield f"--- âœ”ï¸ å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å€‹åˆ¥èª¿æŸ»ãŒå®Œäº† ---"
        return updated_agents # èª¿æŸ»æƒ…å ±ãŒæ³¨å…¥ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’è¿”ã™


    # === â˜…v16.0: ä¿®æ­£ (v15.0 ã®ãƒã‚°ä¿®æ­£) ===
    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        """
        (v16.0) Tavilyç‰ˆã®ãƒ•ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ
        1. èª²é¡Œæ–‡ã®äº‹å‰è£œå¼· (v14)
        2. ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ç·¨æˆ (v13)
        3. â˜…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥èª¿æŸ» (v16)â˜…
        4. å®Ÿè¡Œã‚µã‚¤ã‚¯ãƒ« (v15)
        """
        self.history = []

        # --- ã‚¹ãƒ†ãƒƒãƒ—1: èª²é¡Œæ–‡ã®äº‹å‰è£œå¼· (v14.0ãƒ­ã‚¸ãƒƒã‚¯) ---
        yield "--- ğŸ’¡ èª²é¡Œæ–‡è£œå¼·ã®ãŸã‚ã€LLMãŒæœ€é©ãªæ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆãƒ•ã‚§ãƒ¼ã‚º1 & 2ï¼‰ã‚’ç”Ÿæˆä¸­... ---"
        prompt = self.prompter.get_tavily_multi_phase_query_prompt(problem_statement)
        query_response = self._call_llm(prompt)

        augmented_problem = problem_statement 

        if not isinstance(query_response, dict) or ("analysis_queries" not in query_response and "solution_queries" not in query_response):
            yield f"ã‚¨ãƒ©ãƒ¼: Tavilyã‚¯ã‚¨ãƒªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™: {query_response}"
        else:
            analysis_queries = query_response.get("analysis_queries", [])
            solution_queries = query_response.get("solution_queries", [])
            
            yield f"--- âœ”ï¸ èª²é¡Œè£œå¼·ç”¨ã‚¯ã‚¨ãƒªç”Ÿæˆå®Œäº† ---"
            
            analysis_results_list = []
            solution_results_list = []
            
            if analysis_queries:
                yield "--- ğŸŒ (èª²é¡Œè£œå¼·) ãƒ•ã‚§ãƒ¼ã‚º1: ç¾çŠ¶åˆ†æãƒªã‚µãƒ¼ãƒ (å…¨æ–‡å–å¾—) ã‚’é–‹å§‹... ---"
                for q in analysis_queries:
                    if not q.strip(): continue
                    yield f"  - æ¤œç´¢ä¸­ (åˆ†æ): {q}"
                    tavily_resp = self.tavily.search(q, num_results=self.tavily_results_for_augmentation)
                    if isinstance(tavily_resp, dict) and "results" in tavily_resp:
                        analysis_results_list.extend(tavily_resp["results"])
            
            if solution_queries:
                yield "--- ğŸŒ (èª²é¡Œè£œå¼·) ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–äº‹ä¾‹ãƒªã‚µãƒ¼ãƒ (å…¨æ–‡å–å¾—) ã‚’é–‹å§‹... ---"
                for q in solution_queries:
                    if not q.strip(): continue
                    yield f"  - æ¤œç´¢ä¸­ (è§£æ±ºç­–): {q}"
                    tavily_resp = self.tavily.search(q, num_results=self.tavily_results_for_augmentation)
                    if isinstance(tavily_resp, dict) and "results" in tavily_resp:
                        solution_results_list.extend(tavily_resp["results"])

            yield {"tavily_info_analysis": analysis_results_list, "tavily_info_solution": solution_results_list}

            yield "--- âœï¸ (èª²é¡Œè£œå¼·) Webãƒšãƒ¼ã‚¸å…¨æ–‡ã‚’LLMãŒæ·±å±¤åˆ†æã—ã€å•é¡Œæ–‡ã«çµ±åˆã—ã¾ã™... ---"
            try:
                augmented_problem = self._summarize_multi_phase_results_with_llm(
                    problem_statement, 
                    analysis_results_list, 
                    solution_results_list
                )
            except Exception as e:
                yield f"è­¦å‘Š: Tavily æ·±å±¤åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        
        yield {"augmented_problem": augmented_problem}

        # --- ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ç·¨æˆ (v13.0ãƒ­ã‚¸ãƒƒã‚¯) ---
        yield "--- ğŸ§  è£œå¼·ã•ã‚ŒãŸèª²é¡Œã‚’åˆ†æã—ã€æœ€é©ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ã‚’ç·¨æˆä¸­... ---"
        agent_personas = self._generate_agent_personas(augmented_problem) 

        if not agent_personas or "error" in agent_personas or not all(k in agent_personas for k in ["solver_agents", "evaluators", "output_labels"]):
            yield "ã‚¨ãƒ©ãƒ¼: ãƒãƒ¼ãƒ ç·¨æˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚"
            yield f"**ãƒ‡ãƒãƒƒã‚°æƒ…å ±:** AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™ã€‚APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n```\n{agent_personas}\n```"
            return

        yield f"--- âœ”ï¸ ãƒãƒ¼ãƒ ç·¨æˆå®Œäº† ---"
        yield {"agent_team": agent_personas} 

        # --- ã‚¹ãƒ†ãƒƒãƒ—3: â˜…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥èª¿æŸ» (v16.0 æ–°ãƒ­ã‚¸ãƒƒã‚¯)â˜… ---
        
        # â˜…v16.0 ä¿®æ­£: v15.0 ã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿å‡¦ç†ã®ãƒã‚°ã‚’ä¿®æ­£ã€‚
        # `yield from` ã‚’ä½¿ã„ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã® `return` å€¤ã‚’æ­£ã—ãå—ã‘å–ã‚‹ã€‚
        updated_agents_list = yield from self._run_agent_specific_research(
            augmented_problem, 
            agent_personas["solver_agents"]
        )

        if not updated_agents_list:
             yield "è­¦å‘Š: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å€‹åˆ¥èª¿æŸ»ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚èª¿æŸ»æƒ…å ±ãªã—ã§ç¶šè¡Œã—ã¾ã™ã€‚"
             updated_agents_list = agent_personas["solver_agents"] # å…ƒã®ãƒªã‚¹ãƒˆã§ç¶šè¡Œ

        # èª¿æŸ»æƒ…å ±ãŒæ³¨å…¥ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒªã‚¹ãƒˆã§ `agent_personas` ã‚’ä¸Šæ›¸ã
        agent_personas["solver_agents"] = updated_agents_list
        
        # (v15.0)ã€Œèª¿æŸ»æƒ…å ±ãŒè¿½åŠ ã•ã‚ŒãŸã€å®Œå…¨ãªãƒãƒ¼ãƒ æƒ…å ±ã‚’UIã«å†é€ä¿¡
        yield {"agent_team_updated": agent_personas}


        # --- ã‚¹ãƒ†ãƒƒãƒ—4: å®Ÿè¡Œã‚µã‚¤ã‚¯ãƒ« (v15.0) ---
        yield from super().solve_internal(augmented_problem, agent_personas, generations)


# ----------------------------
# 6) Streamlit UI (v15.0ã®ã¾ã¾å¤‰æ›´ãªã—)
# ----------------------------
st.set_page_config(page_title="EvoGen AI + Tavily (Agent Research)", layout="wide")
st.title("EvoGen AI ğŸ§¬")
st.markdown("é€²åŒ–å‹ç”ŸæˆAIè§£æ¢ç´¢ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ (v16.0: ãƒãƒƒãƒã‚¯ã‚¨ãƒªæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«)")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    gemini_key = st.text_input("Google Gemini API Key", type="password", help="Gemini ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    tavily_key = st.text_input("Tavily API Key", type="password", help="Tavily ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    st.subheader("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    num_generations = st.slider("ä¸–ä»£æ•°", 1, 20, 2, help="ææ¡ˆã‚’é€²åŒ–ã•ã›ã‚‹å›æ•°ã§ã™ã€‚")
    num_solutions = st.slider("ä¸–ä»£ã”ã¨ã®(æœ€å¤§)ææ¡ˆã®æ•°", 3, 10, 10, help="ç¬¬1ä¸–ä»£ä»¥é™ã«ç”Ÿæˆãƒ»è©•ä¾¡ã™ã‚‹ææ¡ˆã®æ•°ã§ã™ã€‚(ç¬¬0ä¸–ä»£ã¯å¸¸ã«10å€‹)")
    tavily_results_per_search = st.slider(
        "Tavily æ¤œç´¢çµæœæ•° (ã‚¯ã‚¨ãƒªæ¯)", 1, 10, 4, 
        help="""
        èª²é¡Œè£œå¼·ãƒ•ã‚§ãƒ¼ã‚º: ã“ã®æ•°ã ã‘æ¤œç´¢ã—ã¾ã™ (ä¾‹: 4ä»¶)ã€‚\n
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå€‹åˆ¥èª¿æŸ»ãƒ•ã‚§ãƒ¼ã‚º: ã“ã®æ•°ã‚’2ï¼ˆã‚¯ã‚¨ãƒªæ•°ï¼‰ã§å‰²ã£ãŸæ•°ã‚’ã€ã‚¯ã‚¨ãƒªã”ã¨ã«æ¤œç´¢ã—ã¾ã™ (ä¾‹: 4ãªã‚‰2ä»¶ãšã¤)ã€‚
        """
    ) 
    st.markdown("---")
    st.info("Tavily ã‚’ä½¿ã£ã¦èª²é¡Œã«é–¢é€£ã™ã‚‹**Webãƒšãƒ¼ã‚¸ã®å…¨æ–‡**ã‚’å–å¾—ã—ã€LLMãŒ**è©³ç´°åˆ†æ**ã—ãŸä¸Šã§èª²é¡Œæ–‡ã‚’è£œå¼·ã—ã¾ã™ã€‚")

# (v13.0äº’æ›)
default_problem = """
# èª²é¡Œ
ä¸­å°ä¼æ¥­ã®çµŒç†éƒ¨é–€ã«ãŠã‘ã‚‹ã€è«‹æ±‚æ›¸å‡¦ç†ã®æ¥­å‹™åŠ¹ç‡ã‚’åŠ‡çš„ã«æ”¹å–„ã™ã‚‹
æ–°ã—ã„AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã›ã‚ˆã€‚

# è¦ä»¶ãƒ»åˆ¶ç´„æ¡ä»¶
- å°å…¥ã‚³ã‚¹ãƒˆãŒä½ã„ã“ã¨ã€‚ï¼ˆæœˆé¡5ä¸‡å††ä»¥ä¸‹ï¼‰
- å°‚é–€çš„ãªITçŸ¥è­˜ãŒãªãã¦ã‚‚åˆ©ç”¨ã§ãã‚‹ã“ã¨ã€‚
- æ—¢å­˜ã®ä¼šè¨ˆã‚½ãƒ•ãƒˆï¼ˆä¾‹: freee, MFã‚¯ãƒ©ã‚¦ãƒ‰ï¼‰ã¨é€£æºã§ãã‚‹ã“ã¨ãŒæœ›ã¾ã—ã„ã€‚
"""
problem_statement = st.text_area("è§£æ±ºã—ãŸã„èª²é¡Œï¼ˆã¾ãŸã¯å‰µä½œã—ãŸã„ãŠé¡Œï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=default_problem, height=260, help="ä¾‹: ã€Œä¸­å°ä¼æ¥­ã®è«‹æ±‚æ›¸å‡¦ç†ã‚’æ”¹å–„ã™ã‚‹AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã›ã‚ˆã€ ã‚„ ã€Œã€æ˜¥ã€ã‚’ãƒ†ãƒ¼ãƒã«ã—ãŸæ–¬æ–°ãªä¿³å¥ã‚’5ã¤è€ƒãˆã¦ã€")

# (v13.0äº’æ›)
if st.button("ææ¡ˆã®ç”Ÿæˆã‚’é–‹å§‹", type="primary"):
    if not gemini_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Google Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not tavily_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Tavily APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not problem_statement.strip():
        st.warning("èª²é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        # (v13.0)
        default_labels = {"main_label": "ææ¡ˆ (åç§°/å‰µä½œç‰©)", "details_label": "è©³ç´° (å†…å®¹/ç†ç”±)"}
        st.session_state.output_labels = default_labels
        
        status_placeholder = st.empty()
        team_placeholder = st.empty()
        augmented_problem_placeholder = st.container() 
        tavily_placeholder = st.container() 
        results_area = st.container()
        final_result_placeholder = st.container()

        with st.spinner("ğŸŒ€ AIãŒæ€è€ƒä¸­ã§ã™... (Webãƒšãƒ¼ã‚¸ã®å…¨æ–‡åˆ†æã‚’å«ã‚€ãŸã‚æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)"):
            try:
                gemini_client = GeminiClient(api_key=gemini_key)
                tavily_client = TavilyClient(api_key=tavily_key)
            except Exception as e:
                st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()

            # â˜…v16.0: ã“ã“ã§ `EvoGenSolver_Tavily` ãŒã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã•ã‚Œã‚‹
            solver = EvoGenSolver_Tavily(
                llm_client=gemini_client,
                tavily_client=tavily_client,
                num_solutions_per_generation=num_solutions,
                tavily_results_per_search=tavily_results_per_search
            )
            
            # (v14.0äº’æ›)
            def display_tavily_results(results_list, title):
                with tavily_placeholder.container():
                    st.subheader(title)
                    if results_list:
                        for r in results_list:
                            title = r.get("title", "No title")
                            url = r.get("url", "")
                            st.markdown(f"- [{title}]({url})")
                    else:
                        st.write("ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.markdown("---")


            # --- Solverã‚’å®Ÿè¡Œã—ã€çµæœã‚’UIã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º ---
            for result in solver.solve(problem_statement, generations=num_generations):
                if isinstance(result, str):
                    status_placeholder.info(result) 

                # (v14.0äº’æ›)
                elif isinstance(result, dict) and ("tavily_info_analysis" in result or "tavily_info_solution" in result):
                    tavily_placeholder.empty()
                    analysis_data = result.get("tavily_info_analysis", [])
                    solution_data = result.get("tavily_info_solution", [])
                    if analysis_data:
                        display_tavily_results(analysis_data, "ğŸŒ (èª²é¡Œè£œå¼·) ãƒ•ã‚§ãƒ¼ã‚º1: ç¾çŠ¶åˆ†æãƒªã‚µãƒ¼ãƒçµæœ")
                    if solution_data:
                        display_tavily_results(solution_data, "ğŸŒ (èª²é¡Œè£œå¼·) ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–äº‹ä¾‹ãƒªã‚µãƒ¼ãƒçµæœ")
                
                # (v14.0äº’æ›)
                elif isinstance(result, dict) and "augmented_problem" in result:
                    with augmented_problem_placeholder.container():
                        st.subheader("ğŸ” ãƒªã‚µãƒ¼ãƒçµæœã§è£œå¼·ã•ã‚ŒãŸèª²é¡Œæ–‡ (LLMè©³ç´°åˆ†æ)")
                        with st.expander("è£œå¼·ã•ã‚ŒãŸèª²é¡Œæ–‡ã®è©³ç´°ã‚’è¡¨ç¤º", expanded=False): 
                            st.markdown(result["augmented_problem"])
                        st.markdown("---")
                
                # (v15.0äº’æ›)
                elif isinstance(result, dict) and ("agent_team" in result or "agent_team_updated" in result):
                    
                    team_data_key = "agent_team_updated" if "agent_team_updated" in result else "agent_team"
                    team = result[team_data_key]

                    if "output_labels" in team:
                        st.session_state.output_labels = team["output_labels"]
                    
                    with team_placeholder.container():
                        st.subheader("ğŸ¤– ç·¨æˆã•ã‚ŒãŸAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ")
                        
                        labels_to_show = st.session_state.output_labels
                        st.markdown(f"**æˆæœç‰©ãƒ©ãƒ™ãƒ«:** `{labels_to_show.get('main_label')}` / `{labels_to_show.get('details_label')}`")

                        is_updated = (team_data_key == "agent_team_updated")
                        with st.expander("ãƒãƒ¼ãƒ ã®è©³ç´°ã‚’è¡¨ç¤º", expanded=is_updated):
                            st.markdown("##### ğŸ’¡ğŸ§¬ è§£æ±ºãƒ»é€²åŒ–æ‹…å½“ (10ä½“)")
                            gen_list = team.get("solver_agents", [])
                            if gen_list:
                                for i, gen in enumerate(gen_list):
                                    st.markdown(f"**{i+1}. {gen.get('role', 'æœªå®šç¾©')}**")
                                    st.caption(f"æŒ‡ç¤º: {gen.get('instructions', 'æœªå®šç¾©')}")
                                    
                                    # (v15.0) å€‹åˆ¥èª¿æŸ»æƒ…å ±ã‚’è¡¨ç¤º
                                    insights = gen.get("agent_research_insights")
                                    if insights:
                                        with st.container(border=True):
                                            st.markdown(f"**å€‹åˆ¥ã®èª¿æŸ»æƒ…å ± (æ´å¯Ÿ):**")
                                            insights_md = "\n".join([f"  - {item}" for item in insights])
                                            st.markdown(insights_md)
                                    elif is_updated:
                                        st.caption("ï¼ˆã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯å€‹åˆ¥èª¿æŸ»ã«å¤±æ•—ã€ã¾ãŸã¯çµæœã‚¼ãƒ­ï¼‰")
                            
                            st.markdown("---")
                            st.markdown("##### ğŸ§ è©•ä¾¡æ‹…å½“ (3ä½“)") 
                            eva_list = team.get("evaluators", [])
                            if eva_list:
                                for i, eva in enumerate(eva_list):
                                    st.markdown(f"**{i+1}. {eva.get('role', 'N/A')}**")
                                    guideline = eva.get('evaluation_guideline', 'è©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æœªå®šç¾©')
                                    st.caption(f"ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³: {guideline}")

                # (v13.0äº’æ›)
                elif isinstance(result, dict) and "generation" in result:
                    labels = st.session_state.output_labels
                    
                    gen_data = result
                    with results_area.container():
                        st.subheader(f"ç¬¬ {gen_data['generation']} ä¸–ä»£ã®çµæœ")
                        with st.container(border=True):
                            if not gen_data.get('results'):
                                st.write("ã“ã®ä¸–ä»£ã§ã¯æœ‰åŠ¹ãªææ¡ˆãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                                continue
                            
                            for item in gen_data.get('results', []):
                                sol = item.get('solution', {})
                                eva = item.get('evaluation', {})
                                score = eva.get('total_score', 0)
                                
                                st.markdown(f"**{labels.get('main_label', 'ææ¡ˆ')}:** {sol.get('proposal_main', 'N/A')} (ã‚¹ã‚³ã‚¢: {score})")
                                st.markdown(f"**{labels.get('details_label', 'è©³ç´°')}:**\n {sol.get('proposal_details', 'N/A')}")
                                
                                if item != gen_data.get('results', [])[-1]:
                                    st.markdown("---")

        # (v13.0äº’æ›)
        all_solutions = [
            item for gen in solver.history
            for item in gen.get("results", [])
            if item.get("evaluation") and "total_score" in item["evaluation"]
        ]

        if all_solutions:
            sorted_solutions = sorted(
                all_solutions,
                key=lambda x: x["evaluation"]["total_score"],
                reverse=True
            )
            
            top_5_solutions = sorted_solutions[:5]
            
            labels = st.session_state.output_labels

            status_placeholder.empty()
            st.balloons()

            with final_result_placeholder:
                st.success("ğŸ† å‡¦ç†å®Œäº†ï¼ã‚¹ã‚³ã‚¢ãƒˆãƒƒãƒ—5ã®ææ¡ˆã¯ã“ã¡ã‚‰ã§ã™ã€‚")
                
                for i, item in enumerate(top_5_solutions):
                    sol = item.get('solution', {})
                    eva = item.get('evaluation', {})
                    score = eva.get('total_score', 'N/A')
                    
                    st.header(f"ğŸ… ç¬¬ {i + 1} ä½")
                    st.metric(label="æœ€çµ‚ã‚¹ã‚³ã‚¢ (3ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¹³å‡)", value=f"{score}")

                    st.info(f"**{labels.get('main_label', 'ææ¡ˆ')}**\n\n{sol.get('proposal_main', 'N/A')}")
                    st.info(f"**{labels.get('details_label', 'è©³ç´°')}**\n\n{sol.get('proposal_details', 'N/A')}")

                    # è©•ä¾¡ã‚’è¡¨ç¤º
                    col1, col2 = st.columns(2)
                    with col1:
                        st.success(f"**å„ªã‚ŒãŸç‚¹ (3åã®è©•ä¾¡è€…ã‚ˆã‚Š)**")
                        st.text_area(
                            f"å„ªã‚ŒãŸç‚¹ {i+1}", 
                            value=eva.get('strengths', 'N/A'), 
                            height=250, 
                            disabled=True,
                            label_visibility="collapsed"
                        )
                    with col2:
                        st.warning(f"**æ‡¸å¿µç‚¹ãƒ»æ”¹å–„ç‚¹ (3åã®è©•ä¾¡è€…ã‚ˆã‚Š)**")
                        st.text_area(
                            f"æ‡¸å¿µç‚¹ãƒ»æ”¹å–„ç‚¹ {i+1}", 
                            value=eva.get('weaknesses', 'N/A'), 
                            height=250, 
                            disabled=True,
                            label_visibility="collapsed"
                        )
                    
                    st.info(f"**ç·è©• (3åã®è©•ä¾¡è€…ã‚ˆã‚Š)**")
                    st.text_area(
                        f"ç·è©• {i+1}",
                        value=eva.get('overall_comment', 'N/A'),
                        height=200,
                        disabled=True,
                        label_visibility="collapsed"
                    )
                    
                    st.markdown("---")
        else:
            status_placeholder.warning("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸãŒã€æœ€çµ‚çš„ãªææ¡ˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")