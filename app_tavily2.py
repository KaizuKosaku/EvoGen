# app_tavily.py (ä¿®æ­£ç‰ˆ)
"""
EvoGen AI with Tavily integration

ä½¿ã„æ–¹:
  - å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
      pip install streamlit requests google-generativeai
  - å®Ÿè¡Œ:
      streamlit run app_tavily.py
"""

import streamlit as st
import os
import json
import abc
from typing import List, Dict, Any, Generator, Optional
import time

# --- å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ ---
try:
    import google.generativeai as genai
except Exception:
    genai = None

try:
    import requests
except ImportError:
    requests = None

# ----------------------------
# 1) LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå±¤ (æ—¢å­˜)
# ----------------------------
class LLMClient(abc.ABC):
    """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åŸºæœ¬ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹"""
    @abc.abstractmethod
    def call(self, prompt: str) -> Dict[str, Any]:
        pass

class GeminiClient(LLMClient):
    """Google Gemini ç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆæ—¢å­˜å®Ÿè£…ã‚’è¸è¥²ï¼‰"""
    def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"):
        if genai is None:
            raise ImportError("`google-generativeai`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install google-generativeai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
        # ã“ã“ã§ã¯ generative model ã« JSON ã‚’è¿”ã•ã›ã‚‹æƒ³å®šã§è¨­å®šã‚’ä½¿ã†
        self.generation_config = genai.GenerationConfig(
            response_mime_type="application/json"
        )

    def call(self, prompt: str) -> Dict[str, Any]:
        """
        prompt -> LLM å‘¼ã³å‡ºã— -> JSON ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
        è¿”ã‚Šå€¤: dictï¼ˆå¤±æ•—æ™‚ã¯ {"error": "...", "raw": "<text>"} ã‚’è¿”ã™ï¼‰
        """
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            # Gemini ã®å ´åˆ response.text ã«æ–‡å­—åˆ—ãŒã‚ã‚‹æƒ³å®š
            text = getattr(response, "text", None) or getattr(response, "response", None) or str(response)
            try:
                return json.loads(text)
            except Exception:
                # JSON ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯ raw ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿”ã™
                return {"raw_text": text}
        except Exception as e:
            # Streamlitä¸Šã§ã‚‚è¦‹ãˆã‚‹ã‚ˆã†ã«ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ãŒã€æˆ»ã‚Šå€¤ã¯ dict ã§
            st.error(f"[GeminiClient Error] API å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return {"error": str(e)}

# ----------------------------
# 2) Tavily ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (æ—¢å­˜)
# ----------------------------
class TavilyClient:
    """
    Tavily Search API ã¨ã®ã‚„ã‚Šå–ã‚Šã‚’è¡Œã†ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€‚
    """
    DEFAULT_ENDPOINT = "https://api.tavily.com/search"

    def __init__(self, api_key: str, endpoint: str = DEFAULT_ENDPOINT, timeout: int = 15):
        if requests is None:
            raise ImportError("`requests`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install requests ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        self.api_key = api_key
        self.endpoint = endpoint
        self.timeout = timeout

    def search(self, query: str, num_results: int = 5, domain: Optional[str] = None, lang: Optional[str] = None) -> Dict[str, Any]:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {"query": query, "max_results": num_results}
        if domain:
            payload["domain"] = domain
        if lang:
            payload["language"] = lang

        try:
            resp = requests.post(self.endpoint, headers=headers, json=payload, timeout=self.timeout)
            resp.raise_for_status()
            data = resp.json()
            return data
        except requests.exceptions.RequestException as e:
            return {"error": f"HTTP error: {e}"}
        except ValueError as e:
            return {"error": f"JSON parse error: {e}", "raw": resp.text if 'resp' in locals() else None}
        except Exception as e:
            return {"error": str(e)}

# ----------------------------
# 3) PromptManagerï¼ˆä¿®æ­£ï¼‰
# ----------------------------
class PromptManager:
    """AIã¸ã®æŒ‡ç¤ºæ›¸ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    # --- æ–°è¦è¿½åŠ ãƒ¡ã‚½ãƒƒãƒ‰ ---
    def get_tavily_query_generation_prompt(self, problem_statement: str) -> str:
        """
        èª²é¡Œè§£æ±ºã«å¿…è¦ãªæƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’LLMã«ç”Ÿæˆã•ã›ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
        """
        return f"""
        ã‚ãªãŸã¯ã€æç¤ºã•ã‚ŒãŸã€Œèª²é¡Œã€ã®è§£æ±ºç­–ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã§æœ€æ–°æƒ…å ±ã‚„äº‹ä¾‹ã‚’æ¤œç´¢ã™ã‚‹å°‚é–€ã®èª¿æŸ»å“¡ã§ã™ã€‚
        
        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’åˆ†æã—ã€**ãã®è§£æ±ºç­–ã‚’è€ƒæ¡ˆã™ã‚‹ãŸã‚ã«**æœ€ã‚‚æœ‰ç”¨ãªæƒ…å ±ã‚’å–å¾—ã§ãã‚‹ã€å…·ä½“çš„ãª**æ—¥æœ¬èªã®æ¤œç´¢ã‚¯ã‚¨ãƒª**ã‚’3ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        ç”Ÿæˆã™ã‚‹ã‚¯ã‚¨ãƒªã¯ã€å˜ãªã‚‹èª²é¡Œã®è¨€ã„æ›ãˆã§ã¯ãªãã€
        ã€Œæœ€æ–°ã®å¯¾ç­–äº‹ä¾‹ã€ã€Œé–¢é€£ã™ã‚‹æŠ€è¡“ã®å‹•å‘ã€ã€Œå…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ã‚„åˆ¶ç´„æ¡ä»¶ã€ã¨ã„ã£ãŸã€è§£æ±ºç­–ã®è³ªã‚’é«˜ã‚ã‚‹ãŸã‚ã®**ãƒ•ã‚¡ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹ã®æƒ…å ±**ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚

        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "queries": [
            "èª²é¡Œè§£æ±ºã®ãŸã‚ã®æƒ…å ±æ¤œç´¢ã‚¯ã‚¨ãƒª1 (æ—¥æœ¬èª)",
            "èª²é¡Œè§£æ±ºã®ãŸã‚ã®æƒ…å ±æ¤œç´¢ã‚¯ã‚¨ãƒª2 (æ—¥æœ¬èª)",
            "èª²é¡Œè§£æ±ºã®ãŸã‚ã®æƒ…å ±æ¤œç´¢ã‚¯ã‚¨ãƒª3 (æ—¥æœ¬èª)"
          ]
        }}
        """
    # -----------------------

    def get_agent_personas_prompt(self, problem_statement: str) -> str:
        return f"""
        # å½¹å‰²
        ã‚ãªãŸã¯ã€éå¸¸ã«è¤‡é›‘ãªèª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ãªã‚‹ãƒ‰ãƒªãƒ¼ãƒ ãƒãƒ¼ãƒ ã‚’ç·¨æˆã™ã‚‹ã€Œãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€ã§ã™ã€‚
        # ã‚¿ã‚¹ã‚¯
        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’æ·±ãåˆ†æã—ã€ã“ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«æœ€ã‚‚åŠ¹æœçš„ãªæ€è€ƒãƒãƒ¼ãƒ ã‚’ç·¨æˆã—ã¦ãã ã•ã„ã€‚
        ãƒãƒ¼ãƒ ã¯ä»¥ä¸‹ã®3ä½“ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã¾ã™ã€‚ãã‚Œãã‚Œã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¤ã„ã¦ã€ãã®å½¹å‰²ï¼ˆãƒšãƒ«ã‚½ãƒŠï¼‰ã¨å…·ä½“çš„ãªè¡Œå‹•æŒ‡ç¤ºã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚

        1. **initial_generator (åˆæœŸã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆæ‹…å½“):**
            - **role:** ã©ã®ã‚ˆã†ãªå°‚é–€æ€§ã‚„æ€§æ ¼ã‚’æŒã¤ã¹ãã‹ï¼Ÿ
            - **instructions:** ã©ã®ã‚ˆã†ãªè¦³ç‚¹ã‹ã‚‰ã€ã©ã®ã‚ˆã†ã«å¤šæ§˜ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å‡ºã™ã¹ãã‹ï¼Ÿ

        2. **evaluator (è©•ä¾¡æ‹…å½“):**
            - **role:** ã©ã®ã‚ˆã†ãªè¦–ç‚¹ã‹ã‚‰ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è©•ä¾¡ã™ã¹ãã‹ï¼Ÿ
            - **criteria:** ã“ã®èª²é¡Œã«ç‰¹åŒ–ã—ãŸè©•ä¾¡åŸºæº–ã‚’3ã¤å®šç¾©ã—ã€é‡è¦åº¦ã«å¿œã˜ã¦åˆè¨ˆ100ç‚¹ã«ãªã‚‹ã‚ˆã†ã«é…ç‚¹ã—ã¦ãã ã•ã„ã€‚

        3. **synthesizer (é€²åŒ–ãƒ»çµ±åˆæ‹…å½“):**
            - **role:** ã©ã®ã‚ˆã†ã«ã—ã¦ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ã‚ˆã‚Šå„ªã‚ŒãŸã‚‚ã®ã¸ã¨é€²åŒ–ã•ã›ã‚‹ã¹ãã‹ï¼Ÿ
            - **instructions:** é«˜è©•ä¾¡æ¡ˆã¨ä½è©•ä¾¡æ¡ˆã‚’ã©ã®ã‚ˆã†ã«åˆ†æã—ã€æ¬¡ä¸–ä»£ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆã™ã¹ãã‹å…·ä½“çš„ãªæŒ‡ç¤ºã‚’ä¸ãˆã¦ãã ã•ã„ã€‚

        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "initial_generator": {{"role": "...", "instructions": "..."}},
          "evaluator": {{"role": "...", "criteria": [{{"criterion": "...", "weight": 10}}]}},
          "synthesizer": {{"role": "...", "instructions": "..."}}
        }}
        """

    def get_initial_generation_prompt(self, problem_statement: str, num_solutions: int, context: Dict[str, str]) -> str:
        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯ä¸€æµã®ã‚¤ãƒãƒ™ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', f'ä»¥ä¸‹ã®èª²é¡Œã«å¯¾ã—ã€äº’ã„ã«å…¨ãç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‹ã‚‰ã®è§£æ±ºç­–ã‚’{num_solutions}å€‹ææ¡ˆã—ã¦ãã ã•ã„ã€‚')}
        # èª²é¡Œæ–‡: {problem_statement}
        # å‡ºåŠ›å½¢å¼: å„è§£æ±ºç­–ã«ã€Œnameã€ã€Œsummaryã€ã€Œspecific_methodã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        {{ "solutions": [ {{ "name": "è§£æ±ºç­–1", "summary": "æ¦‚è¦1", "specific_method": "å…·ä½“çš„æ–¹æ³•1" }} ] }}
        """

    def get_evaluation_prompt(self, solution: Dict[str, str], problem_statement: str, context: Dict[str, Any]) -> str:
        criteria_text = []
        scores_json_structure = []
        if "criteria" in context and isinstance(context["criteria"], list):
            for item in context["criteria"]:
                criterion = item.get("criterion", "ä¸æ˜ãªåŸºæº–")
                weight = item.get("weight", 0)
                criteria_text.append(f"- {criterion}: {weight}ç‚¹")
                scores_json_structure.append(f'"{criterion}": ç‚¹æ•°(æ•´æ•°)')

        criteria_prompt_part = "\n".join(criteria_text)
        scores_json_prompt_part = f"{{ {', '.join(scores_json_structure)} }}"

        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯å®¢è¦³çš„ã§å³ã—ã„æ‰¹è©•å®¶ã§ã™ã€‚')}
        # ã‚¿ã‚¹ã‚¯: æç¤ºã•ã‚ŒãŸèª²é¡Œã«å¯¾ã—ã€è§£æ±ºæ¡ˆã‚’è©•ä¾¡åŸºæº–ã«åŸºã¥ã„ã¦å³å¯†ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        # èª²é¡Œæ–‡: {problem_statement}
        # è©•ä¾¡å¯¾è±¡ã®è§£æ±ºæ¡ˆ:
        - åç§°: {solution.get('name', 'åç§°ä¸æ˜')}
        - æ¦‚è¦: {solution.get('summary', 'æ¦‚è¦ãªã—')}
        # è©•ä¾¡åŸºæº–:
        {criteria_prompt_part}
        # å‡ºåŠ›å½¢å¼: è©•ä¾¡çµæœã‚’å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        {{
          "total_score": åˆè¨ˆç‚¹(æ•´æ•°),
          "scores": {scores_json_prompt_part},
          "strengths": "ã“ã®è§£æ±ºæ¡ˆãŒå„ªã‚Œã¦ã„ã‚‹ç‚¹",
          "weaknesses": "ã“ã®è§£æ±ºæ¡ˆã®æ‡¸å¿µç‚¹ã‚„æ”¹å–„ãŒå¿…è¦ãªç‚¹",
          "overall_comment": "è©•ä¾¡ã®ç·æ‹¬"
        }}
        """

    def get_next_generation_prompt(self, elite_solutions: List[Dict], failed_solutions: List[Dict], problem_statement: str, num_solutions: int, context: Dict[str, str]) -> str:
        elite_text = "\n".join([f"- {s['solution'].get('name', 'N/A')} (ã‚¹ã‚³ã‚¢: {s['evaluation'].get('total_score', 0)})" for s in elite_solutions])
        failed_text = "\n".join([f"- {s['solution'].get('name', 'N/A')} (å¼±ç‚¹: {s['evaluation'].get('weaknesses', 'N/A')})" for s in failed_solutions])

        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯å„ªã‚ŒãŸæˆ¦ç•¥å®¶ã§ã‚ã‚Šç·¨é›†è€…ã§ã™ã€‚')}
        # ã‚¿ã‚¹ã‚¯: å‰ä¸–ä»£ã®åˆ†æã«åŸºã¥ãã€æ¬¡ä¸–ä»£ã®æ–°ã—ã„è§£æ±ºç­–ã‚’{num_solutions}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        # åˆ†æå¯¾è±¡1ï¼šé«˜è©•ä¾¡ã ã£ãŸè§£æ±ºæ¡ˆï¼ˆå„ªã‚ŒãŸéºä¼å­ï¼‰: 
        {elite_text}
        # åˆ†æå¯¾è±¡2ï¼šä½è©•ä¾¡ã ã£ãŸè§£æ±ºæ¡ˆï¼ˆå­¦ã¶ã¹ãæ•™è¨“ï¼‰: 
        {failed_text}
        # æ–°ã—ã„è§£æ±ºç­–ã®ç”ŸæˆæŒ‡ç¤º: {context.get('instructions', 'é«˜è©•ä¾¡æ¡ˆã®è‰¯ã„ç‚¹ã‚’çµ„ã¿åˆã‚ã›ã€ä½è©•ä¾¡æ¡ˆã®å¤±æ•—ã‹ã‚‰å­¦ã³ã€æ–°ã—ã„è§£æ±ºç­–ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚')}
        
        # å‡ºåŠ›å½¢å¼: å„è§£æ±ºç­–ã«ã€Œnameã€ã€Œsummaryã€ã€Œspecific_methodã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        {{ "solutions": [ {{ "name": "æ–°ã—ã„è§£æ±ºç­–1", "summary": "æ¦‚è¦1", "specific_method": "å…·ä½“çš„æ–¹æ³•1" }} ] }}
        """

# ----------------------------
# 4) EvoGenSolverï¼ˆæ—¢å­˜ï¼‰ + Tavily æ‹¡å¼µ
# ----------------------------
class EvoGenSolver:
    """å…ƒã® EvoGenSolverï¼ˆä¸»è¦ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
    def __init__(self, llm_client: LLMClient, num_solutions_per_generation: int = 5):
        self.client = llm_client
        self.num_solutions = num_solutions_per_generation
        self.prompter = PromptManager()
        self.history = []

    def _call_llm(self, prompt: str) -> Dict[str, Any]:
        return self.client.call(prompt)

    def _generate_agent_personas(self, problem_statement: str) -> Dict:
        prompt = self.prompter.get_agent_personas_prompt(problem_statement)
        return self._call_llm(prompt)

    def _generate_initial_solutions(self, problem_statement: str, context: Dict) -> List[Dict[str, str]]:
        prompt = self.prompter.get_initial_generation_prompt(problem_statement, self.num_solutions, context)
        response = self._call_llm(prompt)
        return response.get("solutions", []) if isinstance(response, dict) else []

    def _evaluate_solutions(self, solutions: List[Dict[str, str]], problem_statement: str, context: Dict) -> Generator[str | List[Dict], None, None]:
        evaluated_solutions = []
        if not solutions:
            yield []
            return

        for i, solution in enumerate(solutions):
            yield f"  - è©•ä¾¡ä¸­ {i+1}/{len(solutions)}: {solution.get('name', 'åç§°ä¸æ˜')}"
            prompt = self.prompter.get_evaluation_prompt(solution, problem_statement, context)
            evaluation = self._call_llm(prompt)
            if evaluation and "error" not in evaluation:
                evaluated_solutions.append({"solution": solution, "evaluation": evaluation})

        evaluated_solutions.sort(key=lambda x: x.get("evaluation", {}).get("total_score", 0), reverse=True)
        yield evaluated_solutions

    def _generate_next_generation(self, evaluated_solutions: List[Dict], problem_statement: str, context: Dict) -> List[Dict[str, str]]:
        num_elites = max(1, int(len(evaluated_solutions) * 0.4))
        elite_solutions = evaluated_solutions[:num_elites]
        failed_solutions = evaluated_solutions[num_elites:]
        prompt = self.prompter.get_next_generation_prompt(elite_solutions, failed_solutions, problem_statement, self.num_solutions, context)
        response = self._call_llm(prompt)
        return response.get("solutions", []) if isinstance(response, dict) else []

    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        self.history = []

        # STEP 1: AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ã®ç·¨æˆ
        yield "--- ğŸ§  èª²é¡Œã‚’åˆ†æã—ã€æœ€é©ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ã‚’ç·¨æˆä¸­... ---"
        agent_personas = self._generate_agent_personas(problem_statement)

        if not agent_personas or "error" in agent_personas or not all(k in agent_personas for k in ["initial_generator", "evaluator", "synthesizer"]):
            yield "ã‚¨ãƒ©ãƒ¼: ãƒãƒ¼ãƒ ç·¨æˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚"
            yield f"**ãƒ‡ãƒãƒƒã‚°æƒ…å ±:** AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™ã€‚APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n```\n{agent_personas}\n```"
            return

        yield f"--- âœ”ï¸ ãƒãƒ¼ãƒ ç·¨æˆå®Œäº† ---"
        yield {"agent_team": agent_personas}

        # STEP 2: æœ€åˆã®ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã¨è©•ä¾¡
        yield "\n--- ğŸ’¡ Generation 0: æœ€åˆã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆä¸­... ---"
        solutions = self._generate_initial_solutions(problem_statement, agent_personas["initial_generator"])

        yield "--- ğŸ§ ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è©•ä¾¡ä¸­... ---"
        eval_generator = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluator"])
        evaluated_solutions = []
        for item in eval_generator:
            if isinstance(item, str):
                yield item
            else:
                evaluated_solutions = item

        self.history.append({"generation": 0, "results": evaluated_solutions})
        yield self.history[-1]

        # STEP 3: ä¸–ä»£ã®é€²åŒ–
        for i in range(1, generations):
            yield f"\n--- ğŸš€ Generation {i}: æ¬¡ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã¸é€²åŒ–ä¸­... ---"
            previous_generation_results = self.history[-1]["results"]

            solutions = self._generate_next_generation(previous_generation_results, problem_statement, agent_personas["synthesizer"])

            if not solutions:
                yield f"ã‚¨ãƒ©ãƒ¼: Generation {i} ã®è§£æ±ºç­–ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIãŒé©åˆ‡ãªå¿œç­”ã‚’è¿”ã•ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
                break

            yield f"--- ğŸ§ Generation {i} ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è©•ä¾¡ä¸­... ---"
            eval_generator_next = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluator"])
            evaluated_solutions_next = []
            for item in eval_generator_next:
                if isinstance(item, str):
                    yield item
                else:
                    evaluated_solutions_next = item

            self.history.append({"generation": i, "results": evaluated_solutions_next})
            yield self.history[-1]

        yield "\n--- âœ… é€²åŒ–ãƒ—ãƒ­ã‚»ã‚¹å®Œäº† ---"

# EvoGenSolver_Tavily: Tavily çµ±åˆç‰ˆï¼ˆä¿®æ­£ï¼‰
class EvoGenSolver_Tavily(EvoGenSolver):
    """
    Tavily ã‚’ç”¨ã„ã¦èª²é¡Œã«é–¢é€£ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’åé›†ã—ã€ãã®æƒ…å ±ã‚’
    å•é¡Œæ–‡ã«çµ„ã¿è¾¼ã‚“ã§ EvoGen ã®ãƒ•ãƒ­ãƒ¼ã‚’å›ã™æ‹¡å¼µç‰ˆã€‚
    """
    def __init__(self, llm_client: LLMClient, tavily_client: TavilyClient, num_solutions_per_generation: int = 5, tavily_results_per_search: int = 5):
        super().__init__(llm_client, num_solutions_per_generation)
        self.tavily = tavily_client
        self.tavily_results_per_search = tavily_results_per_search

    # --- æ–°è¦è¿½åŠ ãƒ¡ã‚½ãƒƒãƒ‰ ---
    def _generate_tavily_query(self, problem_statement: str) -> str:
        """
        LLMã‚’å‘¼ã³å‡ºã—ã€Tavilyæ¤œç´¢ã«æœ€é©ãªã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚
        æœ€åˆã®ã‚¯ã‚¨ãƒªã‚’è¿”ã™ã€‚å¤±æ•—ã—ãŸã‚‰å…ƒã®å•é¡Œæ–‡ã‚’è¿”ã™ã€‚
        """
        prompt = self.prompter.get_tavily_query_generation_prompt(problem_statement)
        response = self._call_llm(prompt)
        
        if isinstance(response, dict) and "queries" in response and isinstance(response["queries"], list) and response["queries"]:
            # æœ€åˆã®ã‚¯ã‚¨ãƒªã‚’è¿”ã™
            return response["queries"][0]
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¾ãŸã¯ä¸æ­£ãªå½¢å¼ã®å ´åˆã¯å…ƒã®å•é¡Œæ–‡ã‚’è¿”ã™
        st.warning(f"LLMã«ã‚ˆã‚‹æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€å•é¡Œæ–‡ã®æœ€åˆã®1è¡Œã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\nãƒ‡ãƒãƒƒã‚°æƒ…å ±: {response}")
        # å•é¡Œæ–‡ã®æœ€åˆã®è¡Œï¼ˆç°¡æ½”ãªã‚¯ã‚¨ãƒªã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„éƒ¨åˆ†ï¼‰ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨
        return problem_statement.strip().split('\n')[0].replace('# èª²é¡Œ', '').strip()
    # -----------------------

    def _summarize_tavily_results_with_llm(self, tavily_results: Dict[str, Any], problem_statement: str) -> str:
        """
        Tavily ã®æ¤œç´¢çµæœã‚’ LLM ã«è¦ç´„ã•ã›ã€å•é¡Œæ–‡ã«çµ±åˆã™ã‚‹ã€‚
        - å¤±æ•—ã—ãŸã‚‰ç°¡æ˜“ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¦ç´„ã‚’è¿”ã™ã€‚
        """
        results = tavily_results.get("results", []) if isinstance(tavily_results, dict) else []
        if not results:
            return problem_statement

        snippet_texts = []
        for r in results[:min(len(results), 8)]:
            title = r.get("title", "")
            snippet = r.get("snippet", "") or r.get("description", "")
            url = r.get("url", "")
            snippet_texts.append(f"Title: {title}\nSnippet: {snippet}\nURL: {url}\n---")

        combined = "\n".join(snippet_texts)
        prompt = f"""
        ä»¥ä¸‹ã¯ã€Tavily ã«ã‚ˆã£ã¦å–å¾—ã•ã‚ŒãŸã‚¦ã‚§ãƒ–æ¤œç´¢çµæœã®æŠœç²‹ã§ã™ã€‚å„çµæœã¯å‡ºå…¸ï¼ˆURLï¼‰ã‚’æŒã¡ã¾ã™ã€‚
        ã‚ãªãŸã¯ã“ã®æƒ…å ±ã‚’3ç‚¹ã‚»ãƒƒãƒˆã§è¦ç´„ã—ã€èª²é¡Œã«ã¨ã£ã¦ã€Œç‰¹ã«é‡è¦ãªäº‹å®Ÿ/ãƒ‡ãƒ¼ã‚¿ã€ã€Œæ½œåœ¨çš„ãªåˆ¶ç´„ã‚„ãƒªã‚¹ã‚¯ã€ã€Œå¼•ç”¨ã™ã¹ãå‡ºå…¸(æœ€å¤§3ã¤)ã€ã‚’ç°¡æ½”ã«æ•´ç†ã—ã¦ä¸‹ã•ã„ã€‚
        å‡ºåŠ›ã¯å¿…ãš JSON å½¢å¼ã§ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã£ã¦ãã ã•ã„:
        {{
          "summary": "ç°¡æ½”ãªè¦ç´„ï¼ˆæ—¥æœ¬èªã€3-4æ–‡ï¼‰",
          "key_points": ["é‡è¦ãªäº‹å®Ÿ1", "é‡è¦ãªäº‹å®Ÿ2"],
          "risks": ["ãƒªã‚¹ã‚¯1", "ãƒªã‚¹ã‚¯2"],
          "top_sources": [{{"title":"...", "url":"..."}}]
        }}

        ### Tavily Results (æŠœç²‹)
        {combined}

        ### å…ƒã®èª²é¡Œ:
        {problem_statement}
        """
        llm_ret = self._call_llm(prompt)
        
        if isinstance(llm_ret, dict):
            if any(k in llm_ret for k in ["summary", "key_points", "top_sources", "risks"]):
                try:
                    summary_text = llm_ret.get("summary", "")
                    kp = llm_ret.get("key_points", [])
                    risks = llm_ret.get("risks", [])
                    top = llm_ret.get("top_sources", [])
                    top_text = "\n".join([f"- {s.get('title','')}: {s.get('url','')}" for s in top]) if isinstance(top, list) else ""
                    composed = f"## Tavilyè¦ç´„ï¼ˆLLMç”Ÿæˆï¼‰\n{summary_text}\n\né‡è¦ç‚¹:\n" + "\n".join([f"- {p}" for p in kp]) + "\n\nãƒªã‚¹ã‚¯:\n" + "\n".join([f"- {r}" for r in risks]) + "\n\nå‡ºå…¸:\n" + top_text + "\n\n" + problem_statement
                    return composed
                except Exception:
                    pass
            if "raw_text" in llm_ret:
                return f"## Tavilyè¦ç´„ï¼ˆrawï¼‰\n{llm_ret['raw_text']}\n\n{problem_statement}"
            if "error" in llm_ret:
                pass

        fallback_sources = []
        for r in results[:3]:
            fallback_sources.append(f"- {r.get('title','No title')} ({r.get('url','')})")
        fallback = "## Tavilyè¦ç´„ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n" + \
                   "æœ€æ–°ã®ã‚¦ã‚§ãƒ–æƒ…å ±ã‚’å‚ç…§ã—ã¾ã—ãŸã€‚ä¸Šä½å‡ºå…¸:\n" + "\n".join(fallback_sources) + "\n\n" + problem_statement
        return fallback

    # --- solveãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£ ---
    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        
        # LLMã«Tavilyæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã•ã›ã‚‹
        yield "--- ğŸ’¡ LLMã«ã‚ˆã‚‹æœ€é©ãªTavilyæ¤œç´¢ã‚¯ã‚¨ãƒªã®ç”Ÿæˆä¸­... ---"
        tavily_query = self._generate_tavily_query(problem_statement)
        yield f"--- âœ”ï¸ ç”Ÿæˆã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒª: **{tavily_query}** ---"
        
        # ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªã§Tavilyæ¤œç´¢ã‚’å®Ÿè¡Œ
        yield "--- ğŸŒ Tavily ã«ã‚ˆã‚‹é–¢é€£æƒ…å ±ã®æ¤œç´¢ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™... ---"
        tavily_resp = self.tavily.search(tavily_query, num_results=self.tavily_results_per_search)

        if not isinstance(tavily_resp, dict) or "error" in tavily_resp:
            err = tavily_resp.get("error", "Unknown error") if isinstance(tavily_resp, dict) else "Unknown Tavily response"
            yield f"ã‚¨ãƒ©ãƒ¼: Tavily API ã®å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {err}"
            return

        yield {"tavily_info": tavily_resp}

        yield "--- âœï¸ Tavily çµæœã‚’è¦ç´„ã—ã€å•é¡Œæ–‡ã«çµ±åˆã—ã¾ã™... ---"
        try:
            augmented_problem = self._summarize_tavily_results_with_llm(tavily_resp, problem_statement)
        except Exception as e:
            augmented_problem = problem_statement
            yield f"è­¦å‘Š: Tavily è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        yield from super().solve(augmented_problem, generations)
    # -----------------------

# ----------------------------
# 5) Streamlit UI
# ----------------------------
st.set_page_config(page_title="EvoGen AI + Tavily", layout="wide")
st.title("EvoGen AI (Tavily çµ±åˆç‰ˆ) ğŸ§¬ğŸŒ")
st.markdown("Tavily ã«ã‚ˆã‚‹æœ€æ–°ã‚¦ã‚§ãƒ–æƒ…å ±ã‚’å‚ç…§ã—ãªãŒã‚‰ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ãŒé€²åŒ–çš„ã«è§£æ±ºç­–ã‚’æ¢ç´¢ã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    gemini_key = st.text_input("Google Gemini API Key", type="password", help="Gemini ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    tavily_key = st.text_input("Tavily API Key", type="password", help="Tavily ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    st.subheader("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    num_generations = st.slider("ä¸–ä»£æ•°", 1, 5, 2, help="è§£æ±ºç­–ã‚’é€²åŒ–ã•ã›ã‚‹å›æ•°ã§ã™ã€‚")
    num_solutions = st.slider("ä¸–ä»£ã”ã¨ã®è§£æ±ºç­–ã®æ•°", 3, 10, 4, help="1ä¸–ä»£ã‚ãŸã‚Šã«ç”Ÿæˆãƒ»è©•ä¾¡ã™ã‚‹è§£æ±ºç­–ã®æ•°ã§ã™ã€‚")
    tavily_results_per_search = st.slider("Tavily æ¤œç´¢çµæœæ•°", 1, 10, 5, help="Tavily ã‹ã‚‰å–å¾—ã™ã‚‹æ¤œç´¢çµæœæ•°ã€‚")
    st.markdown("---")
    st.info("Tavily ã‚’ä½¿ã£ã¦èª²é¡Œã«é–¢é€£ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’å–å¾—ã—ã€ãã‚Œã‚’å‚è€ƒã«è§£æ±ºç­–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

default_problem = """
# èª²é¡Œ
éƒ½å¸‚éƒ¨ã«ãŠã‘ã‚‹ã‚«ãƒ©ã‚¹ã«ã‚ˆã‚‹ã‚´ãƒŸé›†ç©æ‰€ã®è¢«å®³ãŒæ·±åˆ»åŒ–ã—ã¦ã„ã‚‹ã€‚
ã‚«ãƒ©ã‚¹ã‚’å‚·ã¤ã‘ã‚‹ã“ã¨ãªãã€ã‹ã¤ä½ã‚³ã‚¹ãƒˆã§æŒç¶šå¯èƒ½ãªæ–¹æ³•ã§ã€
ã‚´ãƒŸãŒè’ã‚‰ã•ã‚Œã‚‹ã®ã‚’é˜²ããŸã‚ã®ç”»æœŸçš„ãªè§£æ±ºç­–ã‚’ææ¡ˆã›ã‚ˆã€‚

# è¦ä»¶ãƒ»åˆ¶ç´„æ¡ä»¶
- ã‚«ãƒ©ã‚¹ã‚„ä»–ã®å‹•ç‰©ã«å±å®³ã‚’åŠ ãˆãªã„ã“ã¨ã€‚
- ä½æ°‘ãŒç°¡å˜ã«åˆ©ç”¨ãƒ»ç®¡ç†ã§ãã‚‹ã“ã¨ã€‚
- å°å…¥ãŠã‚ˆã³ç¶­æŒã‚³ã‚¹ãƒˆãŒä½ã„ã“ã¨ã€‚
- æ™¯è¦³ã‚’å¤§ããæãªã‚ãªã„ã“ã¨ã€‚
"""
problem_statement = st.text_area("è§£æ±ºã—ãŸã„èª²é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=default_problem, height=260)

if st.button("è§£æ±ºç­–ã®ç”Ÿæˆã‚’é–‹å§‹", type="primary"):
    if not gemini_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Google Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not tavily_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Tavily APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not problem_statement.strip():
        st.warning("èª²é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status_placeholder = st.empty()
        team_placeholder = st.empty()
        tavily_placeholder = st.empty()
        results_area = st.container()
        final_result_placeholder = st.container()

        with st.spinner("ğŸŒ€ AIãŒæ€è€ƒä¸­ã§ã™..."):
            try:
                gemini_client = GeminiClient(api_key=gemini_key)
                tavily_client = TavilyClient(api_key=tavily_key)
            except Exception as e:
                st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()

            solver = EvoGenSolver_Tavily(
                llm_client=gemini_client,
                tavily_client=tavily_client,
                num_solutions_per_generation=num_solutions,
                tavily_results_per_search=tavily_results_per_search
            )

            # --- Solverã‚’å®Ÿè¡Œã—ã€çµæœã‚’UIã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º ---
            for result in solver.solve(problem_statement, generations=num_generations):
                if isinstance(result, str):
                    status_placeholder.info(result)

                elif isinstance(result, dict) and "tavily_info" in result:
                    tavily_data = result["tavily_info"]
                    with tavily_placeholder.container():
                        st.subheader("ğŸŒ Tavily æ¤œç´¢çµæœï¼ˆå‡ºå…¸ä»˜ãï¼‰")
                        if "results" in tavily_data and isinstance(tavily_data["results"], list):
                            for r in tavily_data["results"]:
                                title = r.get("title", "No title")
                                url = r.get("url", "")
                                snippet = r.get("snippet", "") or r.get("description", "")
                                st.markdown(f"- [{title}]({url})")
                                if snippet:
                                    st.caption(snippet)
                        else:
                            st.warning("Tavily ã‹ã‚‰æƒ³å®šå¤–ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã£ã¦ãã¾ã—ãŸã€‚")
                            st.text(json.dumps(tavily_data, ensure_ascii=False, indent=2))

                elif isinstance(result, dict) and "agent_team" in result:
                    with team_placeholder.container():
                        st.subheader("ğŸ¤– ç·¨æˆã•ã‚ŒãŸAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ")
                        team = result["agent_team"]
                        with st.expander("ãƒãƒ¼ãƒ ã®è©³ç´°ã‚’è¡¨ç¤º"):
                            gen = team.get("initial_generator", {})
                            st.markdown("##### ğŸ’¡ ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆæ‹…å½“")
                            st.markdown(f"**å½¹å‰²:** {gen.get('role', 'æœªå®šç¾©')}")
                            st.markdown(f"**æŒ‡ç¤º:** {gen.get('instructions', 'æœªå®šç¾©')}")
                            eva = team.get("evaluator", {})
                            st.markdown("##### ğŸ§ è©•ä¾¡æ‹…å½“")
                            st.markdown(f"**å½¹å‰²:** {eva.get('role', 'æœªå®šç¾©')}")
                            criteria_list = eva.get('criteria', [])
                            criteria_md = ""
                            if criteria_list:
                                for c in criteria_list:
                                    criteria_md += f"- **{c.get('criterion', 'é …ç›®åãªã—')}:** {c.get('weight', 0)}ç‚¹\n"
                            st.markdown(f"**è©•ä¾¡åŸºæº–:**\n{criteria_md or 'æœªå®šç¾©'}")
                            syn = team.get("synthesizer", {})
                            st.markdown("##### ğŸ§¬ é€²åŒ–ãƒ»çµ±åˆæ‹…å½“")
                            st.markdown(f"**å½¹å‰²:** {syn.get('role', 'æœªå®šç¾©')}")
                            st.markdown(f"**æŒ‡ç¤º:** {syn.get('instructions', 'æœªå®šç¾©')}")

                # === ä¿®æ­£ç®‡æ‰€ (1) ã®ã¾ã¾ (è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯) ===
                elif isinstance(result, dict) and "generation" in result:
                    gen_data = result
                    with results_area.container():
                        st.subheader(f"ç¬¬ {gen_data['generation']} ä¸–ä»£ã®çµæœ")
                        with st.container(border=True):
                            if not gen_data.get('results'):
                                st.write("ã“ã®ä¸–ä»£ã§ã¯æœ‰åŠ¹ãªè§£æ±ºç­–ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                                continue
                            
                            for item in gen_data.get('results', []):
                                sol = item.get('solution', {})
                                eva = item.get('evaluation', {})
                                score = eva.get('total_score', 0)
                                
                                # ä¾é ¼ã«æ²¿ã£ãŸã€Œé¡Œåã€ã¨ã€Œå†…å®¹ã€ã®å½¢å¼ã§è¡¨ç¤º
                                st.markdown(f"**é¡Œå:** {sol.get('name', 'N/A')} (ã‚¹ã‚³ã‚¢: {score})")
                                content = sol.get('summary', 'N/A')
                                st.markdown(f"**å†…å®¹:** {content}")
                                
                                # å„è§£æ±ºæ¡ˆã®åŒºåˆ‡ã‚Šç·š
                                if item != gen_data.get('results', [])[-1]:
                                    st.markdown("---")
                # === ä¿®æ­£ç®‡æ‰€ (1) ã®ã¾ã¾ ===

        # === ä¿®æ­£ç®‡æ‰€ (2) ã®ã¾ã¾ (æœ€çµ‚çµæœã®è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯) ===
        # --- æœ€çµ‚çµæœã®è¡¨ç¤ºï¼ˆãƒˆãƒƒãƒ—5ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰ ---
        
        # ã™ã¹ã¦ã®ä¸–ä»£ã‹ã‚‰è©•ä¾¡æ¸ˆã¿ã®è§£æ±ºç­–ã‚’åé›†
        all_solutions = [
            item for gen in solver.history
            for item in gen.get("results", [])
            if item.get("evaluation") and "total_score" in item["evaluation"]
        ]

        if all_solutions:
            # ã‚¹ã‚³ã‚¢ã§é™é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_solutions = sorted(
                all_solutions,
                key=lambda x: x["evaluation"]["total_score"],
                reverse=True
            )
            
            top_5_solutions = sorted_solutions[:5]

            status_placeholder.empty()
            st.balloons()

            with final_result_placeholder:
                st.success("ğŸ† å‡¦ç†å®Œäº†ï¼ã‚¹ã‚³ã‚¢ãƒˆãƒƒãƒ—5ã®è§£æ±ºç­–ã¯ã“ã¡ã‚‰ã§ã™ã€‚")
                
                for i, item in enumerate(top_5_solutions):
                    sol = item.get('solution', {})
                    eva = item.get('evaluation', {})
                    score = eva.get('total_score', 'N/A')
                    
                    st.header(f"ğŸ… ç¬¬ {i + 1} ä½: {sol.get('name', 'N/A')}")
                    st.metric(label="æœ€çµ‚ã‚¹ã‚³ã‚¢", value=f"{score}")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.info(f"**æ¦‚è¦**\n\n{sol.get('summary', 'N/A')}")
                        st.warning(f"**æ‡¸å¿µç‚¹ãƒ»æ”¹å–„ç‚¹**\n\n{eva.get('weaknesses', 'N/A')}")
                    with col2:
                        st.success(f"**å„ªã‚ŒãŸç‚¹**\n\n{eva.get('strengths', 'N/A')}")
                        st.info(f"**ç·è©•**\n\n{eva.get('overall_comment', 'N/A')}")
                    st.markdown("---")
        else:
            status_placeholder.warning("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸãŒã€æœ€çµ‚çš„ãªè§£æ±ºç­–ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        # === ä¿®æ­£ç®‡æ‰€ (2) ã®ã¾ã¾ ===