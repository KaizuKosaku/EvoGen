# app_tavily_fixed_v3.py
"""
EvoGen AI with Tavily integration (v3: 2-Phase RAGç‰ˆ)

ä½¿ã„æ–¹:
  - å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
      pip install streamlit requests google-generativeai
  - å®Ÿè¡Œ:
      streamlit run app_tavily_fixed_v3.py
"""

import streamlit as st
import os
import json
import abc
from typing import List, Dict, Any, Generator, Optional
import time

# --- å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ ---
try:
    import google.generativeai as genai
except Exception:
    genai = None

try:
    import requests
except ImportError:
    requests = None

# ----------------------------
# 1) LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå±¤ (æ—¢å­˜)
# ----------------------------
class LLMClient(abc.ABC):
    """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åŸºæœ¬ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹"""
    @abc.abstractmethod
    def call(self, prompt: str) -> Dict[str, Any]:
        pass

class GeminiClient(LLMClient):
    """Google Gemini ç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆæ—¢å­˜å®Ÿè£…ã‚’è¸è¥²ï¼‰"""
    def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"):
        if genai is None:
            raise ImportError("`google-generativeai`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install google-generativeai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
        # ã“ã“ã§ã¯ generative model ã« JSON ã‚’è¿”ã•ã›ã‚‹æƒ³å®šã§è¨­å®šã‚’ä½¿ã†
        self.generation_config = genai.GenerationConfig(
            response_mime_type="application/json"
        )

    def call(self, prompt: str) -> Dict[str, Any]:
        """
        prompt -> LLM å‘¼ã³å‡ºã— -> JSON ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
        è¿”ã‚Šå€¤: dictï¼ˆå¤±æ•—æ™‚ã¯ {"error": "...", "raw": "<text>"} ã‚’è¿”ã™ï¼‰
        """
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            # Gemini ã®å ´åˆ response.text ã«æ–‡å­—åˆ—ãŒã‚ã‚‹æƒ³å®š
            text = getattr(response, "text", None) or getattr(response, "response", None) or str(response)
            try:
                return json.loads(text)
            except Exception:
                # JSON ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯ raw ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿”ã™
                return {"raw_text": text}
        except Exception as e:
            # Streamlitä¸Šã§ã‚‚è¦‹ãˆã‚‹ã‚ˆã†ã«ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ãŒã€æˆ»ã‚Šå€¤ã¯ dict ã§
            st.error(f"[GeminiClient Error] API å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return {"error": str(e)}

# ----------------------------
# 2) Tavily ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (æ—¢å­˜)
# ----------------------------
class TavilyClient:
    """
    Tavily Search API ã¨ã®ã‚„ã‚Šå–ã‚Šã‚’è¡Œã†ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€‚
    """
    DEFAULT_ENDPOINT = "https://api.tavily.com/search"

    def __init__(self, api_key: str, endpoint: str = DEFAULT_ENDPOINT, timeout: int = 15):
        if requests is None:
            raise ImportError("`requests`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install requests ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        self.api_key = api_key
        self.endpoint = endpoint
        self.timeout = timeout

    def search(self, query: str, num_results: int = 5, domain: Optional[str] = None, lang: Optional[str] = None) -> Dict[str, Any]:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {"query": query, "max_results": num_results}
        if domain:
            payload["domain"] = domain
        if lang:
            payload["language"] = lang

        try:
            resp = requests.post(self.endpoint, headers=headers, json=payload, timeout=self.timeout)
            resp.raise_for_status()
            data = resp.json()
            return data
        except requests.exceptions.RequestException as e:
            return {"error": f"HTTP error: {e}"}
        except ValueError as e:
            return {"error": f"JSON parse error: {e}", "raw": resp.text if 'resp' in locals() else None}
        except Exception as e:
            return {"error": str(e)}

# ----------------------------
# 3) PromptManagerï¼ˆâ˜…ä¿®æ­£ç®‡æ‰€â˜…ï¼‰
# ----------------------------
class PromptManager:
    """AIã¸ã®æŒ‡ç¤ºæ›¸ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    # === â˜…ä¿®æ­£ç®‡æ‰€ 1: 2ãƒ•ã‚§ãƒ¼ã‚ºã®ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›´ ===
    def get_tavily_multi_phase_query_prompt(self, problem_statement: str) -> str:
        """
        èª²é¡Œè§£æ±ºã«å¿…è¦ãªæƒ…å ±ã‚’ã€Œåˆ†æã€ã¨ã€Œè§£æ±ºç­–ã€ã®2ãƒ•ã‚§ãƒ¼ã‚ºã§æ¤œç´¢ã™ã‚‹ãŸã‚ã®
        ã‚¯ã‚¨ãƒªã‚’LLMã«ç”Ÿæˆã•ã›ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
        """
        return f"""
        ã‚ãªãŸã¯ã€æç¤ºã•ã‚ŒãŸã€Œèª²é¡Œã€ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®èª¿æŸ»ã‚’2æ®µéšã§è¡Œã†å°‚é–€ã®èª¿æŸ»å“¡ã§ã™ã€‚

        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’åˆ†æã—ã€2ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã«å¯¾å¿œã™ã‚‹**æ—¥æœ¬èªã®æ¤œç´¢ã‚¯ã‚¨ãƒª**ã‚’ãã‚Œãã‚Œ2ã¤ãšã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

        # ãƒ•ã‚§ãƒ¼ã‚º1: ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ
        èª²é¡Œæ–‡ã«å«ã¾ã‚Œã‚‹å›ºæœ‰åè©ï¼ˆçµ„ç¹”åã€åœ°åã€ç‰¹å®šã®ã‚·ã‚¹ãƒ†ãƒ åãªã©ï¼‰ã‚’ç‰¹å®šã—ã€
        ãã®å¯¾è±¡ã®ã€Œæœ€æ–°æƒ…å ±ã€ã€Œç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿ã€ã€Œé–¢é€£ã™ã‚‹èƒŒæ™¯ã‚„åˆ¶ç´„ã€ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã€‚
        (ä¾‹: ã€Œä¹å·å·¥æ¥­å¤§å­¦ å¿—é¡˜è€…æ•° æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã€, ã€Œä¹å·å·¥æ¥­å¤§å­¦ ç¾åœ¨ã®åºƒå ±æˆ¦ç•¥ã€)

        # ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒ»æŠ€è¡“èª¿æŸ»
        èª²é¡Œãã®ã‚‚ã®ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ã€Œæœ€æ–°ã®å¯¾ç­–äº‹ä¾‹ã€ã€Œé–¢é€£ã™ã‚‹æ–°ã—ã„æŠ€è¡“ã®å‹•å‘ã€ã€Œä»–åˆ†é‡ã§ã®æˆåŠŸäº‹ä¾‹ã€ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã€‚
        (ä¾‹: ã€Œå¤§å­¦ å¿—é¡˜è€…æ•° å¢—åŠ æ–½ç­– äº‹ä¾‹ã€, ã€ŒZä¸–ä»£å‘ã‘ å¤§å­¦ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•ã€)

        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "analysis_queries": [
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª1 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª2 (æ—¥æœ¬èª)"
          ],
          "solution_queries": [
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª1 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª2 (æ—¥æœ¬èª)"
          ]
        }}
        """
    # === â˜…ä¿®æ­£ç®‡æ‰€ 1 çµ‚äº† ===

    def get_agent_personas_prompt(self, problem_statement: str) -> str:
        return f"""
        # å½¹å‰²
        ã‚ãªãŸã¯ã€éå¸¸ã«è¤‡é›‘ãªèª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ãªã‚‹ãƒ‰ãƒªãƒ¼ãƒ ãƒãƒ¼ãƒ ã‚’ç·¨æˆã™ã‚‹ã€Œãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€ã§ã™ã€‚
        # ã‚¿ã‚¹ã‚¯
        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’æ·±ãåˆ†æã—ã€ã“ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«æœ€ã‚‚åŠ¹æœçš„ãªæ€è€ƒãƒãƒ¼ãƒ ã‚’ç·¨æˆã—ã¦ãã ã•ã„ã€‚
        ãƒãƒ¼ãƒ ã¯ä»¥ä¸‹ã®3ä½“ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã¾ã™ã€‚ãã‚Œãã‚Œã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¤ã„ã¦ã€ãã®å½¹å‰²ï¼ˆãƒšãƒ«ã‚½ãƒŠï¼‰ã¨å…·ä½“çš„ãªè¡Œå‹•æŒ‡ç¤ºã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚

        1. **initial_generator (åˆæœŸã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆæ‹…å½“):**
            - **role:** ã©ã®ã‚ˆã†ãªå°‚é–€æ€§ã‚„æ€§æ ¼ã‚’æŒã¤ã¹ãã‹ï¼Ÿ
            - **instructions:** ã©ã®ã‚ˆã†ãªè¦³ç‚¹ã‹ã‚‰ã€ã©ã®ã‚ˆã†ã«å¤šæ§˜ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å‡ºã™ã¹ãã‹ï¼Ÿ

        2. **evaluator (è©•ä¾¡æ‹…å½“):**
            - **role:** ã©ã®ã‚ˆã†ãªè¦–ç‚¹ã‹ã‚‰ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è©•ä¾¡ã™ã¹ãã‹ï¼Ÿ
            - **criteria:** ã“ã®èª²é¡Œã«ç‰¹åŒ–ã—ãŸè©•ä¾¡åŸºæº–ã‚’3ã¤å®šç¾©ã—ã€é‡è¦åº¦ã«å¿œã˜ã¦åˆè¨ˆ100ç‚¹ã«ãªã‚‹ã‚ˆã†ã«é…ç‚¹ã—ã¦ãã ã•ã„ã€‚

        3. **synthesizer (é€²åŒ–ãƒ»çµ±åˆæ‹…å½“):**
            - **role:** ã©ã®ã‚ˆã†ã«ã—ã¦ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ã‚ˆã‚Šå„ªã‚ŒãŸã‚‚ã®ã¸ã¨é€²åŒ–ã•ã›ã‚‹ã¹ãã‹ï¼Ÿ
            - **instructions:** é«˜è©•ä¾¡æ¡ˆã¨ä½è©•ä¾¡æ¡ˆã‚’ã©ã®ã‚ˆã†ã«åˆ†æã—ã€æ¬¡ä¸–ä»£ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆã™ã¹ãã‹å…·ä½“çš„ãªæŒ‡ç¤ºã‚’ä¸ãˆã¦ãã ã•ã„ã€‚

        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "initial_generator": {{"role": "...", "instructions": "..."}},
          "evaluator": {{"role": "...", "criteria": [{{"criterion": "...", "weight": 10}}]}},
          "synthesizer": {{"role": "...", "instructions": "..."}}
        }}
        """

    def get_initial_generation_prompt(self, problem_statement: str, num_solutions: int, context: Dict[str, str]) -> str:
        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯ä¸€æµã®ã‚¤ãƒãƒ™ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', f'ä»¥ä¸‹ã®èª²é¡Œã«å¯¾ã—ã€äº’ã„ã«å…¨ãç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‹ã‚‰ã®è§£æ±ºç­–ã‚’{num_solutions}å€‹ææ¡ˆã—ã¦ãã ã•ã„ã€‚')}
        # èª²é¡Œæ–‡: {problem_statement}
        # å‡ºåŠ›å½¢å¼: 
        å„è§£æ±ºç­–ã«ã€Œnameã€ã€Œsummaryã€ã€Œspecific_methodã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        
        # !!é‡è¦!! 
        - ã€Œspecific_methodã€ã®å†…å®¹ã¯ã€ãã®æ–¹æ³•è«–ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãã®ç†ç”±ãªã©ã‚’èª¬æ˜ã™ã‚‹**ç°¡æ½”ãªå¹³æ˜“ãªæ–‡ç« ï¼ˆ2ã€œ3æ–‡ç¨‹åº¦ï¼‰**ã«ã—ã¦ãã ã•ã„ã€‚
        - ã€Œspecific_methodã€ã«ã¯**ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã€æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚** å¿…ãšå˜ä¸€ã®æ–‡å­—åˆ—ï¼ˆStringï¼‰ã«ã—ã¦ãã ã•ã„ã€‚

        {{ 
          "solutions": [ 
            {{ 
              "name": "è§£æ±ºç­–1ã®åç§°", 
              "summary": "è§£æ±ºç­–1ã®ç°¡æ½”ãªæ¦‚è¦", 
              "specific_method": "è§£æ±ºç­–1ã®å…·ä½“çš„ãªæ–¹æ³•ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹ç°¡æ½”ãªæ–‡ç« ã§ã™ã€‚" 
            }},
            {{ 
              "name": "è§£æ±ºç­–2ã®åç§°", 
              "summary": "è§£æ±ºç­–2ã®ç°¡æ½”ãªæ¦‚è¦", 
              "specific_method": "è§£æ±ºç­–2ã®å…·ä½“çš„ãªæ–¹æ³•ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹ç°¡æ½”ãªæ–‡ç« ã§ã™ã€‚" 
            }}
          ] 
        }}
        """

    def get_evaluation_prompt(self, solution: Dict[str, str], problem_statement: str, context: Dict[str, Any]) -> str:
        criteria_text = []
        scores_json_structure = []
        if "criteria" in context and isinstance(context["criteria"], list):
            for item in context["criteria"]:
                criterion = item.get("criterion", "ä¸æ˜ãªåŸºæº–")
                weight = item.get("weight", 0)
                criteria_text.append(f"- {criterion}: {weight}ç‚¹")
                scores_json_structure.append(f'"{criterion}": ç‚¹æ•°(æ•´æ•°)')

        criteria_prompt_part = "\n".join(criteria_text)
        scores_json_prompt_part = f"{{ {', '.join(scores_json_structure)} }}"

        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯å®¢è¦³çš„ã§å³ã—ã„æ‰¹è©•å®¶ã§ã™ã€‚')}
        # ã‚¿ã‚¹ã‚¯: æç¤ºã•ã‚ŒãŸèª²é¡Œã«å¯¾ã—ã€è§£æ±ºæ¡ˆã‚’è©•ä¾¡åŸºæº–ã«åŸºã¥ã„ã¦å³å¯†ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        # èª²é¡Œæ–‡: {problem_statement}
        
        # è©•ä¾¡å¯¾è±¡ã®è§£æ±ºæ¡ˆ:
        - åç§°: {solution.get('name', 'åç§°ä¸æ˜')}
        - æ¦‚è¦: {solution.get('summary', 'æ¦‚è¦ãªã—')}
        - å…·ä½“çš„ãªæ–¹æ³•: {solution.get('specific_method', 'å…·ä½“çš„ãªæ–¹æ³•ãªã—')}
        
        # è©•ä¾¡åŸºæº–:
        {criteria_prompt_part}
        
        # å‡ºåŠ›å½¢å¼: è©•ä¾¡çµæœã‚’å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        {{
          "total_score": åˆè¨ˆç‚¹(æ•´æ•°),
          "scores": {scores_json_prompt_part},
          "strengths": "ã“ã®è§£æ±ºæ¡ˆãŒå„ªã‚Œã¦ã„ã‚‹ç‚¹ï¼ˆç°¡æ½”ã«ï¼‰",
          "weaknesses": "ã“ã®è§£æ±ºæ¡ˆã®æ‡¸å¿µç‚¹ã‚„æ”¹å–„ãŒå¿…è¦ãªç‚¹ï¼ˆç°¡æ½”ã«ï¼‰",
          "overall_comment": "è©•ä¾¡ã®ç·æ‹¬ï¼ˆç°¡æ½”ã«ï¼‰"
        }}
        """

    def get_next_generation_prompt(self, elite_solutions: List[Dict], failed_solutions: List[Dict], problem_statement: str, num_solutions: int, context: Dict[str, str]) -> str:
        elite_text = "\n".join([f"- {s['solution'].get('name', 'N/A')} (ã‚¹ã‚³ã‚¢: {s['evaluation'].get('total_score', 0)})" for s in elite_solutions])
        failed_text = "\n".join([f"- {s['solution'].get('name', 'N/A')} (å¼±ç‚¹: {s['evaluation'].get('weaknesses', 'N/A')})" for s in failed_solutions])

        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯å„ªã‚ŒãŸæˆ¦ç•¥å®¶ã§ã‚ã‚Šç·¨é›†è€…ã§ã™ã€‚')}
        # ã‚¿ã‚¹ã‚¯: å‰ä¸–ä»£ã®åˆ†æã«åŸºã¥ãã€æ¬¡ä¸–ä»£ã®æ–°ã—ã„è§£æ±ºç­–ã‚’{num_solutions}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        # åˆ†æå¯¾è±¡1ï¼šé«˜è©•ä¾¡ã ã£ãŸè§£æ±ºæ¡ˆï¼ˆå„ªã‚ŒãŸéºä¼å­ï¼‰: 
        {elite_text}
        # åˆ†æå¯¾è±¡2ï¼šä½è©•ä¾¡ã ã£ãŸè§£æ±ºæ¡ˆï¼ˆå­¦ã¶ã¹ãæ•™è¨“ï¼‰: 
        {failed_text}
        # æ–°ã—ã„è§£æ±ºç­–ã®ç”ŸæˆæŒ‡ç¤º: {context.get('instructions', 'é«˜è©•ä¾¡æ¡ˆã®è‰¯ã„ç‚¹ã‚’çµ„ã¿åˆã‚ã›ã€ä½è©•ä¾¡æ¡ˆã®å¤±æ•—ã‹ã‚‰å­¦ã³ã€æ–°ã—ã„è§£æ±ºç­–ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚')}
        
        # å‡ºåŠ›å½¢å¼: 
        å„è§£æ±ºç­–ã«ã€Œnameã€ã€Œsummaryã€ã€Œspecific_methodã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        
        # !!é‡è¦!! 
        - ã€Œspecific_methodã€ã®å†…å®¹ã¯ã€ãã®æ–¹æ³•è«–ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãã®ç†ç”±ãªã©ã‚’èª¬æ˜ã™ã‚‹**ç°¡æ½”ãªå¹³æ˜“ãªæ–‡ç« ï¼ˆ2ã€œ3æ–‡ç¨‹åº¦ï¼‰**ã«ã—ã¦ãã ã•ã„ã€‚
        - ã€Œspecific_methodã€ã«ã¯**ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã€æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚** å¿…ãšå˜ä¸€ã®æ–‡å­—åˆ—ï¼ˆStringï¼‰ã«ã—ã¦ãã ã•ã„ã€‚

        {{ 
          "solutions": [ 
            {{ 
              "name": "æ–°ã—ã„è§£æ±ºç­–1ã®åç§°", 
              "summary": "æ–°ã—ã„è§£æ±ºç­–1ã®ç°¡æ½”ãªæ¦‚è¦", 
              "specific_method": "æ–°ã—ã„è§£æ±ºç­–1ã®å…·ä½“çš„ãªæ–¹æ³•ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹ç°¡æ½”ãªæ–‡ç« ã§ã™ã€‚" 
            }},
            {{ 
              "name": "æ–°ã—ã„è§£æ±ºç­–2ã®åç§°", 
              "summary": "æ–°ã—ã„è§£æ±ºç­–2ã®ç°¡æ½”ãªæ¦‚è¦", 
              "specific_method": "æ–°ã—ã„è§£æ±ºç­–2ã®å…·ä½“çš„ãªæ–¹æ³•ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹ç°¡æ½”ãªæ–‡ç« ã§ã™ã€‚" 
            }}
          ] 
        }}
        """

# ----------------------------
# 4) EvoGenSolverï¼ˆæ—¢å­˜ï¼‰ + Tavily æ‹¡å¼µ
# ----------------------------
class EvoGenSolver:
    """å…ƒã® EvoGenSolverï¼ˆä¸»è¦ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
    def __init__(self, llm_client: LLMClient, num_solutions_per_generation: int = 5):
        self.client = llm_client
        self.num_solutions = num_solutions_per_generation
        self.prompter = PromptManager()
        self.history = []

    def _call_llm(self, prompt: str) -> Dict[str, Any]:
        return self.client.call(prompt)

    def _generate_agent_personas(self, problem_statement: str) -> Dict:
        prompt = self.prompter.get_agent_personas_prompt(problem_statement)
        return self._call_llm(prompt)

    def _generate_initial_solutions(self, problem_statement: str, context: Dict) -> List[Dict[str, str]]:
        prompt = self.prompter.get_initial_generation_prompt(problem_statement, self.num_solutions, context)
        response = self._call_llm(prompt)
        # å½¢å¼ãŒå´©ã‚ŒãŸå ´åˆï¼ˆdictã ãŒsolutionsãŒãªã„ã€ã¾ãŸã¯ãƒªã‚¹ãƒˆã§ãªã„ï¼‰ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å¼·åŒ–
        if isinstance(response, dict) and "solutions" in response and isinstance(response["solutions"], list):
            return response["solutions"]
        else:
            st.warning(f"[EvoGenSolver] åˆæœŸè§£æ±ºç­–ã®ç”Ÿæˆã§ä¸æ­£ãªå½¢å¼ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {response}")
            return []

    def _evaluate_solutions(self, solutions: List[Dict[str, str]], problem_statement: str, context: Dict) -> Generator[str | List[Dict], None, None]:
        evaluated_solutions = []
        if not solutions:
            yield []
            return

        for i, solution in enumerate(solutions):
            # è§£æ±ºç­–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè‡ªä½“ãŒä¸æ­£ãªå½¢å¼ã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
            if not isinstance(solution, dict) or "name" not in solution:
                yield f"  - è©•ä¾¡ã‚¹ã‚­ãƒƒãƒ—: ä¸æ­£ãªå½¢å¼ã®è§£æ±ºç­–ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚"
                continue
                
            yield f"  - è©•ä¾¡ä¸­ {i+1}/{len(solutions)}: {solution.get('name', 'åç§°ä¸æ˜')}"
            prompt = self.prompter.get_evaluation_prompt(solution, problem_statement, context)
            evaluation = self._call_llm(prompt)
            
            # è©•ä¾¡çµæœãŒæœŸå¾…é€šã‚Šï¼ˆdictã§total_scoreã‚’æŒã¤ï¼‰ã‹ãƒã‚§ãƒƒã‚¯
            if isinstance(evaluation, dict) and "total_score" in evaluation and "error" not in evaluation:
                evaluated_solutions.append({"solution": solution, "evaluation": evaluation})
            else:
                st.warning(f"[EvoGenSolver] è§£æ±ºç­– '{solution.get('name', 'N/A')}' ã®è©•ä¾¡ã§ä¸æ­£ãªå½¢å¼ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {evaluation}")


        evaluated_solutions.sort(key=lambda x: x.get("evaluation", {}).get("total_score", 0), reverse=True)
        yield evaluated_solutions

    def _generate_next_generation(self, evaluated_solutions: List[Dict], problem_statement: str, context: Dict) -> List[Dict[str, str]]:
        num_elites = max(1, int(len(evaluated_solutions) * 0.4))
        elite_solutions = evaluated_solutions[:num_elites]
        failed_solutions = evaluated_solutions[num_elites:]
        prompt = self.prompter.get_next_generation_prompt(elite_solutions, failed_solutions, problem_statement, self.num_solutions, context)
        response = self._call_llm(prompt)
        # å½¢å¼ãŒå´©ã‚ŒãŸå ´åˆï¼ˆdictã ãŒsolutionsãŒãªã„ã€ã¾ãŸã¯ãƒªã‚¹ãƒˆã§ãªã„ï¼‰ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å¼·åŒ–
        if isinstance(response, dict) and "solutions" in response and isinstance(response["solutions"], list):
            return response["solutions"]
        else:
            st.warning(f"[EvoGenSolver] æ¬¡ä¸–ä»£ã®è§£æ±ºç­–ç”Ÿæˆã§ä¸æ­£ãªå½¢å¼ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {response}")
            return []

    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        self.history = []

        # STEP 1: AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ã®ç·¨æˆ
        yield "--- ğŸ§  èª²é¡Œã‚’åˆ†æã—ã€æœ€é©ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ã‚’ç·¨æˆä¸­... ---"
        agent_personas = self._generate_agent_personas(problem_statement)

        if not agent_personas or "error" in agent_personas or not all(k in agent_personas for k in ["initial_generator", "evaluator", "synthesizer"]):
            yield "ã‚¨ãƒ©ãƒ¼: ãƒãƒ¼ãƒ ç·¨æˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚"
            yield f"**ãƒ‡ãƒãƒƒã‚°æƒ…å ±:** AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™ã€‚APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n```\n{agent_personas}\n```"
            return

        yield f"--- âœ”ï¸ ãƒãƒ¼ãƒ ç·¨æˆå®Œäº† ---"
        yield {"agent_team": agent_personas}

        # STEP 2: æœ€åˆã®ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã¨è©•ä¾¡
        yield "\n--- ğŸ’¡ Generation 0: æœ€åˆã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆä¸­... ---"
        solutions = self._generate_initial_solutions(problem_statement, agent_personas["initial_generator"])
        
        if not solutions:
             yield "ã‚¨ãƒ©ãƒ¼: æœ€åˆã®è§£æ±ºç­–ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIãŒé©åˆ‡ãªå¿œç­”ã‚’è¿”ã•ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
             return

        yield "--- ğŸ§ ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è©•ä¾¡ä¸­... ---"
        eval_generator = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluator"])
        evaluated_solutions = []
        for item in eval_generator:
            if isinstance(item, str):
                yield item
            else:
                evaluated_solutions = item
        
        if not evaluated_solutions:
             yield "ã‚¨ãƒ©ãƒ¼: è§£æ±ºç­–ã®è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
             return

        self.history.append({"generation": 0, "results": evaluated_solutions})
        yield self.history[-1]

        # STEP 3: ä¸–ä»£ã®é€²åŒ–
        for i in range(1, generations):
            yield f"\n--- ğŸš€ Generation {i}: æ¬¡ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã¸é€²åŒ–ä¸­... ---"
            previous_generation_results = self.history[-1]["results"]
            
            if not previous_generation_results:
                yield f"ã‚¨ãƒ©ãƒ¼: å‰ä¸–ä»£ ({i-1}) ã®æœ‰åŠ¹ãªè©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚é€²åŒ–ã‚’åœæ­¢ã—ã¾ã™ã€‚"
                break

            solutions = self._generate_next_generation(previous_generation_results, problem_statement, agent_personas["synthesizer"])

            if not solutions:
                yield f"ã‚¨ãƒ©ãƒ¼: Generation {i} ã®è§£æ±ºç­–ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIãŒé©åˆ‡ãªå¿œç­”ã‚’è¿”ã•ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
                break

            yield f"--- ğŸ§ Generation {i} ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è©•ä¾¡ä¸­... ---"
            eval_generator_next = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluator"])
            evaluated_solutions_next = []
            for item in eval_generator_next:
                if isinstance(item, str):
                    yield item
                else:
                    evaluated_solutions_next = item

            if not evaluated_solutions_next:
                 yield f"ã‚¨ãƒ©ãƒ¼: Generation {i} ã®è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
                 break

            self.history.append({"generation": i, "results": evaluated_solutions_next})
            yield self.history[-1]

        yield "\n--- âœ… é€²åŒ–ãƒ—ãƒ­ã‚»ã‚¹å®Œäº† ---"

# === â˜…ä¿®æ­£ç®‡æ‰€ 2: EvoGenSolver_Tavily ã®ä¿®æ­£ ===
class EvoGenSolver_Tavily(EvoGenSolver):
    """
    Tavily ã‚’ç”¨ã„ã¦èª²é¡Œã«é–¢é€£ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’åé›†ã—ã€ãã®æƒ…å ±ã‚’
    å•é¡Œæ–‡ã«çµ„ã¿è¾¼ã‚“ã§ EvoGen ã®ãƒ•ãƒ­ãƒ¼ã‚’å›ã™æ‹¡å¼µç‰ˆã€‚
    (v3: 2ãƒ•ã‚§ãƒ¼ã‚ºRAG)
    """
    def __init__(self, llm_client: LLMClient, tavily_client: TavilyClient, num_solutions_per_generation: int = 5, tavily_results_per_search: int = 5):
        super().__init__(llm_client, num_solutions_per_generation)
        self.tavily = tavily_client
        # tavily_results_per_search ã¯ã€Œã‚¯ã‚¨ãƒªã”ã¨ã€ã®å–å¾—æ•°ã¨ã™ã‚‹
        self.tavily_results_per_query = tavily_results_per_search 

    def _get_snippet_text(self, results: List[Dict[str, Any]], max_snippets: int = 5) -> str:
        """Tavilyã®çµæœãƒªã‚¹ãƒˆã‹ã‚‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆæ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼"""
        snippet_texts = []
        for r in results[:min(len(results), max_snippets)]:
            title = r.get("title", "")
            snippet = r.get("snippet", "") or r.get("description", "")
            url = r.get("url", "")
            snippet_texts.append(f"Title: {title}\nSnippet: {snippet}\nURL: {url}\n---")
        return "\n".join(snippet_texts)

    def _summarize_multi_phase_results_with_llm(
        self, 
        problem_statement: str, 
        analysis_results: List[Dict[str, Any]], 
        solution_results: List[Dict[str, Any]]
    ) -> str:
        """
        2ãƒ•ã‚§ãƒ¼ã‚ºã®Tavilyæ¤œç´¢çµæœã‚’LLMã«è¦ç´„ã•ã›ã€å•é¡Œæ–‡ã«çµ±åˆã™ã‚‹ã€‚
        """
        if not analysis_results and not solution_results:
            return problem_statement

        analysis_snippets = self._get_snippet_text(analysis_results, max_snippets=5)
        solution_snippets = self._get_snippet_text(solution_results, max_snippets=5)

        prompt = f"""
        ã‚ãªãŸã¯ã€2æ®µéšã®ã‚¦ã‚§ãƒ–èª¿æŸ»çµæœã‚’åˆ†æã—ã€å…ƒã®èª²é¡Œæ–‡ã«çµ±åˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
        
        # å…ƒã®èª²é¡Œ
        {problem_statement}

        # èª¿æŸ»çµæœ 1: ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ (å›ºæœ‰åè©ã‚„ç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿)
        {analysis_snippets if analysis_snippets else "ãªã—"}

        # èª¿æŸ»çµæœ 2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒ»æŠ€è¡“ (ä»–äº‹ä¾‹ã‚„æŠ€è¡“å‹•å‘)
        {solution_snippets if solution_snippets else "ãªã—"}

        # ã‚¿ã‚¹ã‚¯
        ä¸Šè¨˜ã®2ã¤ã®èª¿æŸ»çµæœã‚’åˆ†æã—ã€å…ƒã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ä¸Šã§ç‰¹ã«é‡è¦ã¨ãªã‚‹æƒ…å ±ã‚’æŠ½å‡ºãƒ»è¦ç´„ã—ã¦ãã ã•ã„ã€‚
        
        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "summary_analysis": "ã€Œèª¿æŸ»çµæœ1ï¼ˆç¾çŠ¶ãƒ»èƒŒæ™¯ï¼‰ã€ã®ç°¡æ½”ãªè¦ç´„ï¼ˆ1ã€œ2æ–‡ï¼‰",
          "summary_solution": "ã€Œèª¿æŸ»çµæœ2ï¼ˆè§£æ±ºç­–ãƒ»äº‹ä¾‹ï¼‰ã€ã®ç°¡æ½”ãªè¦ç´„ï¼ˆ1ã€œ2æ–‡ï¼‰",
          "key_points": [
            "èª¿æŸ»çµæœå…¨ä½“ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸé‡è¦ãªäº‹å®Ÿã‚„åˆ¶ç´„1",
            "èª¿æŸ»çµæœå…¨ä½“ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸé‡è¦ãªäº‹å®Ÿã‚„åˆ¶ç´„2"
          ],
          "top_sources": [
            {{"title":"æœ€ã‚‚é‡è¦ãªå‡ºå…¸ã®ã‚¿ã‚¤ãƒˆãƒ«1", "url":"..."}},
            {{"title":"æœ€ã‚‚é‡è¦ãªå‡ºå…¸ã®ã‚¿ã‚¤ãƒˆãƒ«2", "url":"..."}}
          ]
        }}
        """
        
        llm_ret = self._call_llm(prompt)
        
        # LLMã«ã‚ˆã‚‹è¦ç´„ãŒæˆåŠŸã—ãŸå ´åˆ
        if isinstance(llm_ret, dict) and any(k in llm_ret for k in ["summary_analysis", "summary_solution", "key_points"]):
            try:
                summary_analysis_text = llm_ret.get("summary_analysis", "ç¾çŠ¶åˆ†æã®è¦ç´„ãªã—")
                summary_solution_text = llm_ret.get("summary_solution", "è§£æ±ºç­–äº‹ä¾‹ã®è¦ç´„ãªã—")
                kp = llm_ret.get("key_points", [])
                top = llm_ret.get("top_sources", [])
                top_text = "\n".join([f"- {s.get('title','')}: {s.get('url','')}" for s in top]) if isinstance(top, list) else ""
                
                composed = f"""
## Tavilyãƒªã‚µãƒ¼ãƒè¦ç´„ï¼ˆLLMç”Ÿæˆï¼‰
### ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ
{summary_analysis_text}
### è§£æ±ºç­–ãƒ»äº‹ä¾‹
{summary_solution_text}

### æŠ½å‡ºã•ã‚ŒãŸé‡è¦ç‚¹
""" + "\n".join([f"- {p}" for p in kp]) + "\n\n" + \
"### ä¸»ãªå‡ºå…¸\n" + top_text + "\n\n" + \
"--- (ä»¥ä¸‹ã€å…ƒã®èª²é¡Œæ–‡) ---\n" + problem_statement
                
                return composed
            except Exception:
                pass # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã¸

        # LLMè¦ç´„ãŒå¤±æ•—ã—ãŸå ´åˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        fallback_sources = []
        for r in analysis_results[:2]:
            fallback_sources.append(f"- [åˆ†æ] {r.get('title','No title')} ({r.get('url','')})")
        for r in solution_results[:2]:
            fallback_sources.append(f"- [è§£æ±ºç­–] {r.get('title','No title')} ({r.get('url','')})")
            
        fallback = "## Tavilyãƒªã‚µãƒ¼ãƒè¦ç´„ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n" + \
                   "æœ€æ–°ã®ã‚¦ã‚§ãƒ–æƒ…å ±ã‚’å‚ç…§ã—ã¾ã—ãŸã€‚ä¸Šä½å‡ºå…¸:\n" + "\n".join(fallback_sources) + \
                   "\n\n" + "--- (ä»¥ä¸‹ã€å…ƒã®èª²é¡Œæ–‡) ---\n" + problem_statement
        return fallback

    # --- solveãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£ ---
    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        
        # LLMã«2ãƒ•ã‚§ãƒ¼ã‚ºã®Tavilyæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã•ã›ã‚‹
        yield "--- ğŸ’¡ LLMã«ã‚ˆã‚‹æœ€é©ãªæ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆãƒ•ã‚§ãƒ¼ã‚º1 & 2ï¼‰ã‚’ç”Ÿæˆä¸­... ---"
        prompt = self.prompter.get_tavily_multi_phase_query_prompt(problem_statement)
        query_response = self._call_llm(prompt)

        if not isinstance(query_response, dict) or ("analysis_queries" not in query_response and "solution_queries" not in query_response):
            yield f"ã‚¨ãƒ©ãƒ¼: Tavilyã‚¯ã‚¨ãƒªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™: {query_response}"
            # ã‚¯ã‚¨ãƒªç”ŸæˆãŒå¤±æ•—ã—ã¦ã‚‚ã€Tavilyç„¡ã—ã§ç¶šè¡Œ
            augmented_problem = problem_statement
        else:
            analysis_queries = query_response.get("analysis_queries", [])
            solution_queries = query_response.get("solution_queries", [])
            
            yield f"--- âœ”ï¸ ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒª ---"
            yield f"  - åˆ†æã‚¯ã‚¨ãƒª: {', '.join(analysis_queries) if analysis_queries else 'ãªã—'}"
            yield f"  - è§£æ±ºç­–ã‚¯ã‚¨ãƒª: {', '.join(solution_queries) if solution_queries else 'ãªã—'}"
            
            analysis_results_list = []
            solution_results_list = []

            # --- ãƒ•ã‚§ãƒ¼ã‚º1: åˆ†æã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ ---
            if analysis_queries:
                yield "--- ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º1: èª²é¡Œã®ç¾çŠ¶åˆ†æãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹... ---"
                for q in analysis_queries:
                    if not q.strip(): continue
                    yield f"  - æ¤œç´¢ä¸­ (åˆ†æ): {q}"
                    tavily_resp = self.tavily.search(q, num_results=self.tavily_results_per_query)
                    if isinstance(tavily_resp, dict) and "results" in tavily_resp:
                        analysis_results_list.extend(tavily_resp["results"])
                    elif isinstance(tavily_resp, dict) and "error" in tavily_resp:
                         yield f"  - Tavily ã‚¨ãƒ©ãƒ¼ (åˆ†æã‚¯ã‚¨ãƒª: {q}): {tavily_resp['error']}"
            
            # --- ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ ---
            if solution_queries:
                yield "--- ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹... ---"
                for q in solution_queries:
                    if not q.strip(): continue
                    yield f"  - æ¤œç´¢ä¸­ (è§£æ±ºç­–): {q}"
                    tavily_resp = self.tavily.search(q, num_results=self.tavily_results_per_query)
                    if isinstance(tavily_resp, dict) and "results" in tavily_resp:
                        solution_results_list.extend(tavily_resp["results"])
                    elif isinstance(tavily_resp, dict) and "error" in tavily_resp:
                         yield f"  - Tavily ã‚¨ãƒ©ãƒ¼ (è§£æ±ºç­–ã‚¯ã‚¨ãƒª: {q}): {tavily_resp['error']}"

            # UIã«æ¤œç´¢çµæœã‚’æ¸¡ã™
            yield {"tavily_info_analysis": analysis_results_list, "tavily_info_solution": solution_results_list}

            # --- 2ã¤ã®ãƒªã‚µãƒ¼ãƒçµæœã‚’è¦ç´„ãƒ»çµ±åˆ ---
            yield "--- âœï¸ 2ã¤ã®ãƒªã‚µãƒ¼ãƒçµæœã‚’è¦ç´„ã—ã€å•é¡Œæ–‡ã«çµ±åˆã—ã¾ã™... ---"
            try:
                augmented_problem = self._summarize_multi_phase_results_with_llm(
                    problem_statement, 
                    analysis_results_list, 
                    solution_results_list
                )
            except Exception as e:
                augmented_problem = problem_statement
                yield f"è­¦å‘Š: Tavily è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        # æ‹¡å¼µã•ã‚ŒãŸå•é¡Œæ–‡ï¼ˆã¾ãŸã¯å…ƒã®å•é¡Œæ–‡ï¼‰ã§EvoGenã®æœ¬ä½“ã‚’å®Ÿè¡Œ
        yield from super().solve(augmented_problem, generations)
    # === â˜…ä¿®æ­£ç®‡æ‰€ 2 çµ‚äº† ===

# ----------------------------
# 5) Streamlit UI (â˜…ä¿®æ­£ç®‡æ‰€â˜…)
# ----------------------------
st.set_page_config(page_title="EvoGen AI + Tavily", layout="wide")
st.title("EvoGen AI (Tavily çµ±åˆç‰ˆ) ğŸ§¬ğŸŒ")
st.markdown("Tavily ã«ã‚ˆã‚‹æœ€æ–°ã‚¦ã‚§ãƒ–æƒ…å ±ã‚’å‚ç…§ã—ãªãŒã‚‰ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ãŒé€²åŒ–çš„ã«è§£æ±ºç­–ã‚’æ¢ç´¢ã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    gemini_key = st.text_input("Google Gemini API Key", type="password", help="Gemini ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    tavily_key = st.text_input("Tavily API Key", type="password", help="Tavily ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    st.subheader("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    num_generations = st.slider("ä¸–ä»£æ•°", 1, 5, 2, help="è§£æ±ºç­–ã‚’é€²åŒ–ã•ã›ã‚‹å›æ•°ã§ã™ã€‚")
    num_solutions = st.slider("ä¸–ä»£ã”ã¨ã®è§£æ±ºç­–ã®æ•°", 3, 10, 4, help="1ä¸–ä»£ã‚ãŸã‚Šã«ç”Ÿæˆãƒ»è©•ä¾¡ã™ã‚‹è§£æ±ºç­–ã®æ•°ã§ã™ã€‚")
    tavily_results_per_search = st.slider("Tavily æ¤œç´¢çµæœæ•° (ã‚¯ã‚¨ãƒªæ¯)", 1, 10, 3, help="1ã¤ã®ã‚¯ã‚¨ãƒªã‚ãŸã‚Šã«Tavily ã‹ã‚‰å–å¾—ã™ã‚‹æ¤œç´¢çµæœæ•°ã€‚")
    st.markdown("---")
    st.info("Tavily ã‚’ä½¿ã£ã¦èª²é¡Œã«é–¢é€£ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’å–å¾—ã—ã€ãã‚Œã‚’å‚è€ƒã«è§£æ±ºç­–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

default_problem = """
# èª²é¡Œ
ä¹å·å·¥æ¥­å¤§å­¦ã®å…¥å­¦å¿—é¡˜è€…æ•°ã‚’å¢—åŠ ã•ã›ã‚‹ã‚ˆã†ãªç”»æœŸçš„ãªè§£æ±ºç­–ã‚’ææ¡ˆã›ã‚ˆã€‚

# è¦ä»¶ãƒ»åˆ¶ç´„æ¡ä»¶
- ã‚³ã‚¹ãƒˆãŒã‚ã¾ã‚Šã‹ã‹ã‚‰ãªã„ã“ã¨ã€‚
- ä¹å·å·¥æ¥­å¤§å­¦ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æãªã‚ãªã„ã“ã¨ã€‚
- å„ªç§€ãªå­¦ç”Ÿã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ãã‚‹ã“ã¨ã€‚
"""
problem_statement = st.text_area("è§£æ±ºã—ãŸã„èª²é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=default_problem, height=260)

if st.button("è§£æ±ºç­–ã®ç”Ÿæˆã‚’é–‹å§‹", type="primary"):
    if not gemini_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Google Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not tavily_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Tavily APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not problem_statement.strip():
        st.warning("èª²é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status_placeholder = st.empty()
        team_placeholder = st.empty()
        tavily_placeholder = st.container() # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ã‚³ãƒ³ãƒ†ãƒŠã«å¤‰æ›´
        results_area = st.container()
        final_result_placeholder = st.container()

        with st.spinner("ğŸŒ€ AIãŒæ€è€ƒä¸­ã§ã™..."):
            try:
                gemini_client = GeminiClient(api_key=gemini_key)
                tavily_client = TavilyClient(api_key=tavily_key)
            except Exception as e:
                st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()

            solver = EvoGenSolver_Tavily(
                llm_client=gemini_client,
                tavily_client=tavily_client,
                num_solutions_per_generation=num_solutions,
                tavily_results_per_search=tavily_results_per_search
            )
            
            # Tavilyçµæœã‚’Tavilyãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
            def display_tavily_results(results_list, title):
                with tavily_placeholder.container():
                    st.subheader(title)
                    if results_list:
                        for r in results_list:
                            title = r.get("title", "No title")
                            url = r.get("url", "")
                            snippet = r.get("snippet", "") or r.get("description", "")
                            st.markdown(f"- [{title}]({url})")
                            if snippet:
                                st.caption(snippet)
                    else:
                        st.write("ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.markdown("---")


            # --- Solverã‚’å®Ÿè¡Œã—ã€çµæœã‚’UIã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º ---
            for result in solver.solve(problem_statement, generations=num_generations):
                if isinstance(result, str):
                    status_placeholder.info(result)

                # === â˜…ä¿®æ­£ç®‡æ‰€ 3: 2ãƒ•ã‚§ãƒ¼ã‚ºã®Tavilyçµæœã‚’ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° ===
                elif isinstance(result, dict) and ("tavily_info_analysis" in result or "tavily_info_solution" in result):
                    # æ—¢ã«Tavilyãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«æ›¸ãè¾¼ã‚“ã§ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ä¸€åº¦ã‚¯ãƒªã‚¢ã™ã‚‹
                    tavily_placeholder.empty()
                    
                    analysis_data = result.get("tavily_info_analysis", [])
                    solution_data = result.get("tavily_info_solution", [])
                    
                    if analysis_data:
                        display_tavily_results(analysis_data, "ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º1: èª²é¡Œã®ç¾çŠ¶åˆ†æãƒªã‚µãƒ¼ãƒçµæœ")
                    
                    if solution_data:
                        display_tavily_results(solution_data, "ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒªã‚µãƒ¼ãƒçµæœ")
                # === â˜…ä¿®æ­£ç®‡æ‰€ 3 çµ‚äº† ===

                elif isinstance(result, dict) and "agent_team" in result:
                    with team_placeholder.container():
                        st.subheader("ğŸ¤– ç·¨æˆã•ã‚ŒãŸAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ")
                        team = result["agent_team"]
                        with st.expander("ãƒãƒ¼ãƒ ã®è©³ç´°ã‚’è¡¨ç¤º"):
                            gen = team.get("initial_generator", {})
                            st.markdown("##### ğŸ’¡ ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆæ‹…å½“")
                            st.markdown(f"**å½¹å‰²:** {gen.get('role', 'æœªå®šç¾©')}")
                            st.markdown(f"**æŒ‡ç¤º:** {gen.get('instructions', 'æœªå®šç¾©')}")
                            eva = team.get("evaluator", {})
                            st.markdown("##### ğŸ§ è©•ä¾¡æ‹…å½“")
                            st.markdown(f"**å½¹å‰²:** {eva.get('role', 'æœªå®šç¾©')}")
                            criteria_list = eva.get('criteria', [])
                            criteria_md = ""
                            if criteria_list:
                                for c in criteria_list:
                                    criteria_md += f"- **{c.get('criterion', 'é …ç›®åãªã—')}:** {c.get('weight', 0)}ç‚¹\n"
                            st.markdown(f"**è©•ä¾¡åŸºæº–:**\n{criteria_md or 'æœªå®šç¾©'}")
                            syn = team.get("synthesizer", {})
                            st.markdown("##### ğŸ§¬ é€²åŒ–ãƒ»çµ±åˆæ‹…å½“")
                            st.markdown(f"**å½¹å‰²:** {syn.get('role', 'æœªå®šç¾©')}")
                            st.markdown(f"**æŒ‡ç¤º:** {syn.get('instructions', 'æœªå®šç¾©')}")

                # === ä¸–ä»£ã”ã¨ï¼ˆé€”ä¸­çµŒéï¼‰ã®è¡¨ç¤ºï¼ˆUIå¤‰æ›´ãªã—ï¼‰ ===
                elif isinstance(result, dict) and "generation" in result:
                    gen_data = result
                    with results_area.container():
                        st.subheader(f"ç¬¬ {gen_data['generation']} ä¸–ä»£ã®çµæœ")
                        with st.container(border=True):
                            if not gen_data.get('results'):
                                st.write("ã“ã®ä¸–ä»£ã§ã¯æœ‰åŠ¹ãªè§£æ±ºç­–ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                                continue
                            
                            for item in gen_data.get('results', []):
                                sol = item.get('solution', {})
                                eva = item.get('evaluation', {})
                                score = eva.get('total_score', 0)
                                
                                st.markdown(f"**é¡Œå:** {sol.get('name', 'N/A')} (ã‚¹ã‚³ã‚¢: {score})")
                                content = sol.get('specific_method', 'N/A') 
                                st.markdown(f"**å…·ä½“çš„ãªæ–¹æ³•:** {content}")
                                
                                if item != gen_data.get('results', [])[-1]:
                                    st.markdown("---")

        # === æœ€çµ‚çµæœã®è¡¨ç¤ºï¼ˆUIå¤‰æ›´ãªã—ï¼‰ ===
        
        all_solutions = [
            item for gen in solver.history
            for item in gen.get("results", [])
            if item.get("evaluation") and "total_score" in item["evaluation"]
        ]

        if all_solutions:
            sorted_solutions = sorted(
                all_solutions,
                key=lambda x: x["evaluation"]["total_score"],
                reverse=True
            )
            
            top_5_solutions = sorted_solutions[:5]

            status_placeholder.empty()
            st.balloons()

            with final_result_placeholder:
                st.success("ğŸ† å‡¦ç†å®Œäº†ï¼ã‚¹ã‚³ã‚¢ãƒˆãƒƒãƒ—5ã®è§£æ±ºç­–ã¯ã“ã¡ã‚‰ã§ã™ã€‚")
                
                for i, item in enumerate(top_5_solutions):
                    sol = item.get('solution', {})
                    eva = item.get('evaluation', {})
                    score = eva.get('total_score', 'N/A')
                    
                    st.header(f"ğŸ… ç¬¬ {i + 1} ä½: {sol.get('name', 'N/A')}")
                    st.metric(label="æœ€çµ‚ã‚¹ã‚³ã‚¢", value=f"{score}")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.info(f"**å…·ä½“çš„ãªæ–¹æ³•**\n\n{sol.get('specific_method', 'N/A')}")
                        st.warning(f"**æ‡¸å¿µç‚¹ãƒ»æ”¹å–„ç‚¹**\n\n{eva.get('weaknesses', 'N/A')}")
                    with col2:
                        st.success(f"**å„ªã‚ŒãŸç‚¹**\n\n{eva.get('strengths', 'N/A')}")
                        st.info(f"**ç·è©•**\n\n{eva.get('overall_comment', 'N/A')}")
                    st.markdown("---")
        else:
            status_placeholder.warning("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸãŒã€æœ€çµ‚çš„ãªè§£æ±ºç­–ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
