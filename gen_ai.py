# app_tavily_fixed_v12_universal_proposal.py
"""
EvoGen AI with Tavily integration (v12.0: æ±ç”¨ææ¡ˆãƒ¢ãƒ‡ãƒ«ç‰ˆ)

v11.0 (app_tavily9.py) ã‹ã‚‰ã®å¤‰æ›´ç‚¹:
- (æ±ç”¨æ€§å‘ä¸Š) ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æœ›ã«åŸºã¥ãã€ã‚ã‚‰ã‚†ã‚‹å•é¡Œã«å¯¾å¿œã§ãã‚‹ã‚ˆã†ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’
  ã€Œè§£æ±ºç­–(solution)ã€ã‹ã‚‰ã€Œææ¡ˆ(proposal)ã€ã«å¤‰æ›´ã€‚
- (ãƒ‡ãƒ¼ã‚¿æ§‹é€ )
  - å¾“æ¥ã® `{"name": "...", "summary": "...", "specific_method": "..."}` ã‚’å»ƒæ­¢ã€‚
  - æ–°ãŸã« `{"proposal_title": "...", "proposal_content": "...", "proposal_rationale": "..."}` ã‚’æ¡ç”¨ã€‚
    - `proposal_title`: ææ¡ˆã®åç§° (ä¾‹: AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³åã€ä¿³å¥ã®é¡Œå)
    - `proposal_content`: ææ¡ˆã®æ ¸ (ä¾‹: ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³æ¦‚è¦ã€ä¿³å¥ãã®ã‚‚ã®)
    - `proposal_rationale`: ææ¡ˆã®ç†ç”± (ä¾‹: å…·ä½“çš„ãªæ–¹æ³•è«–ã€ä¿³å¥ã®ç‹™ã„ã‚„èƒŒæ™¯)
- (PromptManager ä¿®æ­£)
  - `get_initial_generation_prompt`, `get_next_generation_prompt`, 
    `get_revolutionary_generation_prompt` ãŒæ–°ã—ã„æ±ç”¨JSONæ§‹é€ ã‚’
    ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¨é¢æ”¹ä¿®ã€‚
  - `get_evaluation_prompt` ãŒæ–°ã—ã„æ±ç”¨JSONæ§‹é€ ã‚’è©•ä¾¡å¯¾è±¡ã¨ã—ã¦
    å—ã‘å–ã‚‹ã‚ˆã†ã«ä¿®æ­£ã€‚
- (EvoGenSolver ä¿®æ­£)
  - `_evaluate_solutions` å†…ã®ãƒ­ã‚°å‚ç…§ã‚’ `name` ã‹ã‚‰ `proposal_title` ã«å¤‰æ›´ã€‚
- (Streamlit UI ä¿®æ­£)
  - ä¸–ä»£åˆ¥ãŠã‚ˆã³æœ€çµ‚çµæœã®è¡¨ç¤ºã‚’ã€æ–°ã—ã„æ±ç”¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
    (proposal_title, proposal_content, proposal_rationale) ã‚’
    è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã«ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¤‰æ›´ã€‚

v11.0 ã®ç‰¹å¾´ (v10.1ã‹ã‚‰å¤‰æ›´):
- (è©•ä¾¡ç²¾åº¦å‘ä¸Š) è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€Œè©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³(evaluation_guideline)ã€ã‚’
  å‹•çš„ã«ç”Ÿæˆã—ã€ãã‚Œã«åŸºã¥ãé«˜ç²¾åº¦ãªè©•ä¾¡ã‚’è¡Œã†ã€‚
"""

import streamlit as st
import os
import json
import abc
from typing import List, Dict, Any, Generator, Optional
import time
import random 

# --- å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ ---
try:
    import google.generativeai as genai
except Exception:
    genai = None

try:
    import requests
except ImportError:
    requests = None

# ----------------------------
# 1) LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå±¤ (å¤‰æ›´ãªã—)
# ----------------------------
class LLMClient(abc.ABC):
    """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åŸºæœ¬ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹"""
    @abc.abstractmethod
    def call(self, prompt: str) -> Dict[str, Any]:
        pass

class GeminiClient(LLMClient):
    """Google Gemini ç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆv9.0 JSONä¿®å¾©æ©Ÿèƒ½ä»˜ãï¼‰"""
    def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"): 
        if genai is None:
            raise ImportError("`google-generativeai`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install google-generativeai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
        self.generation_config = genai.GenerationConfig(
            response_mime_type="application/json"
        )

    def _extract_json(self, text: str) -> Optional[str]:
        """
        ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚„ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ©ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹
        æ–‡å­—åˆ—ã‹ã‚‰ã€æœ€åˆã¨æœ€å¾Œã®æ³¢æ‹¬å¼§/è§’æ‹¬å¼§ã«åŸºã¥ã„ã¦JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºã™ã‚‹ã€‚
        """
        if not text:
            return None
        
        start_brace = text.find('{')
        start_bracket = text.find('[')
        
        if start_brace == -1 and start_bracket == -1:
            return None
            
        if start_brace == -1:
            start = start_bracket
        elif start_bracket == -1:
            start = start_brace
        else:
            start = min(start_brace, start_bracket)
            
        end_brace = text.rfind('}')
        end_bracket = text.rfind(']')
        
        if end_brace == -1 and end_bracket == -1:
            return None
            
        end = max(end_brace, end_bracket)
        
        if end <= start:
            return None
            
        potential_json = text[start:end+1]
        return potential_json

    def _get_json_repair_prompt(self, malformed_text: str) -> str:
        """
        LLMãŒç”Ÿæˆã—ãŸä¸æ­£ãªå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿®å¾©ã•ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
        """
        return f"""
        # æŒ‡ç¤º
        ã‚ãªãŸã¯ä»¥å‰ã€JSONå½¢å¼ã§ã®å‡ºåŠ›ã‚’æ±‚ã‚ã‚‰ã‚Œã¾ã—ãŸãŒã€ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚
        ã—ã‹ã—ã€ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯JSONã¨ã—ã¦æ­£ã—ããƒ‘ãƒ¼ã‚¹ï¼ˆè§£æï¼‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚

        # ä¸æ­£ãªå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆ
        ```
        {malformed_text}
        ```

        # ã‚¿ã‚¹ã‚¯
        ä¸Šè¨˜ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’**å®Œå…¨ã«**åæ˜ ã—ã¤ã¤ã€**ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ (```json ... ```) ã‚„èª¬æ˜æ–‡ã‚’ä¸€åˆ‡å«ã¾ãªã„ã€
        å³å¯†ã«æ­£ã—ã„JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆ`{{ ... }}` ã¾ãŸã¯ `[ ... ]` ã§å§‹ã¾ã‚‹ï¼‰**
        ã¨ã—ã¦ä¿®æ­£ã—ã€ãã®JSONã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        """

    def call(self, prompt: str, is_retry: bool = False) -> Dict[str, Any]:
        """
        prompt -> LLM å‘¼ã³å‡ºã— -> JSON ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° -> JSON ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
        ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã€LLMã«ä¿®å¾©ã‚’ä¾é ¼ã™ã‚‹ãƒªãƒˆãƒ©ã‚¤ã‚’1å›è¡Œã†ã€‚
        """
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            text = getattr(response, "text", None) or getattr(response, "response", None) or str(response)
            
            cleaned_text = self._extract_json(text)
            
            if cleaned_text:
                try:
                    return json.loads(cleaned_text) 
                except Exception as e_clean:
                    st.warning(f"[GeminiClient Warning] JSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ (ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ)ã€‚ Error: {e_clean}")
                    
                    if is_retry:
                        st.error(f"[GeminiClient Error] JSONä¿®å¾©ãƒªãƒˆãƒ©ã‚¤ã«ã‚‚å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        return {"raw_text": text, "parse_error": f"Retry failed: {e_clean}"}
                    else:
                        st.info(f"[GeminiClient Info] JSONä¿®å¾©ã®ãŸã‚ã€LLMã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                        repair_prompt = self._get_json_repair_prompt(text)
                        return self.call(repair_prompt, is_retry=True)
            else:
                st.warning(f"[GeminiClient Warning] å¿œç­”ã‹ã‚‰JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                
                if is_retry:
                    st.error(f"[GeminiClient Error] JSONä¿®å¾©ãƒªãƒˆãƒ©ã‚¤å¾Œã‚‚ã€JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    return {"raw_text": text, "parse_error": "Retry failed: No JSON block found"}
                else:
                    st.info(f"[GeminiClient Info] JSONä¿®å¾©ã®ãŸã‚ã€LLMã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                    repair_prompt = self._get_json_repair_prompt(text)
                    return self.call(repair_prompt, is_retry=True)
                
        except Exception as e:
            st.error(f"[GeminiClient Error] API å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if is_retry:
                return {"error": f"API call failed during retry: {e}"}
            else:
                return {"error": str(e)}


# ----------------------------
# 2) Tavily ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (å¤‰æ›´ãªã—)
# ----------------------------
class TavilyClient:
    """
    Tavily Search API ã¨ã®ã‚„ã‚Šå–ã‚Šã‚’è¡Œã†ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€‚
    """
    DEFAULT_ENDPOINT = "https://api.tavily.com/search"

    def __init__(self, api_key: str, endpoint: str = DEFAULT_ENDPOINT, timeout: int = 15):
        if requests is None:
            raise ImportError("`requests`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install requests ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        self.api_key = api_key
        self.endpoint = endpoint
        self.timeout = timeout

    def search(self, query: str, num_results: int = 5, domain: Optional[str] = None, lang: Optional[str] = None) -> Dict[str, Any]:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {"query": query, "max_results": num_results}
        if domain:
            payload["domain"] = domain
        if lang:
            payload["language"] = lang

        try:
            resp = requests.post(self.endpoint, headers=headers, json=payload, timeout=self.timeout)
            resp.raise_for_status()
            data = resp.json()
            return data
        except requests.exceptions.RequestException as e:
            return {"error": f"HTTP error: {e}"}
        except ValueError as e:
            return {"error": f"JSON parse error: {e}", "raw": resp.text if 'resp' in locals() else None}
        except Exception as e:
            return {"error": str(e)}

# ----------------------------
# 3) PromptManager (â˜…ä¿®æ­£ç®‡æ‰€â˜…)
# ----------------------------
class PromptManager:
    """AIã¸ã®æŒ‡ç¤ºæ›¸ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def get_tavily_multi_phase_query_prompt(self, problem_statement: str) -> str:
        """
        (v10.0ã®ã¾ã¾)
        èª²é¡Œè§£æ±ºã«å¿…è¦ãªæƒ…å ±ã‚’ã€Œåˆ†æã€ã¨ã€Œè§£æ±ºç­–ã€ã®2ãƒ•ã‚§ãƒ¼ã‚ºã§æ¤œç´¢ã™ã‚‹ãŸã‚ã®
        ã‚¯ã‚¨ãƒªã‚’LLMã«ç”Ÿæˆã•ã›ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚(ã‚¯ã‚¨ãƒªæ•°4)
        """
        return f"""
        ã‚ãªãŸã¯ã€æç¤ºã•ã‚ŒãŸã€Œèª²é¡Œã€ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®èª¿æŸ»ã‚’2æ®µéšã§è¡Œã†å°‚é–€ã®èª¿æŸ»å“¡ã§ã™ã€‚

        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’åˆ†æã—ã€2ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã«å¯¾å¿œã™ã‚‹**æ—¥æœ¬èªã®æ¤œç´¢ã‚¯ã‚¨ãƒª**ã‚’ãã‚Œãã‚Œ4ã¤ãšã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

        # ãƒ•ã‚§ãƒ¼ã‚º1: ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ
        èª²é¡Œæ–‡ã«å«ã¾ã‚Œã‚‹å›ºæœ‰åè©ï¼ˆçµ„ç¹”åã€åœ°åã€ç‰¹å®šã®ã‚·ã‚¹ãƒ†ãƒ åãªã©ï¼‰ã‚’ç‰¹å®šã—ã€
        ãã®å¯¾è±¡ã®ã€Œæœ€æ–°æƒ…å ±ã€ã€Œç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿ã€ã€Œé–¢é€£ã™ã‚‹èƒŒæ™¯ã‚„åˆ¶ç´„ã€ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã€‚
        (ä¾‹: ã€Œã‚·ã‚¹ãƒ†ãƒ X æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã€, ã€Œçµ„ç¹”Yã®ç¾çŠ¶ã®æˆ¦ç•¥ã€)

        # ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒ»æŠ€è¡“èª¿æŸ»
        èª²é¡Œãã®ã‚‚ã®ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ã€Œæœ€æ–°ã®å¯¾ç­–äº‹ä¾‹ã€ã€Œé–¢é€£ã™ã‚‹æ–°ã—ã„æŠ€è¡“ã®å‹•å‘ã€ã€Œä»–åˆ†é‡ã§ã®æˆåŠŸäº‹ä¾‹ã€ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã€‚
        (ä¾‹: ã€Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ äº‹ä¾‹ã€, ã€ŒBtoBãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚° æœ€æ–°æ‰‹æ³•ã€)

        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "analysis_queries": [
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª1 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª2 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª3 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚¯ã‚¨ãƒª4 (æ—¥æœ¬èª)"
          ],
          "solution_queries": [
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª1 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª2 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª3 (æ—¥æœ¬èª)",
            "ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚¯ã‚¨ãƒª4 (æ—¥æœ¬èª)"
          ]
        }}
        """

    def get_agent_personas_prompt(self, problem_statement: str) -> str:
        """
        (v11.0ã®ã¾ã¾)
        ã‚ã‚‰ã‚†ã‚‹èª²é¡Œã‚’åˆ†æã—ã€å°‚é–€ç‰¹åŒ–ã—ãŸã€Œè§£æ±ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã¨ã€
        èª²é¡Œã«å¿œã˜ã¦æœ€é©åŒ–ã•ã‚ŒãŸã€Œè©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ï¼ˆå½¹å‰²ï¼‹è©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼‰ã‚’ã‚¼ãƒ­ã‹ã‚‰ç”Ÿæˆã™ã‚‹ã€‚
        """
        return f"""
        # å½¹å‰²
        ã‚ãªãŸã¯ã€éå¸¸ã«è¤‡é›‘ãªèª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ãªã‚‹ã€Œã‚¹ã‚¦ã‚©ãƒ¼ãƒ ï¼ˆç¾¤ã‚Œï¼‰ã€ã‚’ç·¨æˆã™ã‚‹ã€Œãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€ã§ã™ã€‚

        # ã‚¿ã‚¹ã‚¯
        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æœ€ã‚‚åŠ¹æœçš„ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç¾¤ã‚’ç·¨æˆã—ã¦ãã ã•ã„ã€‚
        ç·¨æˆã¯ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å³å¯†ã«è¡Œã£ã¦ãã ã•ã„ã€‚

        ## ã‚¹ãƒ†ãƒƒãƒ—1: èª²é¡Œã®å¾¹åº•åˆ†æ (Your Internal Monologue)
        (ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯å‡ºåŠ›ã«å«ã‚ãšã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®šç¾©ã®ãŸã‚ã«å†…éƒ¨ã§å®Ÿè¡Œã—ã¦ãã ã•ã„)
        1.  **æ ¸å¿ƒçš„ç›®æ¨™(Goal)ã¯ä½•ã‹ï¼Ÿ**: èª²é¡Œæ–‡ãŒæœ€çµ‚çš„ã«é”æˆã—ãŸã„çŠ¶æ…‹ã¯ä½•ã‹ï¼Ÿ (ä¾‹: ã€Œåç›Šã‚’20%å‘ä¸Šã•ã›ã‚‹ã€ã€Œã‚·ã‚¹ãƒ†ãƒ ã®å¿œç­”é€Ÿåº¦ã‚’50msçŸ­ç¸®ã™ã‚‹ã€ã€Œãƒ–ãƒ©ãƒ³ãƒ‰èªçŸ¥åº¦ã‚’é«˜ã‚ã‚‹ã€)
        2.  **ä¸»è¦ãªåˆ¶ç´„(Constraints)ã¯ä½•ã‹ï¼Ÿ**: èª²é¡Œæ–‡ã«æ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ã€ã‚ã‚‹ã„ã¯æš—é»™çš„ã«å«ã¾ã‚Œã‚‹åˆ¶ç´„ã¯ï¼Ÿ (ä¾‹: ã€Œäºˆç®—100ä¸‡å††ä»¥å†…ã€ã€Œ3ãƒ¶æœˆä»¥å†…ã«å®Ÿè£…ã€ã€Œæ—¢å­˜ã®Aã‚·ã‚¹ãƒ†ãƒ ã¨é€£æºå¿…é ˆã€ã€Œæ³•çš„è¦åˆ¶ã®éµå®ˆã€)
        3.  **ä¸»è¦ãªåˆ©å®³é–¢ä¿‚è€…(Stakeholders)ã¯èª°ã‹ï¼Ÿ**: ã“ã®èª²é¡Œã®å½±éŸ¿ã‚’å—ã‘ã‚‹ã®ã¯èª°ã‹ï¼Ÿ (ä¾‹: ã€Œä¸­å°ä¼æ¥­ã®çµŒç†æ‹…å½“è€…ã€ã€Œã‚¢ãƒ—ãƒªã®æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã€Œç ”ç©¶å®¤ã®ãƒ¡ãƒ³ãƒãƒ¼ã€ã€Œç¤¾ä¼šå…¨ä½“ã€)
        4.  **èª²é¡Œã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¯ä½•ã‹ï¼Ÿ**: ãªãœä»Šã€ã“ã®ç›®æ¨™ãŒé”æˆã§ãã¦ã„ãªã„ã®ã‹ï¼Ÿ

        ## ã‚¹ãƒ†ãƒƒãƒ—2: è§£æ±ºãƒ»é€²åŒ–æ‹…å½“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (10ä½“) ã®å®šç¾©
        - ã‚¹ãƒ†ãƒƒãƒ—1ã®åˆ†æã«åŸºã¥ãã€èª²é¡Œè§£æ±ºã«æœ€é©åŒ–ã•ã‚ŒãŸã€Œäº’ã„ã«ç•°ãªã‚‹10ã®è¦–ç‚¹ã€ã‚’æŒã¤å°‚é–€å®¶ï¼ˆsolver_agentsï¼‰ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - **é‡è¦**: ã€Œãƒãƒ¼ã‚±ã‚¿ãƒ¼ã€ã®ã‚ˆã†ãªä¸€èˆ¬çš„ãªå½¹å‰²ã§ã¯ãªãã€ã€Œ**[åˆ©å®³é–¢ä¿‚è€…]ã®[ç‰¹å®šã®èª²é¡Œ]ã‚’è§£æ±ºã™ã‚‹å°‚é–€å®¶**ã€ã‚„ã€Œ**[ä¸»è¦ãªåˆ¶ç´„]ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹[ç‰¹å®šæŠ€è¡“]ã®å°‚é–€å®¶**ã€ã®ã‚ˆã†ã«ã€**ã“ã®èª²é¡Œå°‚ç”¨ã«ç‰¹åŒ–ã•ã›ãŸå½¹å‰²ï¼ˆroleï¼‰**ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - `instructions`ã«ã¯ã€ãã®å°‚é–€æ€§ã‚’æ´»ã‹ã—ã¦ã€ŒåˆæœŸè§£ã®ç”Ÿæˆã€ã¨ã€Œæ—¢å­˜è§£ã®é€²åŒ–ã€ã®ä¸¡æ–¹ã§ã©ã†æŒ¯ã‚‹èˆã†ã¹ãã‹å…·ä½“çš„ã«æŒ‡ç¤ºã—ã¦ãã ã•ã„ã€‚

        ## ã‚¹ãƒ†ãƒƒãƒ—3: èª²é¡Œç‰¹åŒ–å‹ è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (3ä½“) ã®å®šç¾©
        - ã‚¹ãƒ†ãƒƒãƒ—1ã®åˆ†æï¼ˆæ ¸å¿ƒçš„ç›®æ¨™ã€ä¸»è¦ãªåˆ¶ç´„ã€åˆ©å®³é–¢ä¿‚è€…ï¼‰ã«åŸºã¥ãã€ç”Ÿæˆã•ã‚ŒãŸè§£æ±ºç­–ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«**æœ€ã‚‚é‡è¦ã¨ãªã‚‹3ã¤ã®ç•°ãªã‚‹è©•ä¾¡è¦³ç‚¹**ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
        - ãã®3ã¤ã®è¦³ç‚¹ã«åŸºã¥ãã€ãã‚Œãã‚Œå°‚é–€ã®è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆevaluatorsï¼‰ã‚’3ä½“å®šç¾©ã—ã¦ãã ã•ã„ã€‚
        - **!!æœ€é‡è¦!!**: ã€Œã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã€ã€Œå®Ÿç¾æ€§ã€ã€Œãƒªã‚¹ã‚¯ã€ã®ã‚ˆã†ãªå›ºå®šçš„ãªå½¹å‰²ã«**ç¸›ã‚‰ã‚Œãªã„ã§ãã ã•ã„**ã€‚**ã“ã®èª²é¡Œã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸå½¹å‰²ï¼ˆroleï¼‰**ã‚’ã‚¼ãƒ­ã‹ã‚‰è€ƒæ¡ˆã—ã¦ãã ã•ã„ã€‚
        - (ä¾‹: ã€Œä¿³å¥ã‚’ä½œæˆã™ã‚‹ã€èª²é¡Œã®å ´åˆã€ã€ŒèŠ¸è¡“æ€§ãƒ»æƒ…æ™¯æå†™ è©•ä¾¡è€…ã€ã€Œé©æ–°æ€§ãƒ»å­£èªè§£é‡ˆ è©•ä¾¡è€…ã€ã€Œèª­è€…ã®å¿ƒç†çš„åŠ¹æœ è©•ä¾¡è€…ã€ãªã©ã€‚)
        - (ä¾‹: ã€Œãƒ“ã‚¸ãƒã‚¹AIã‚’ææ¡ˆã™ã‚‹ã€èª²é¡Œã®å ´åˆã€ã€ŒROIãƒ»åç›Šæ€§ è©•ä¾¡è€…ã€ã€ŒæŠ€è¡“çš„å®Ÿç¾æ€§ãƒ»é‹ç”¨ è©•ä¾¡è€…ã€ã€ŒUXãƒ»é¡§å®¢å—å®¹æ€§ è©•ä¾¡è€…ã€ãªã©ã€‚)
        - `role`: ã‚ãªãŸãŒè€ƒæ¡ˆã—ãŸã€èª²é¡Œã«ç‰¹åŒ–ã—ãŸè©•ä¾¡è€…ã®å½¹å‰²åã€‚
        - `evaluation_guideline`: (â˜…v11.0ã®ã¾ã¾â˜…) ãã®å½¹å‰²ãŒè§£æ±ºç­–ã‚’å³å¯†ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ã€**å…·ä½“çš„ã‹ã¤è©³ç´°ãªè©•ä¾¡æŒ‡é‡ï¼ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼‰**ã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«ã¯ã€ä½•ã‚’æœ€é‡è¦è¦–ã—ã€ã©ã®ã‚ˆã†ãªè¦³ç‚¹ã§å„ªåŠ£ã‚’åˆ¤æ–­ã™ã¹ãã‹ã‚’æ˜ç¢ºã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

        # èª²é¡Œ
        {problem_statement}

        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "solver_agents": [
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²1ï¼‰", "instructions": "..." }},
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²2ï¼‰", "instructions": "..." }},
            // ... (10ä½“åˆ†)
            {{ "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2ã§å®šç¾©ã—ãŸå°‚é–€çš„å½¹å‰²10ï¼‰", "instructions": "..." }}
          ],
          "evaluators": [
            // è©•ä¾¡è€…1: ã‚ãªãŸãŒè€ƒæ¡ˆã—ãŸèª²é¡Œç‰¹åŒ–ã®å½¹å‰²
            {{ 
              "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã§è€ƒæ¡ˆã—ãŸè©•ä¾¡å½¹å‰²1ï¼‰", 
              "evaluation_guideline": "ï¼ˆãã®å½¹å‰²ã®ãŸã‚ã®å…·ä½“çš„ã‹ã¤è©³ç´°ãªè©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‚ä½•ã‚’æœ€é‡è¦è¦–ã—ã€ã©ã†åˆ¤æ–­ã™ã¹ãã‹ã€‚ï¼‰"
            }},
            // è©•ä¾¡è€…2: ã‚ãªãŸãŒè€ƒæ¡ˆã—ãŸèª²é¡Œç‰¹åŒ–ã®å½¹å‰²
            {{ 
              "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã§è€ƒæ¡ˆã—ãŸè©•ä¾¡å½¹å‰²2ï¼‰", 
              "evaluation_guideline": "ï¼ˆãã®å½¹å‰²ã®ãŸã‚ã®å…·ä½“çš„ã‹ã¤è©³ç´°ãªè©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‚ä½•ã‚’æœ€é‡è¦è¦–ã—ã€ã©ã†åˆ¤æ–­ã™ã¹ãã‹ã€‚ï¼‰"
            }},
            // è©•ä¾¡è€…3: ã‚ãªãŸãŒè€ƒæ¡ˆã—ãŸèª²é¡Œç‰¹åŒ–ã®å½¹å‰²
            {{ 
              "role": "ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã§è€ƒæ¡ˆã—ãŸè©•ä¾¡å½¹å‰²3ï¼‰", 
              "evaluation_guideline": "ï¼ˆãã®å½¹å‰²ã®ãŸã‚ã®å…·ä½“çš„ã‹ã¤è©³ç´°ãªè©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‚ä½•ã‚’æœ€é‡è¦è¦–ã—ã€ã©ã†åˆ¤æ–­ã™ã¹ãã‹ã€‚ï¼‰"
            }}
          ]
        }}
        """

    # === â˜…v12.0: ä¿®æ­£ç‚¹ 1 (æ±ç”¨ææ¡ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æŒ‡ç¤º) ===
    def get_initial_generation_prompt(self, problem_statement: str, num_solutions: int, context: Dict[str, str]) -> str:
        """
        (â˜…v12.0: æ±ç”¨ææ¡ˆãƒ¢ãƒ‡ãƒ«ç‰ˆâ˜…)
        ã€Œè§£æ±ºç­–ã€ã«ã‚‚ã€Œå‰µä½œç‰©ã€ã«ã‚‚å¯¾å¿œã§ãã‚‹æ±ç”¨çš„ãª
        `proposal_title`, `proposal_content`, `proposal_rationale`
        ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚
        """
        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯ä¸€æµã®ã‚¤ãƒãƒ™ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', f'ä»¥ä¸‹ã®èª²é¡Œã«å¯¾ã—ã€äº’ã„ã«å…¨ãç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‹ã‚‰ã®ææ¡ˆã‚’{num_solutions}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚')}
        # èª²é¡Œæ–‡: {problem_statement}

        # !!æœ€é‡è¦!! (å‡ºåŠ›å½¢å¼)
        å„ææ¡ˆã«ã€Œproposal_titleã€ã€Œproposal_contentã€ã€Œproposal_rationaleã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

        # å‡ºåŠ›é …ç›®ã®å®šç¾©
        * **proposal_title**: ææ¡ˆã®ç°¡æ½”ãªåç§° (ä¾‹: ã€ŒAIè«‹æ±‚æ›¸ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã€, ã€Œæ˜¥é¢¨ã®ä¿³å¥ã€, ã€Œæ–°å•†å“ã®ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼Aã€)
        * **proposal_content**: ææ¡ˆã®ã€Œæ ¸ã€ã¨ãªã‚‹å†…å®¹ã€‚
            * (è§£æ±ºç­–ã®å ´åˆ): ææ¡ˆã®æ¦‚è¦ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
            * (å‰µä½œç‰©ã®å ´åˆ): ä¿³å¥ã€ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã€åå‰ãªã©ã®ã€Œå‰µä½œç‰©ãã®ã‚‚ã®ã€ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
        * **proposal_rationale**: ææ¡ˆã®ã€Œç†ç”±ã€ã‚„ã€Œæ–¹æ³•ã€ã€‚
            * (è§£æ±ºç­–ã®å ´åˆ): ã€Œå…·ä½“çš„ãªæ–¹æ³•ã€ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãã®ç†ç”±ã‚’2ã€œ4è¡Œã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
            * (å‰µä½œç‰©ã®å ´åˆ): ã€Œãã®å‰µä½œç‰©ã®ç‹™ã„ã‚„åŠ¹æœã€èƒŒæ™¯ã€ç†ç”±ã€ã‚’2ã€œ4è¡Œã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        * **é‡è¦**: ã€Œproposal_rationaleã€ã«ã¯ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚ãŸã ã—ã€**æ–‡ç« å†…ã§ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã¯ä½¿ç”¨ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚**

        # å‡ºåŠ›JSONã®ä¾‹
        {{ 
          "solutions": [ 
            {{ 
              "proposal_title": "ææ¡ˆ1ã®åç§°", 
              "proposal_content": "ææ¡ˆ1ã®æ ¸ã¨ãªã‚‹å†…å®¹ (æ¦‚è¦ã‚„å‰µä½œç‰©ãã®ã‚‚ã®)", 
              "proposal_rationale": "ææ¡ˆ1ã®å…·ä½“çš„ãªæ–¹æ³•ã€ã¾ãŸã¯ç‹™ã„ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹2ã€œ4è¡Œã®æ–‡ç« ã§ã™ã€‚\nã“ã®ã‚ˆã†ã«æ”¹è¡Œã‚’å«ã‚ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
            }}
          ] 
        }}
        """

    # === â˜…v12.0: ä¿®æ­£ç‚¹ 2 (æ±ç”¨ææ¡ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®è©•ä¾¡) ===
    def get_evaluation_prompt(self, solution: Dict[str, str], problem_statement: str, context: Dict[str, Any]) -> str:
        """
        (â˜…v12.0: æ±ç”¨ææ¡ˆãƒ¢ãƒ‡ãƒ«ç‰ˆâ˜…)
        AIãŒç”Ÿæˆã—ãŸã€Œå½¹å‰²ã€ã¨ã€Œè©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€ã«åŸºã¥ãã€
        æ–°ã—ã„æ±ç”¨ææ¡ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è©•ä¾¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
        """
        
        evaluator_role = context.get('role', 'ã‚ãªãŸã¯å®¢è¦³çš„ã§å³ã—ã„æ‰¹è©•å®¶ã§ã™ã€‚')
        evaluation_guideline = context.get('evaluation_guideline', 'æç¤ºã•ã‚ŒãŸææ¡ˆã‚’ã€èª²é¡Œã®è¦ä»¶ã«åŸºã¥ãå³å¯†ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚')

        return f"""
        # ã‚ãªãŸã®å³æ ¼ãªå½¹å‰²
        ã‚ãªãŸã¯ã€Œ{evaluator_role}ã€ã§ã™ã€‚

        # ã‚ãªãŸã®æœ€é‡è¦è©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
        {evaluation_guideline}

        # è©•ä¾¡å¯¾è±¡ã®èª²é¡Œ
        {problem_statement}
        
        # è©•ä¾¡å¯¾è±¡ã®ææ¡ˆ (â˜…v12.0 ä¿®æ­£ç®‡æ‰€)
        - åç§°/ã‚¿ã‚¤ãƒˆãƒ«: {solution.get('proposal_title', 'åç§°ä¸æ˜')}
        - ææ¡ˆå†…å®¹ (æ¦‚è¦/å‰µä½œç‰©): {solution.get('proposal_content', 'å†…å®¹ãªã—')}
        - å…·ä½“çš„ãªæ–¹æ³•/ç†ç”±: {solution.get('proposal_rationale', 'å…·ä½“çš„ãªæ–¹æ³•/ç†ç”±ãªã—')}
        
        # ã‚¿ã‚¹ã‚¯
        ã‚ãªãŸã®ã€Œå½¹å‰²ã€ã¨ã€Œæœ€é‡è¦è©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€ã«å³å¯†ã«å¾“ã„ã€ä¸Šè¨˜ã®ã€Œææ¡ˆã€ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«ç…§ã‚‰ã—ã¦ã€ã“ã®ææ¡ˆãŒèª²é¡Œã‚’ã©ã‚Œã ã‘åŠ¹æœçš„ã«è§£æ±º/é”æˆã§ãã‚‹ã‹ã€ã¾ãŸã¯åŠ£ã£ã¦ã„ã‚‹ã‹ã‚’å…·ä½“çš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚

        # å‡ºåŠ›å½¢å¼ (JSON)
        ä»¥ä¸‹ã®å½¢å¼ã§ã€è©•ä¾¡çµæœã‚’JSONã§å³å¯†ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        - **total_score**: ã‚ãªãŸã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«åŸºã¥ã„ãŸç·åˆè©•ä¾¡ç‚¹ (0ã€œ100ç‚¹ã®æ•´æ•°)ã€‚
        - **strengths**: ã‚ãªãŸã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®è¦³ç‚¹ã§ã€ç‰¹ã«å„ªã‚Œã¦ã„ã‚‹ç‚¹ã€‚ï¼ˆç°¡æ½”ã«ï¼‰
        - **weaknesses**: ã‚ãªãŸã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®è¦³ç‚¹ã§ã€æ‡¸å¿µãƒ»æ”¹å–„ãŒå¿…è¦ãªç‚¹ã€‚ï¼ˆç°¡æ½”ã«ï¼‰
        - **overall_comment**: è©•ä¾¡ã®ç·æ‹¬ã€‚ï¼ˆç°¡æ½”ã«ï¼‰

        {{
          "total_score": (0-100ã®æ•´æ•°),
          "strengths": "ï¼ˆ{evaluator_role}ã®è¦³ç‚¹ã§å„ªã‚Œã¦ã„ã‚‹ç‚¹ï¼‰",
          "weaknesses": "ï¼ˆ{evaluator_role}ã®è¦³ç‚¹ã§æ‡¸å¿µãƒ»æ”¹å–„ãŒå¿…è¦ãªç‚¹ï¼‰",
          "overall_comment": "ï¼ˆ{evaluator_role}ã®è¦³ç‚¹ã§ã®ç·æ‹¬ï¼‰"
        }}
        """

    # === â˜…v12.0: ä¿®æ­£ç‚¹ 3 (æ±ç”¨ææ¡ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®é€²åŒ–) ===
    def get_next_generation_prompt(self, elite_solutions: List[Dict], failed_solutions: List[Dict], problem_statement: str, num_solutions: int, context: Dict[str, str]) -> str:
        """
        (â˜…v12.0: æ±ç”¨ææ¡ˆãƒ¢ãƒ‡ãƒ«ç‰ˆâ˜…)
        æ—¢å­˜ã®è§£ã‚’ã€Œé€²åŒ–ã€ã•ã›ã€æ–°ã—ã„æ±ç”¨ææ¡ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã™ã‚‹ã€‚
        """
        # â˜…v12.0 ä¿®æ­£: 'name' -> 'proposal_title'
        elite_text = "\n".join([f"- {s['solution'].get('proposal_title', 'N/A')} (ã‚¹ã‚³ã‚¢: {s['evaluation'].get('total_score', 0)})" for s in elite_solutions])
        failed_text = "\n".join([f"- {s['solution'].get('proposal_title', 'N/A')} (å¼±ç‚¹: {s['evaluation'].get('weaknesses', 'N/A')})" for s in failed_solutions])

        return f"""
        # å½¹å‰²: {context.get('role', 'ã‚ãªãŸã¯å„ªã‚ŒãŸæˆ¦ç•¥å®¶ã§ã‚ã‚Šç·¨é›†è€…ã§ã™ã€‚')}
        # æŒ‡ç¤º: {context.get('instructions', 'é«˜è©•ä¾¡æ¡ˆã®è‰¯ã„ç‚¹ã‚’çµ„ã¿åˆã‚ã›ã€ä½è©•ä¾¡æ¡ˆã®å¤±æ•—ã‹ã‚‰å­¦ã³ã€æ–°ã—ã„ææ¡ˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚')}
        # ã‚¿ã‚¹ã‚¯: å‰ä¸–ä»£ã®åˆ†æã«åŸºã¥ãã€æ¬¡ä¸–ä»£ã®æ–°ã—ã„ææ¡ˆã‚’{num_solutions}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        # åˆ†æå¯¾è±¡1ï¼šé«˜è©•ä¾¡ã ã£ãŸææ¡ˆï¼ˆå„ªã‚ŒãŸéºä¼å­ï¼‰: 
        {elite_text}
        # åˆ†æå¯¾è±¡2ï¼šä½è©•ä¾¡ã ã£ãŸææ¡ˆï¼ˆå­¦ã¶ã¹ãæ•™è¨“ï¼‰: 
        {failed_text}
        # æ–°ã—ã„ææ¡ˆã®ç”ŸæˆæŒ‡ç¤º: {context.get('instructions')}
        
        # !!æœ€é‡è¦!! (å‡ºåŠ›å½¢å¼)
        å„ææ¡ˆã«ã€Œproposal_titleã€ã€Œproposal_contentã€ã€Œproposal_rationaleã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

        # å‡ºåŠ›é …ç›®ã®å®šç¾©
        * **proposal_title**: ææ¡ˆã®ç°¡æ½”ãªåç§° (ä¾‹: ã€ŒAIè«‹æ±‚æ›¸ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã€, ã€Œæ˜¥é¢¨ã®ä¿³å¥ã€, ã€Œæ–°å•†å“ã®ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼Aã€)
        * **proposal_content**: ææ¡ˆã®ã€Œæ ¸ã€ã¨ãªã‚‹å†…å®¹ã€‚
            * (è§£æ±ºç­–ã®å ´åˆ): ææ¡ˆã®æ¦‚è¦ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
            * (å‰µä½œç‰©ã®å ´åˆ): ä¿³å¥ã€ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã€åå‰ãªã©ã®ã€Œå‰µä½œç‰©ãã®ã‚‚ã®ã€ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
        * **proposal_rationale**: ææ¡ˆã®ã€Œç†ç”±ã€ã‚„ã€Œæ–¹æ³•ã€ã€‚
            * (è§£æ±ºç­–ã®å ´åˆ): ã€Œå…·ä½“çš„ãªæ–¹æ³•ã€ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãã®ç†ç”±ã‚’2ã€œ4è¡Œã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
            * (å‰µä½œç‰©ã®å ´åˆ): ã€Œãã®å‰µä½œç‰©ã®ç‹™ã„ã‚„åŠ¹æœã€èƒŒæ™¯ã€ç†ç”±ã€ã‚’2ã€œ4è¡Œã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        * **é‡è¦**: ã€Œproposal_rationaleã€ã«ã¯ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚ãŸã ã—ã€**æ–‡ç« å†…ã§ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã¯ä½¿ç”¨ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚**

        # å‡ºåŠ›JSONã®ä¾‹
        {{ 
          "solutions": [ 
            {{ 
              "proposal_title": "æ–°ã—ã„ææ¡ˆ1ã®åç§°", 
              "proposal_content": "æ–°ã—ã„ææ¡ˆ1ã®æ ¸ã¨ãªã‚‹å†…å®¹ (æ¦‚è¦ã‚„å‰µä½œç‰©ãã®ã‚‚ã®)", 
              "proposal_rationale": "æ–°ã—ã„ææ¡ˆ1ã®å…·ä½“çš„ãªæ–¹æ³•ã€ã¾ãŸã¯ç‹™ã„ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹2ã€œ4è¡Œã®æ–‡ç« ã§ã™ã€‚\nã“ã®ã‚ˆã†ã«æ”¹è¡Œã‚’å«ã‚ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
            }}
          ] 
        }}
        """

    # === â˜…v12.0: ä¿®æ­£ç‚¹ 4 (æ±ç”¨ææ¡ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®é©æ–°) ===
    def get_revolutionary_generation_prompt(self, problem_statement: str, num_solutions: int, existing_roles: List[str]) -> str:
        """
        (â˜…v12.0: æ±ç”¨ææ¡ˆãƒ¢ãƒ‡ãƒ«ç‰ˆâ˜…)
        å…¨ãæ–°ã—ã„ã€Œé©æ–°çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã‚’å®šç¾©ã•ã›ã€
        æ–°ã—ã„æ±ç”¨ææ¡ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã•ã›ã‚‹ã€‚
        """
        
        existing_roles_list = "\n".join([f"- {role}" for role in existing_roles]) if existing_roles else "ãªã—"

        return f"""
        # å½¹å‰²: 
        ã‚ãªãŸã¯ã€Œå¸¸è­˜å¤–ã‚Œã®ã‚¤ãƒãƒ™ãƒ¼ã‚¿ãƒ¼ã€ã‚’ä»»å‘½ã™ã‚‹ãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚
        ã‚ãªãŸã¯ã€Œçªç„¶å¤‰ç•°ã€ã‚’å¼•ãèµ·ã“ã™ãŸã‚ã€æ—¢å­˜ã®ææ¡ˆã‚„éå»ã®è©•ä¾¡ï¼ˆã‚¨ãƒªãƒ¼ãƒˆè§£ã€å¤±æ•—è§£ï¼‰ã¯**å®Œå…¨ã«ç„¡è¦–**ã—ã¾ã™ã€‚

        # ã‚¿ã‚¹ã‚¯:
        ä»¥ä¸‹ã®ã€Œèª²é¡Œã€ã«å¯¾ã—ã€æ—¢å­˜ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã¯**å…¨ãç•°ãªã‚‹æ–°ã—ã„è¦³ç‚¹**ã‚’æŒã¤
        ã€Œé©æ–°çš„ãªå°‚é–€å®¶ã€ã‚’{num_solutions}äººï¼ˆã¾ãŸã¯{num_solutions}å€‹ï¼‰å®šç¾©ã—ã€
        ãã®å°‚é–€å®¶ã®è¦–ç‚¹ã‹ã‚‰ã€é©æ–°çš„ãªææ¡ˆã‚’{num_solutions}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

        # èª²é¡Œæ–‡: 
        {problem_statement}

        # æ—¢å­˜ã®å°‚é–€å®¶ãƒ­ãƒ¼ãƒ« (ã“ã‚Œã‚‰ã¨ã¯ç•°ãªã‚‹è¦–ç‚¹ã«ã™ã‚‹ã“ã¨):
        {existing_roles_list}

        # !!é‡è¦!! 
        - ã‚¹ãƒ†ãƒƒãƒ—1ï¼ˆå†…éƒ¨æ€è€ƒï¼‰: æ—¢å­˜ãƒ­ãƒ¼ãƒ«ãŒã‚«ãƒãƒ¼ã—ã¦ã„ãªã„ã€å…¨ãæ–°ã—ã„ã€Œå½¹å‰²ï¼ˆãƒ­ãƒ¼ãƒ«ï¼‰ã€ã‚’è€ƒæ¡ˆã™ã‚‹ã€‚
        - ã‚¹ãƒ†ãƒƒãƒ—2ï¼ˆå†…éƒ¨æ€è€ƒï¼‰: ãã®å½¹å‰²ã«åŸºã¥ãã€é©æ–°çš„ãªææ¡ˆï¼ˆproposal_title, proposal_content, proposal_rationaleï¼‰ã‚’è€ƒæ¡ˆã™ã‚‹ã€‚
        - ã‚¹ãƒ†ãƒƒãƒ—3ï¼ˆå‡ºåŠ›ï¼‰: è€ƒæ¡ˆã—ãŸææ¡ˆã‚’ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã€‚

        # !!æœ€é‡è¦!! (å‡ºåŠ›å½¢å¼)
        å„ææ¡ˆã«ã€Œproposal_titleã€ã€Œproposal_contentã€ã€Œproposal_rationaleã€ã‚’å¿…ãšå«ã‚ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        ã€Œproposal_titleã€ã«ã¯ã€è€ƒæ¡ˆã—ãŸæ–°ã—ã„å°‚é–€å®¶ã®å½¹å‰²ã‚„ã€ãã®é©æ–°æ€§ãŒä¼ã‚ã‚‹ã‚ˆã†ãªåç§°ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚

        # å‡ºåŠ›é …ç›®ã®å®šç¾©
        * **proposal_title**: ææ¡ˆã®ç°¡æ½”ãªåç§° (ä¾‹: ã€ŒAIè«‹æ±‚æ›¸ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã€, ã€Œæ˜¥é¢¨ã®ä¿³å¥ã€, ã€Œæ–°å•†å“ã®ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼Aã€)
        * **proposal_content**: ææ¡ˆã®ã€Œæ ¸ã€ã¨ãªã‚‹å†…å®¹ã€‚
            * (è§£æ±ºç­–ã®å ´åˆ): ææ¡ˆã®æ¦‚è¦ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
            * (å‰µä½œç‰©ã®å ´åˆ): ä¿³å¥ã€ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã€åå‰ãªã©ã®ã€Œå‰µä½œç‰©ãã®ã‚‚ã®ã€ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
        * **proposal_rationale**: ææ¡ˆã®ã€Œç†ç”±ã€ã‚„ã€Œæ–¹æ³•ã€ã€‚
            * (è§£æ±ºç­–ã®å ´åˆ): ã€Œå…·ä½“çš„ãªæ–¹æ³•ã€ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãã®ç†ç”±ã‚’2ã€œ4è¡Œã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
            * (å‰µä½œç‰©ã®å ´åˆ): ã€Œãã®å‰µä½œç‰©ã®ç‹™ã„ã‚„åŠ¹æœã€èƒŒæ™¯ã€ç†ç”±ã€ã‚’2ã€œ4è¡Œã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        * **é‡è¦**: ã€Œproposal_rationaleã€ã«ã¯ç®‡æ¡æ›¸ãã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚ãŸã ã—ã€**æ–‡ç« å†…ã§ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰(\n)ã¯ä½¿ç”¨ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚**

        # å‡ºåŠ›JSONã®ä¾‹
        {{ 
          "solutions": [ 
            {{ 
              "proposal_title": "ï¼ˆè€ƒæ¡ˆã—ãŸæ–°å°‚é–€å®¶ã®å½¹å‰²ã‚’åæ˜ ã—ãŸé©æ–°çš„ãªåç§°ï¼‰", 
              "proposal_content": "ï¼ˆãã®å°‚é–€å®¶ãŒç”Ÿæˆã—ãŸé©æ–°çš„ãªææ¡ˆã®æ ¸ã¨ãªã‚‹å†…å®¹ï¼‰", 
              "proposal_rationale": "ï¼ˆãã®ææ¡ˆã®å…·ä½“çš„ãªæ–¹æ³•ã€ã¾ãŸã¯ç‹™ã„ã‚„ç†ç”±ã‚’èª¬æ˜ã™ã‚‹2ã€œ4è¡Œã®æ–‡ç« ã§ã™ã€‚ï¼‰" 
            }}
          ] 
        }}
        """


# ----------------------------
# 4) EvoGenSolver (â˜…ä¿®æ­£ç®‡æ‰€â˜…)
# ----------------------------
class EvoGenSolver:
    """å…ƒã® EvoGenSolverï¼ˆä¸»è¦ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
    def __init__(self, llm_client: LLMClient, num_solutions_per_generation: int = 10):
        self.client = llm_client
        self.num_solutions = num_solutions_per_generation 
        self.prompter = PromptManager()
        self.history = []

    def _call_llm(self, prompt: str) -> Dict[str, Any]:
        return self.client.call(prompt) 

    def _generate_agent_personas(self, problem_statement: str) -> Dict:
        # (v11.0ã®ã¾ã¾)
        prompt = self.prompter.get_agent_personas_prompt(problem_statement)
        return self._call_llm(prompt)

    def _generate_initial_solutions(self, problem_statement: str, context: Dict) -> List[Dict[str, str]]:
        # (v9.0ã®ã¾ã¾)
        initial_agent_list = context 
        if not isinstance(initial_agent_list, list) or len(initial_agent_list) == 0:
            st.warning(f"[EvoGenSolver] è§£æ±ºãƒ»é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒä¸æ­£ã§ã™ã€‚")
            return []
        
        num_initial_agents = len(initial_agent_list)
        st.info(f"ğŸ’¡ {num_initial_agents}ä½“ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆæœŸè§£ï¼ˆ10å€‹ï¼‰ã‚’åˆ†æ‹…ã—ã¦ç”Ÿæˆä¸­...")
        
        all_solutions = []
        for i, agent_context in enumerate(initial_agent_list):
            st.caption(f"  - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}/{num_initial_agents} ({agent_context.get('role', 'N/A')}) ãŒç”Ÿæˆä¸­...")
            
            # (v12.0 ã®æ±ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå‘¼ã°ã‚Œã‚‹)
            prompt = self.prompter.get_initial_generation_prompt(problem_statement, 1, agent_context)
            response = self._call_llm(prompt) 
            
            if isinstance(response, dict) and "solutions" in response and isinstance(response["solutions"], list) and len(response["solutions"]) > 0:
                all_solutions.append(response["solutions"][0])
            else:
                st.warning(f"[EvoGenSolver] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1} ãŒä¸æ­£ãªå½¢å¼ã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {response}")
                
        return all_solutions

    # === â˜…v12.0: ä¿®æ­£ç‚¹ 5 (ãƒ­ã‚°å‡ºåŠ›ç­‰ã‚’ 'proposal_title' ã«å¤‰æ›´) ===
    def _evaluate_solutions(self, solutions: List[Dict[str, str]], problem_statement: str, context: Dict) -> Generator[str | List[Dict], None, None]:
        
        evaluator_agent_list = context
        if not isinstance(evaluator_agent_list, list) or len(evaluator_agent_list) == 0:
            st.error("[EvoGenSolver] è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒä¸æ­£ã§ã™ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
            yield []
            return

        evaluated_solutions = []
        if not solutions:
            yield []
            return

        num_evaluators = len(evaluator_agent_list)

        for i, solution in enumerate(solutions):
            # â˜…v12.0 ä¿®æ­£: 'name' -> 'proposal_title'
            if not isinstance(solution, dict) or "proposal_title" not in solution:
                yield f"  - è©•ä¾¡ã‚¹ã‚­ãƒƒãƒ—: ä¸æ­£ãªå½¢å¼ã®ææ¡ˆãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚"
                continue
            
            # â˜…v12.0 ä¿®æ­£: 'name' -> 'proposal_title'
            yield f"  - è©•ä¾¡ä¸­ {i+1}/{len(solutions)}: {solution.get('proposal_title', 'åç§°ä¸æ˜')} ( {num_evaluators}ä½“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹è©•ä¾¡)"

            individual_evaluations = []
            
            for j, eval_context in enumerate(evaluator_agent_list):
                yield f"    - è©•ä¾¡è€… {j+1}/{num_evaluators} ({eval_context.get('role', 'N/A')}) ãŒè©•ä¾¡..."
                
                # (v12.0 ã®æ±ç”¨è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå‘¼ã°ã‚Œã‚‹)
                prompt = self.prompter.get_evaluation_prompt(solution, problem_statement, eval_context)
                evaluation = self._call_llm(prompt)
                
                if isinstance(evaluation, dict) and "total_score" in evaluation and "error" not in evaluation:
                    individual_evaluations.append(evaluation)
                else:
                    # â˜…v12.0 ä¿®æ­£: 'name' -> 'proposal_title'
                    st.warning(f"[EvoGenSolver] ææ¡ˆ '{solution.get('proposal_title', 'N/A')}' ã®è©•ä¾¡è€… {j+1} ãŒä¸æ­£ãªå½¢å¼ã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {evaluation}")

            if not individual_evaluations:
                # â˜…v12.0 ä¿®æ­£: 'name' -> 'proposal_title'
                st.warning(f"[EvoGenSolver] ææ¡ˆ '{solution.get('proposal_title', 'N/A')}' ã®æœ‰åŠ¹ãªè©•ä¾¡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                continue

            # (v11.0ã®ã¾ã¾ã®é›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯ã§OK)
            total_score_sum = sum(e.get('total_score', 0) for e in individual_evaluations)
            aggregated_score = round(total_score_sum / len(individual_evaluations))
            
            agg_strengths = "\n---\n".join([f"è©•ä¾¡è€…{k+1} ({e.get('role', 'N/A')}):\n{e.get('strengths', 'N/A')}" for k, e in enumerate(individual_evaluations)])
            agg_weaknesses = "\n---\n".join([f"è©•ä¾¡è€…{k+1} ({e.get('role', 'N/A')}):\n{e.get('weaknesses', 'N/A')}" for k, e in enumerate(individual_evaluations)])
            agg_comment = "\n---\n".join([f"è©•ä¾¡è€…{k+1} ({e.get('role', 'N/A')}):\n{e.get('overall_comment', 'N/A')}" for k, e in enumerate(individual_evaluations)])

            aggregated_evaluation = {
                "total_score": aggregated_score,
                "strengths": agg_strengths,
                "weaknesses": agg_weaknesses,
                "overall_comment": agg_comment,
                "individual_evals": individual_evaluations 
            }
            
            evaluated_solutions.append({"solution": solution, "evaluation": aggregated_evaluation})
            yield f"    - ç·åˆè©•ä¾¡ã‚¹ã‚³ã‚¢: {aggregated_score}"


        evaluated_solutions.sort(key=lambda x: x.get("evaluation", {}).get("total_score", 0), reverse=True)
        yield evaluated_solutions

    def _generate_next_generation(self, evaluated_solutions: List[Dict], problem_statement: str, context: Dict) -> List[Dict[str, str]]:
        # (v9.0ã®ã¾ã¾)
        solver_agent_list = context 
        if not isinstance(solver_agent_list, list) or len(solver_agent_list) == 0:
            st.warning(f"[EvoGenSolver] è§£æ±ºãƒ»é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒä¸æ­£ã§ã™ã€‚")
            return []

        num_elites = max(1, int(len(evaluated_solutions) * 0.4))
        elite_solutions = evaluated_solutions[:num_elites]
        failed_solutions = evaluated_solutions[num_elites:]

        st.info(f"ğŸš€ {self.num_solutions} ä½“ã®è§£æ±ºãƒ»é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸å‡ºã—ã¦æ¬¡ä¸–ä»£ã‚’ç”Ÿæˆ...")

        new_solutions = []
        for i in range(self.num_solutions):
            
            if random.random() < 0.20:
                # 20%ã®ç¢ºç‡: é©æ–° (v12.0 ã®æ±ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå‘¼ã°ã‚Œã‚‹)
                st.caption(f"  - âš¡ (çªç„¶å¤‰ç•°) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}/{self.num_solutions} ãŒã€Œæ–°è¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®šç¾©ã€ã¨ã€Œé©æ–°çš„ãªææ¡ˆã€ã‚’å®Ÿè¡Œ...")
                
                existing_roles = [a.get('role', 'N/A') for a in solver_agent_list]
                
                prompt = self.prompter.get_revolutionary_generation_prompt(
                    problem_statement, 
                    1, 
                    existing_roles 
                )
            else:
                # 80%ã®ç¢ºç‡: é€²åŒ– (v12.0 ã®æ±ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå‘¼ã°ã‚Œã‚‹)
                selected_agent_context = random.choice(solver_agent_list) 
                st.caption(f"  - ğŸ§¬ (é€²åŒ–) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1}/{self.num_solutions} ({selected_agent_context.get('role', 'N/A')}) ãŒã€Œæ—¢å­˜ã®ææ¡ˆã€ã‚’é€²åŒ–...")
                
                prompt = self.prompter.get_next_generation_prompt(
                    elite_solutions, 
                    failed_solutions, 
                    problem_statement, 
                    1, 
                    selected_agent_context
                )
            
            response = self._call_llm(prompt) 
            
            if isinstance(response, dict) and "solutions" in response and isinstance(response["solutions"], list) and len(response["solutions"]) > 0:
                new_solutions.append(response["solutions"][0])
            else:
                st.warning(f"[EvoGenSolver] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ {i+1} ãŒä¸æ­£ãªå½¢å¼ã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {response}")

        return new_solutions

    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        # (v9.0ã®ã¾ã¾)
        self.history = []

        yield "--- ğŸ§  èª²é¡Œã‚’åˆ†æã—ã€æœ€é©ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ã‚’ç·¨æˆä¸­... ---"
        agent_personas = self._generate_agent_personas(problem_statement) 

        if not agent_personas or "error" in agent_personas or not all(k in agent_personas for k in ["solver_agents", "evaluators"]):
            yield "ã‚¨ãƒ©ãƒ¼: ãƒãƒ¼ãƒ ç·¨æˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚"
            yield f"**ãƒ‡ãƒãƒƒã‚°æƒ…å ±:** AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™ã€‚APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n```\n{agent_personas}\n```"
            return

        yield f"--- âœ”ï¸ ãƒãƒ¼ãƒ ç·¨æˆå®Œäº† ---"
        yield {"agent_team": agent_personas}

        yield "\n--- ğŸ’¡ Generation 0: æœ€åˆã®ææ¡ˆ (10å€‹) ã‚’ç”Ÿæˆä¸­... ---"
        solutions = self._generate_initial_solutions(problem_statement, agent_personas["solver_agents"])
        
        if not solutions:
             yield "ã‚¨ãƒ©ãƒ¼: æœ€åˆã®ææ¡ˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIãŒé©åˆ‡ãªå¿œç­”ã‚’è¿”ã•ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
             return

        yield "--- ğŸ§ ææ¡ˆã‚’è©•ä¾¡ä¸­ (3ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ x 10ææ¡ˆ)... ---"
        eval_generator = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluators"])
        evaluated_solutions = []
        for item in eval_generator:
            if isinstance(item, str):
                yield item
            else:
                evaluated_solutions = item
        
        if not evaluated_solutions:
             yield "ã‚¨ãƒ©ãƒ¼: ææ¡ˆã®è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
             return

        self.history.append({"generation": 0, "results": evaluated_solutions})
        yield self.history[-1]

        for i in range(1, generations):
            yield f"\n--- ğŸš€ Generation {i}: æ¬¡ã®ææ¡ˆã¸é€²åŒ–ä¸­... ---"
            previous_generation_results = self.history[-1]["results"]
            
            if not previous_generation_results:
                yield f"ã‚¨ãƒ©ãƒ¼: å‰ä¸–ä»£ ({i-1}) ã®æœ‰åŠ¹ãªè©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚é€²åŒ–ã‚’åœæ­¢ã—ã¾ã™ã€‚"
                break
            
            solutions = self._generate_next_generation(previous_generation_results, problem_statement, agent_personas["solver_agents"]) 

            if not solutions:
                yield f"ã‚¨ãƒ©ãƒ¼: Generation {i} ã®ææ¡ˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIãŒé©åˆ‡ãªå¿œç­”ã‚’è¿”ã•ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
                break

            yield f"--- ğŸ§ Generation {i} ã®ææ¡ˆã‚’è©•ä¾¡ä¸­... ---"
            eval_generator_next = self._evaluate_solutions(solutions, problem_statement, agent_personas["evaluators"])
            evaluated_solutions_next = []
            for item in eval_generator_next:
                if isinstance(item, str):
                    yield item
                else:
                    evaluated_solutions_next = item

            if not evaluated_solutions_next:
                 yield f"ã‚¨ãƒ©ãƒ¼: Generation {i} ã®è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚"
                 break

            self.history.append({"generation": i, "results": evaluated_solutions_next})
            yield self.history[-1]

        yield "\n--- âœ… é€²åŒ–ãƒ—ãƒ­ã‚»ã‚¹å®Œäº† ---"


# ----------------------------
# 5) EvoGenSolver_Tavily (å¤‰æ›´ãªã—)
# ----------------------------
class EvoGenSolver_Tavily(EvoGenSolver):
    """
    Tavily ã‚’ç”¨ã„ã¦èª²é¡Œã«é–¢é€£ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’åé›†ã—ã€ãã®æƒ…å ±ã‚’
    å•é¡Œæ–‡ã«çµ„ã¿è¾¼ã‚“ã§ EvoGen ã®ãƒ•ãƒ­ãƒ¼ã‚’å›ã™æ‹¡å¼µç‰ˆã€‚
    """
    def __init__(self, llm_client: LLMClient, tavily_client: TavilyClient, num_solutions_per_generation: int = 10, tavily_results_per_search: int = 5):
        super().__init__(llm_client, num_solutions_per_generation)
        self.tavily = tavily_client
        self.tavily_results_per_query = tavily_results_per_search 

    def _get_snippet_text(self, results: List[Dict[str, Any]], max_snippets: int = 5) -> str:
        # (v9.0ã®ã¾ã¾)
        snippet_texts = []
        for r in results[:min(len(results), max_snippets)]:
            title = r.get("title", "")
            snippet = r.get("snippet", "") or r.get("description", "")
            url = r.get("url", "")
            snippet_texts.append(f"Title: {title}\nSnippet: {snippet}\nURL: {url}\n---")
        return "\n".join(snippet_texts)

    def _summarize_multi_phase_results_with_llm(
        self, 
        problem_statement: str, 
        analysis_results: List[Dict[str, Any]], 
        solution_results: List[Dict[str, Any]]
    ) -> str:
        # (v9.0ã®ã¾ã¾)
        if not analysis_results and not solution_results:
            return problem_statement

        analysis_snippets = self._get_snippet_text(analysis_results, max_snippets=5)
        solution_snippets = self._get_snippet_text(solution_results, max_snippets=5) 

        prompt = f"""
        ã‚ãªãŸã¯ã€2æ®µéšã®ã‚¦ã‚§ãƒ–èª¿æŸ»çµæœã‚’åˆ†æã—ã€å…ƒã®èª²é¡Œæ–‡ã«çµ±åˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
        
        # å…ƒã®èª²é¡Œ
        {problem_statement}

        # èª¿æŸ»çµæœ 1: ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ (å›ºæœ‰åè©ã‚„ç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿)
        {analysis_snippets if analysis_snippets else "ãªã—"}

        # èª¿æŸ»çµæœ 2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒ»æŠ€è¡“ (ä»–äº‹ä¾‹ã‚„æŠ€è¡“å‹•å‘)
        {solution_snippets if solution_snippets else "ãªã—"}

        # ã‚¿ã‚¹ã‚¯
        ä¸Šè¨˜ã®2ã¤ã®èª¿æŸ»çµæœã‚’åˆ†æã—ã€å…ƒã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ä¸Šã§ç‰¹ã«é‡è¦ã¨ãªã‚‹æƒ…å ±ã‚’æŠ½å‡ºãƒ»è¦ç´„ã—ã¦ãã ã•ã„ã€‚
        
        # å‡ºåŠ›å½¢å¼ (JSON)
        {{
          "summary_analysis": "ã€Œèª¿æŸ»çµæœ1ï¼ˆç¾çŠ¶ãƒ»èƒŒæ™¯ï¼‰ã€ã®ç°¡æ½”ãªè¦ç´„ï¼ˆ1ã€œ2æ–‡ï¼‰",
          "summary_solution": "ã€Œèª¿æŸ»çµæœ2ï¼ˆè§£æ±ºç­–ãƒ»äº‹ä¾‹ï¼‰ã€ã®ç°¡æ½”ãªè¦ç´„ï¼ˆ1ã€œ2æ–‡ï¼‰",
          "key_points": [
            "èª¿æŸ»çµæœå…¨ä½“ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸé‡è¦ãªäº‹å®Ÿã‚„åˆ¶ç´„1",
            "èª¿æŸ»çµæœå…¨ä½“ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸé‡è¦ãªäº‹å®Ÿã‚„åˆ¶ç´„2"
          ],
          "top_sources": [
            {{"title":"æœ€ã‚‚é‡è¦ãªå‡ºå…¸ã®ã‚¿ã‚¤ãƒˆãƒ«1", "url":"..."}},
            {{"title":"æœ€ã‚‚é‡è¦ãªå‡ºå…¸ã®ã‚¿ã‚¤ãƒˆãƒ«2", "url":"..."}}
          ]
        }}
        """
        
        llm_ret = self._call_llm(prompt) 
        
        if isinstance(llm_ret, dict) and any(k in llm_ret for k in ["summary_analysis", "summary_solution", "key_points"]):
            try:
                summary_analysis_text = llm_ret.get("summary_analysis", "ç¾çŠ¶åˆ†æã®è¦ç´„ãªã—")
                summary_solution_text = llm_ret.get("summary_solution", "è§£æ±ºç­–äº‹ä¾‹ã®è¦ç´„ãªã—")
                kp = llm_ret.get("key_points", [])
                top = llm_ret.get("top_sources", [])
                top_text = "\n".join([f"- {s.get('title','')}: {s.get('url','')}" for s in top]) if isinstance(top, list) else ""
                
                composed = f"""
## Tavilyãƒªã‚µãƒ¼ãƒè¦ç´„ï¼ˆLLMç”Ÿæˆï¼‰
### ç¾çŠ¶ãƒ»èƒŒæ™¯åˆ†æ
{summary_analysis_text}
### è§£æ±ºç­–ãƒ»äº‹ä¾‹
{summary_solution_text}

### æŠ½å‡ºã•ã‚ŒãŸé‡è¦ç‚¹
""" + "\n".join([f"- {p}" for p in kp]) + "\n\n" + \
"### ä¸»ãªå‡ºå…¸\n" + top_text + "\n\n" + \
"--- (ä»¥ä¸‹ã€å…ƒã®èª²é¡Œæ–‡) ---\n" + problem_statement
                
                return composed
            except Exception:
                pass 

        fallback_sources = []
        for r in analysis_results[:2]:
            fallback_sources.append(f"- [åˆ†æ] {r.get('title','No title')} ({r.get('url','')})")
        for r in solution_results[:2]:
            fallback_sources.append(f"- [è§£æ±ºç­–] {r.get('title','No title')} ({r.get('url','')})")
            
        fallback = "## Tavilyãƒªã‚µãƒ¼ãƒè¦ç´„ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n" + \
                   "æœ€æ–°ã®ã‚¦ã‚§ãƒ–æƒ…å ±ã‚’å‚ç…§ã—ã¾ã—ãŸã€‚ä¸Šä½å‡ºå…¸:\n" + "\n".join(fallback_sources) + \
                   "\n\n" + "--- (ä»¥ä¸‹ã€å…ƒã®èª²é¡Œæ–‡) ---\n" + problem_statement
        return fallback

    def solve(self, problem_statement: str, generations: int = 3) -> Generator[str | Dict, None, None]:
        # (v10.1ã®ã¾ã¾)
        
        yield "--- ğŸ’¡ LLMã«ã‚ˆã‚‹æœ€é©ãªæ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆãƒ•ã‚§ãƒ¼ã‚º1 & 2ï¼‰ã‚’ç”Ÿæˆä¸­... ---"
        prompt = self.prompter.get_tavily_multi_phase_query_prompt(problem_statement)
        query_response = self._call_llm(prompt)

        if not isinstance(query_response, dict) or ("analysis_queries" not in query_response and "solution_queries" not in query_response):
            yield f"ã‚¨ãƒ©ãƒ¼: Tavilyã‚¯ã‚¨ãƒªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™: {query_response}"
            augmented_problem = problem_statement
        else:
            analysis_queries = query_response.get("analysis_queries", [])
            solution_queries = query_response.get("solution_queries", [])
            
            yield f"--- âœ”ï¸ ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒª ---"
            yield f"  - åˆ†æã‚¯ã‚¨ãƒª: {', '.join(analysis_queries) if analysis_queries else 'ãªã—'}"
            yield f"  - è§£æ±ºç­–ã‚¯ã‚¨ãƒª: {', '.join(solution_queries) if solution_queries else 'ãªã—'}"
            
            analysis_results_list = []
            solution_results_list = []
            
            if analysis_queries:
                yield "--- ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º1: èª²é¡Œã®ç¾çŠ¶åˆ†æãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹... ---"
                for q in analysis_queries:
                    if not q.strip(): continue
                    yield f"  - æ¤œç´¢ä¸­ (åˆ†æ): {q}"
                    tavily_resp = self.tavily.search(q, num_results=self.tavily_results_per_query)
                    if isinstance(tavily_resp, dict) and "results" in tavily_resp:
                        analysis_results_list.extend(tavily_resp["results"])
                    elif isinstance(tavily_resp, dict) and "error" in tavily_resp:
                         yield f"  - Tavily ã‚¨ãƒ©ãƒ¼ (åˆ†æã‚¯ã‚¨ãƒª: {q}): {tavily_resp['error']}"
            
            if solution_queries:
                yield "--- ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹... ---"
                for q in solution_queries:
                    if not q.strip(): continue
                    yield f"  - æ¤œç´¢ä¸­ (è§£æ±ºç­–): {q}"
                    tavily_resp = self.tavily.search(q, num_results=self.tavily_results_per_query)
                    if isinstance(tavily_resp, dict) and "results" in tavily_resp:
                        solution_results_list.extend(tavily_resp["results"])
                    elif isinstance(tavily_resp, dict) and "error" in tavily_resp:
                         yield f"  - Tavily ã‚¨ãƒ©ãƒ¼ (è§£æ±ºç­–ã‚¯ã‚¨ãƒª: {q}): {tavily_resp['error']}"

            yield {"tavily_info_analysis": analysis_results_list, "tavily_info_solution": solution_results_list}

            yield "--- âœï¸ 2ã¤ã®ãƒªã‚µãƒ¼ãƒçµæœã‚’è¦ç´„ã—ã€å•é¡Œæ–‡ã«çµ±åˆã—ã¾ã™... ---"
            try:
                augmented_problem = self._summarize_multi_phase_results_with_llm(
                    problem_statement, 
                    analysis_results_list, 
                    solution_results_list
                )
            except Exception as e:
                augmented_problem = problem_statement
                yield f"è­¦å‘Š: Tavily è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        
        # (v10.1ã®ã¾ã¾) æ‹¡å¼µã•ã‚ŒãŸå•é¡Œæ–‡ï¼ˆã¾ãŸã¯å…ƒã®å•é¡Œæ–‡ï¼‰ã‚’UIã«æ¸¡ã™
        yield {"augmented_problem": augmented_problem}

        # (v12.0) æ‹¡å¼µã•ã‚ŒãŸå•é¡Œæ–‡ã§ EvoGen ã®æ±ç”¨ææ¡ˆã‚¹ã‚¦ã‚©ãƒ¼ãƒ ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè¡Œ
        yield from super().solve(augmented_problem, generations)


# ----------------------------
# 6) Streamlit UI (â˜…v12.0: è¡¨ç¤ºå†…å®¹ã‚’æ±ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾å¿œâ˜…)
# ----------------------------
st.set_page_config(page_title="EvoGen AI + Tavily (Generalist Swarm)", layout="wide")
st.title("EvoGen AI ğŸ§¬")
st.markdown("é€²åŒ–å‹ç”ŸæˆAIè§£æ¢ç´¢ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ (v12.0: æ±ç”¨ææ¡ˆãƒ¢ãƒ‡ãƒ«)")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š (v10.1ã®ã¾ã¾) ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    gemini_key = st.text_input("Google Gemini API Key", type="password", help="Gemini ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    tavily_key = st.text_input("Tavily API Key", type="password", help="Tavily ã® API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚")
    st.subheader("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    num_generations = st.slider("ä¸–ä»£æ•°", 1, 20, 2, help="ææ¡ˆã‚’é€²åŒ–ã•ã›ã‚‹å›æ•°ã§ã™ã€‚")
    num_solutions = st.slider("ä¸–ä»£ã”ã¨ã®(æœ€å¤§)ææ¡ˆã®æ•°", 3, 10, 10, help="ç¬¬1ä¸–ä»£ä»¥é™ã«ç”Ÿæˆãƒ»è©•ä¾¡ã™ã‚‹ææ¡ˆã®æ•°ã§ã™ã€‚(ç¬¬0ä¸–ä»£ã¯å¸¸ã«10å€‹)")
    tavily_results_per_search = st.slider("Tavily æ¤œç´¢çµæœæ•° (ã‚¯ã‚¨ãƒªæ¯)", 1, 10, 4, help="1ã¤ã®ã‚¯ã‚¨ãƒªã‚ãŸã‚Šã«Tavily ã‹ã‚‰å–å¾—ã™ã‚‹æ¤œç´¢çµæœæ•°ã€‚") 
    st.markdown("---")
    st.info("Tavily ã‚’ä½¿ã£ã¦èª²é¡Œã«é–¢é€£ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’å–å¾—ã—ã€ãã‚Œã‚’å‚è€ƒã«ææ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

# (v10.1ã®ã¾ã¾)
default_problem = """
# èª²é¡Œ
ä¸­å°ä¼æ¥­ã®çµŒç†éƒ¨é–€ã«ãŠã‘ã‚‹ã€è«‹æ±‚æ›¸å‡¦ç†ã®æ¥­å‹™åŠ¹ç‡ã‚’åŠ‡çš„ã«æ”¹å–„ã™ã‚‹
æ–°ã—ã„AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã›ã‚ˆã€‚

# è¦ä»¶ãƒ»åˆ¶ç´„æ¡ä»¶
- å°å…¥ã‚³ã‚¹ãƒˆãŒä½ã„ã“ã¨ã€‚ï¼ˆæœˆé¡5ä¸‡å††ä»¥ä¸‹ï¼‰
- å°‚é–€çš„ãªITçŸ¥è­˜ãŒãªãã¦ã‚‚åˆ©ç”¨ã§ãã‚‹ã“ã¨ã€‚
- æ—¢å­˜ã®ä¼šè¨ˆã‚½ãƒ•ãƒˆï¼ˆä¾‹: freee, MFã‚¯ãƒ©ã‚¦ãƒ‰ï¼‰ã¨é€£æºã§ãã‚‹ã“ã¨ãŒæœ›ã¾ã—ã„ã€‚
"""
problem_statement = st.text_area("è§£æ±ºã—ãŸã„èª²é¡Œï¼ˆã¾ãŸã¯å‰µä½œã—ãŸã„ãŠé¡Œï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=default_problem, height=260)

# (v10.1ã®ã¾ã¾)
if st.button("ææ¡ˆã®ç”Ÿæˆã‚’é–‹å§‹", type="primary"):
    if not gemini_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Google Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not tavily_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Tavily APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not problem_statement.strip():
        st.warning("èª²é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status_placeholder = st.empty()
        team_placeholder = st.empty()
        augmented_problem_placeholder = st.container() 
        tavily_placeholder = st.container() 
        results_area = st.container()
        final_result_placeholder = st.container()

        with st.spinner("ğŸŒ€ AIãŒæ€è€ƒä¸­ã§ã™..."):
            try:
                gemini_client = GeminiClient(api_key=gemini_key)
                tavily_client = TavilyClient(api_key=tavily_key)
            except Exception as e:
                st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()

            solver = EvoGenSolver_Tavily(
                llm_client=gemini_client,
                tavily_client=tavily_client,
                num_solutions_per_generation=num_solutions,
                tavily_results_per_search=tavily_results_per_search
            )
            
            # (v10.1ã®ã¾ã¾)
            def display_tavily_results(results_list, title):
                with tavily_placeholder.container():
                    st.subheader(title)
                    if results_list:
                        for r in results_list:
                            title = r.get("title", "No title")
                            url = r.get("url", "")
                            snippet = r.get("snippet", "") or r.get("description", "")
                            st.markdown(f"- [{title}]({url})")
                            if snippet:
                                st.caption(snippet)
                    else:
                        st.write("ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.markdown("---")


            # --- Solverã‚’å®Ÿè¡Œã—ã€çµæœã‚’UIã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º ---
            for result in solver.solve(problem_statement, generations=num_generations):
                if isinstance(result, str):
                    status_placeholder.info(result) 

                # (v10.1ã®ã¾ã¾)
                elif isinstance(result, dict) and ("tavily_info_analysis" in result or "tavily_info_solution" in result):
                    tavily_placeholder.empty()
                    analysis_data = result.get("tavily_info_analysis", [])
                    solution_data = result.get("tavily_info_solution", [])
                    if analysis_data:
                        display_tavily_results(analysis_data, "ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º1: èª²é¡Œã®ç¾çŠ¶åˆ†æãƒªã‚µãƒ¼ãƒçµæœ")
                    if solution_data:
                        display_tavily_results(solution_data, "ğŸŒ ãƒ•ã‚§ãƒ¼ã‚º2: è§£æ±ºç­–ã®äº‹ä¾‹ãƒªã‚µãƒ¼ãƒçµæœ")
                
                # (v10.1ã®ã¾ã¾)
                elif isinstance(result, dict) and "augmented_problem" in result:
                    with augmented_problem_placeholder.container():
                        st.subheader("ğŸ” ãƒªã‚µãƒ¼ãƒçµæœã§è£œå¼·ã•ã‚ŒãŸèª²é¡Œæ–‡")
                        with st.expander("è£œå¼·ã•ã‚ŒãŸèª²é¡Œæ–‡ã®è©³ç´°ã‚’è¡¨ç¤º", expanded=False): 
                            st.markdown(result["augmented_problem"])
                        st.markdown("---")
                
                # (v11.0ã®ã¾ã¾)
                elif isinstance(result, dict) and "agent_team" in result:
                    with team_placeholder.container():
                        st.subheader("ğŸ¤– ç·¨æˆã•ã‚ŒãŸAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ")
                        team = result["agent_team"]
                        with st.expander("ãƒãƒ¼ãƒ ã®è©³ç´°ã‚’è¡¨ç¤º"):
                            
                            st.markdown("##### ğŸ’¡ğŸ§¬ è§£æ±ºãƒ»é€²åŒ–æ‹…å½“ (10ä½“)")
                            gen_list = team.get("solver_agents", [])
                            if gen_list:
                                for i, gen in enumerate(gen_list):
                                    st.markdown(f"**{i+1}. {gen.get('role', 'æœªå®šç¾©')}:** {gen.get('instructions', 'æœªå®šç¾©')}")
                            else:
                                st.markdown("ï¼ˆå®šç¾©ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰")
                            
                            st.markdown("---")
                            st.markdown("##### ğŸ§ è©•ä¾¡æ‹…å½“ (3ä½“)") 
                            eva_list = team.get("evaluators", [])
                            if eva_list:
                                for i, eva in enumerate(eva_list):
                                    st.markdown(f"**{i+1}. {eva.get('role', 'N/A')}**")
                                    guideline = eva.get('evaluation_guideline', 'è©•ä¾¡ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æœªå®šç¾©')
                                    st.caption(f"ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³: {guideline}")
                            else:
                                st.markdown("ï¼ˆå®šç¾©ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰")

                # (â˜…v12.0: ä¸–ä»£ã”ã¨çµæœè¡¨ç¤ºã‚’æ±ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾å¿œ)
                elif isinstance(result, dict) and "generation" in result:
                    gen_data = result
                    with results_area.container():
                        st.subheader(f"ç¬¬ {gen_data['generation']} ä¸–ä»£ã®çµæœ")
                        with st.container(border=True):
                            if not gen_data.get('results'):
                                st.write("ã“ã®ä¸–ä»£ã§ã¯æœ‰åŠ¹ãªææ¡ˆãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                                continue
                            
                            for item in gen_data.get('results', []):
                                sol = item.get('solution', {})
                                eva = item.get('evaluation', {})
                                score = eva.get('total_score', 0)
                                
                                # â˜…v12.0 ä¿®æ­£
                                st.markdown(f"**é¡Œå:** {sol.get('proposal_title', 'N/A')} (ã‚¹ã‚³ã‚¢: {score})")
                                st.markdown(f"**ææ¡ˆå†…å®¹ (æ¦‚è¦/å‰µä½œç‰©):**\n {sol.get('proposal_content', 'N/A')}")
                                st.markdown(f"**æ–¹æ³•/ç†ç”±:**\n {sol.get('proposal_rationale', 'N/A')}")
                                
                                if item != gen_data.get('results', [])[-1]:
                                    st.markdown("---")

        # === â˜…v12.0: æœ€çµ‚çµæœã®è¡¨ç¤ºã‚’æ±ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾å¿œ ===
        
        all_solutions = [
            item for gen in solver.history
            for item in gen.get("results", [])
            if item.get("evaluation") and "total_score" in item["evaluation"]
        ]

        if all_solutions:
            sorted_solutions = sorted(
                all_solutions,
                key=lambda x: x["evaluation"]["total_score"],
                reverse=True
            )
            
            top_5_solutions = sorted_solutions[:5]

            status_placeholder.empty()
            st.balloons()

            with final_result_placeholder:
                st.success("ğŸ† å‡¦ç†å®Œäº†ï¼ã‚¹ã‚³ã‚¢ãƒˆãƒƒãƒ—5ã®ææ¡ˆã¯ã“ã¡ã‚‰ã§ã™ã€‚")
                
                for i, item in enumerate(top_5_solutions):
                    sol = item.get('solution', {})
                    eva = item.get('evaluation', {})
                    score = eva.get('total_score', 'N/A')
                    
                    # â˜…v12.0 ä¿®æ­£
                    st.header(f"ğŸ… ç¬¬ {i + 1} ä½: {sol.get('proposal_title', 'N/A')}")
                    st.metric(label="æœ€çµ‚ã‚¹ã‚³ã‚¢ (3ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¹³å‡)", value=f"{score}")

                    # â˜…v12.0 ä¿®æ­£: ææ¡ˆå†…å®¹ã¨ç†ç”±ã‚’å…ˆã«è¡¨ç¤º
                    st.info(f"**ææ¡ˆå†…å®¹ (æ¦‚è¦/å‰µä½œç‰©)**\n\n{sol.get('proposal_content', 'N/A')}")
                    st.info(f"**å…·ä½“çš„ãªæ–¹æ³• / ç‹™ã„ãƒ»ç†ç”±**\n\n{sol.get('proposal_rationale', 'N/A')}")

                    # è©•ä¾¡ã‚’è¡¨ç¤º
                    col1, col2 = st.columns(2)
                    with col1:
                        st.success(f"**å„ªã‚ŒãŸç‚¹ (3åã®è©•ä¾¡è€…ã‚ˆã‚Š)**")
                        st.text_area(
                            f"å„ªã‚ŒãŸç‚¹ {i+1}", 
                            value=eva.get('strengths', 'N/A'), 
                            height=250, 
                            disabled=True,
                            label_visibility="collapsed"
                        )
                    with col2:
                        st.warning(f"**æ‡¸å¿µç‚¹ãƒ»æ”¹å–„ç‚¹ (3åã®è©•ä¾¡è€…ã‚ˆã‚Š)**")
                        st.text_area(
                            f"æ‡¸å¿µç‚¹ãƒ»æ”¹å–„ç‚¹ {i+1}", 
                            value=eva.get('weaknesses', 'N/A'), 
                            height=250, 
                            disabled=True,
                            label_visibility="collapsed"
                        )
                    
                    st.info(f"**ç·è©• (3åã®è©•ä¾¡è€…ã‚ˆã‚Š)**")
                    st.text_area(
                        f"ç·è©• {i+1}",
                        value=eva.get('overall_comment', 'N/A'),
                        height=200,
                        disabled=True,
                        label_visibility="collapsed"
                    )
                    
                    st.markdown("---")
        else:
            status_placeholder.warning("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸãŒã€æœ€çµ‚çš„ãªææ¡ˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")